<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>G_iResNet</title>
      <link href="/2022/03/28/G-iResNet/"/>
      <url>/2022/03/28/G-iResNet/</url>
      
        <content type="html"><![CDATA[<h1 id="Invertible-Residual-Networks"><a href="#Invertible-Residual-Networks" class="headerlink" title="Invertible Residual Networks"></a>Invertible Residual Networks</h1><p>ICML2019<br><span id="more"></span></p><p><a href="https://kexue.fm/archives/6482">细水长flow之可逆ResNet：极致的暴力美学</a></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python -m visdom.server # 开启visdom服务  http://127.0.0.2:8097/</span><br><span class="line"><span class="meta">#</span><span class="language-bash">开启容器时加参数 -p 127.0.0.2:8097:8097</span> </span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># dens_set_cifar</span></span><br><span class="line">python CIFAR_main.py --nBlocks 16 16 16 --nStrides 1 2 2 --nChannels 512 512 512 --coeff 0.9 -densityEstimation -multiScale --lr 0.003 --weight_decay 0. --numSeriesTerms 5 --dataset cifar10 --batch 128 --warmup_epochs 1 --save_dir ./results/dens_est_cifar --vis_server your.server.local --vis_port your_port_nr</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># classify_cifar</span></span><br><span class="line">python ./CIFAR_main.py --nBlocks 7 7 7 --nStrides 1 2 2 --nChannels 32 64 128 --coeff 0.9 --batch 128 --dataset cifar10 --init_ds 1 --inj_pad 13 --powerIterSpectralNorm 1 --save_dir ./results/zca_clf_full_cifar10_wrn22_inj_pad_coeff09 --nonlin elu --optimizer sgd --vis_server your.server.local --vis_port your_port_nr</span><br></pre></td></tr></table></figure><h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;Train i-ResNet/ResNet on Cifar&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-densityEstimation&#x27;</span>, <span class="string">&#x27;--densityEstimation&#x27;</span>, dest=<span class="string">&#x27;densityEstimation&#x27;</span>,</span><br><span class="line">                    action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;perform density estimation&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--optimizer&#x27;</span>, default=<span class="string">&quot;adamax&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;optimizer&quot;</span>, choices=[<span class="string">&quot;adam&quot;</span>, <span class="string">&quot;adamax&quot;</span>, <span class="string">&quot;sgd&quot;</span>])</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, default=<span class="number">0.003</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;learning rate&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--coeff&#x27;</span>, default=<span class="number">0.9</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;contraction coefficient for linear layers&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--numTraceSamples&#x27;</span>, default=<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;number of samples used for trace estimation&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--numSeriesTerms&#x27;</span>, default=<span class="number">5</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;number of terms used in power series for matrix log&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--powerIterSpectralNorm&#x27;</span>, default=<span class="number">5</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;number of power iterations used for spectral norm&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--weight_decay&#x27;</span>, default=<span class="number">0.</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;coefficient for weight decay&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--drop_rate&#x27;</span>, default=<span class="number">0.1</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;dropout rate&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--batch&#x27;</span>, default=<span class="number">4</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;batch size&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--init_batch&#x27;</span>, default=<span class="number">1024</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;init batch size&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--init_ds&#x27;</span>, default=<span class="number">2</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;initial downsampling&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--warmup_epochs&#x27;</span>, default=<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;epochs for warmup&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--inj_pad&#x27;</span>, default=<span class="number">0</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;initial inj padding&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, default=<span class="number">200</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;number of epochs&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--nBlocks&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=[<span class="number">16</span>, <span class="number">16</span>, <span class="number">16</span>])</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--nStrides&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--nChannels&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=[<span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>])</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--resume&#x27;</span>, default=<span class="string">&#x27;&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, metavar=<span class="string">&#x27;PATH&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;path to latest checkpoint (default: none)&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-e&#x27;</span>, <span class="string">&#x27;--evaluate&#x27;</span>, dest=<span class="string">&#x27;evaluate&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;evaluate model on validation set&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-interpolate&#x27;</span>, <span class="string">&#x27;--interpolate&#x27;</span>, dest=<span class="string">&#x27;interpolate&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;train iresnet&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-drop_two&#x27;</span>, <span class="string">&#x27;--drop_two&#x27;</span>, dest=<span class="string">&#x27;drop_two&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;2d dropout on&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-nesterov&#x27;</span>, <span class="string">&#x27;--nesterov&#x27;</span>, dest=<span class="string">&#x27;nesterov&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;nesterov momentum&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-norm&#x27;</span>, <span class="string">&#x27;--norm&#x27;</span>, dest=<span class="string">&#x27;norm&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;compute norms of conv operators&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-analysisTraceEst&#x27;</span>, <span class="string">&#x27;--analysisTraceEst&#x27;</span>, dest=<span class="string">&#x27;analysisTraceEst&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;analysis of trace estimation&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-multiScale&#x27;</span>, <span class="string">&#x27;--multiScale&#x27;</span>, dest=<span class="string">&#x27;multiScale&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;use multiscale&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-fixedPrior&#x27;</span>, <span class="string">&#x27;--fixedPrior&#x27;</span>, dest=<span class="string">&#x27;fixedPrior&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;use fixed prior, default is learned prior&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-noActnorm&#x27;</span>, <span class="string">&#x27;--noActnorm&#x27;</span>, dest=<span class="string">&#x27;noActnorm&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;disable actnorm, default uses actnorm&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--nonlin&#x27;</span>, default=<span class="string">&quot;elu&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, choices=[<span class="string">&quot;relu&quot;</span>, <span class="string">&quot;elu&quot;</span>, <span class="string">&quot;sorting&quot;</span>, <span class="string">&quot;softplus&quot;</span>])</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--dataset&#x27;</span>, default=<span class="string">&#x27;cifar10&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;dataset&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--save_dir&#x27;</span>, default=<span class="string">&quot;./results/dens_est_cifar&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;directory to save results&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--vis_port&#x27;</span>, default=<span class="number">8097</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;port for visdom&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--vis_server&#x27;</span>, default=<span class="string">&quot;localhost&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;server for visdom&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--log_every&#x27;</span>, default=<span class="number">10</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;logs every x iters&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-log_verbose&#x27;</span>, <span class="string">&#x27;--log_verbose&#x27;</span>, dest=<span class="string">&#x27;log_verbose&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;verbose logging: sigmas, max gradient&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-deterministic&#x27;</span>, <span class="string">&#x27;--deterministic&#x27;</span>, dest=<span class="string">&#x27;deterministic&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;fix random seeds and set cuda deterministic&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="main-py"><a href="#main-py" class="headerlink" title="main.py"></a>main.py</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># dens_est</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line"><span class="comment"># transform</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># datasets</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># setup logging with visdom</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># dataloader</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># get multiscale network4</span></span><br><span class="line">    model = multiscale_iResNet(in_shape, <span class="comment">#(3, 32, 32)</span></span><br><span class="line">                                       args.nBlocks, args.nStrides, args.nChannels,<span class="comment">#[16 16 16] [1 2 2] [512 512 512]</span></span><br><span class="line">                                       args.init_ds == <span class="number">2</span>,</span><br><span class="line">                                       args.inj_pad, args.coeff, args.densityEstimation,<span class="comment">#0 0.9 true</span></span><br><span class="line">                                       args.nClasses, <span class="comment">#10</span></span><br><span class="line">                                       args.numTraceSamples, args.numSeriesTerms,<span class="comment">#1 5</span></span><br><span class="line">                                       args.powerIterSpectralNorm,<span class="comment">#5</span></span><br><span class="line">                                       actnorm=(<span class="keyword">not</span> args.noActnorm),<span class="comment">#false</span></span><br><span class="line">                                       learn_prior=(<span class="keyword">not</span> args.fixedPrior),<span class="comment">#false</span></span><br><span class="line">                                       nonlin=args.nonlin)<span class="comment">#elu</span></span><br><span class="line">    </span><br></pre></td></tr></table></figure><h3 id="conv-iResNet-py"><a href="#conv-iResNet-py" class="headerlink" title="conv_iResNet.py"></a>conv_iResNet.py</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">multiscale_conv_iResNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_shape, nBlocks, nStrides, nChannels, init_squeeze=<span class="literal">False</span>, inj_pad=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 coeff=<span class="number">.9</span>, density_estimation=<span class="literal">False</span>, nClasses=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 numTraceSamples=<span class="number">1</span>, numSeriesTerms=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 n_power_iter=<span class="number">5</span>,</span></span><br><span class="line"><span class="params">                 actnorm=<span class="literal">True</span>, learn_prior=<span class="literal">True</span>, nonlin=<span class="string">&quot;relu&quot;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(multiscale_conv_iResNet, self).__init__()</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(nBlocks) == <span class="built_in">len</span>(nStrides) == <span class="built_in">len</span>(nChannels)</span><br><span class="line">        <span class="keyword">if</span> init_squeeze:</span><br><span class="line">            self.init_squeeze = Squeeze(<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.init_squeeze = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> inj_pad &gt; <span class="number">0</span>:</span><br><span class="line">            self.inj_pad = injective_pad(inj_pad)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.inj_pad = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> init_squeeze:</span><br><span class="line">            in_shape = downsample_shape(in_shape)</span><br><span class="line">        in_shape = (in_shape[<span class="number">0</span>] + inj_pad, in_shape[<span class="number">1</span>], in_shape[<span class="number">2</span>])  <span class="comment"># adjust channels</span></span><br><span class="line"></span><br><span class="line">        self.nBlocks = nBlocks</span><br><span class="line">        self.density_estimation = density_estimation</span><br><span class="line">        self.nClasses = nClasses</span><br><span class="line">        <span class="comment"># parameters for trace estimation</span></span><br><span class="line">        self.numTraceSamples = numTraceSamples <span class="keyword">if</span> density_estimation <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        self.numSeriesTerms = numSeriesTerms <span class="keyword">if</span> density_estimation <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        self.n_power_iter = n_power_iter</span><br><span class="line"></span><br><span class="line">        self.stack, self.in_shapes = self._make_stack(in_shape, nBlocks,</span><br><span class="line">                                                      nStrides, nChannels, numSeriesTerms, numTraceSamples,</span><br><span class="line">                                                      coeff, actnorm, n_power_iter, nonlin)</span><br><span class="line">        <span class="comment"># make prior distribution</span></span><br><span class="line">        self._make_prior(learn_prior)</span><br><span class="line">        <span class="comment"># make classifier</span></span><br><span class="line">        self._make_classifier(self.final_shape(), nClasses)</span><br><span class="line">        <span class="keyword">assert</span> (nClasses <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">or</span> density_estimation), <span class="string">&quot;Must be either classifier or density estimator&quot;</span></span><br></pre></td></tr></table></figure><h3 id="SpectralNormConv"><a href="#SpectralNormConv" class="headerlink" title="SpectralNormConv"></a>SpectralNormConv</h3><script type="math/tex; mode=display">\mathbf{W} = \dfrac{\mathbf{W}}{\sigma(\mathbf{W})} \\         \sigma(\mathbf{W}) = \max_{\mathbf{h}: \mathbf{h} \ne 0} \dfrac{\|\mathbf{W} \mathbf{h}\|_2}{\|\mathbf{h}\|_2}</script><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">spectral_norm_conv</span>(<span class="params">module, coeff, input_dim, name=<span class="string">&#x27;weight&#x27;</span>, n_power_iterations=<span class="number">1</span>, eps=<span class="number">1e-12</span></span>):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot;将谱归一化应用于给定模块中的参数</span></span><br><span class="line"><span class="string">    谱归一化通过使用幂迭代方法计算的权重矩阵的谱范数重新缩放权重张量来稳定GAN中鉴别器的训练。如果权重张量的维数大于2，则在幂迭代法中将其重新整形为2D以获得谱范数。这是通过一个hook实现的，该hook在每个 :meth:`~Module.forward` 调用之前计算谱范数并重新调整权重。 </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        module (nn.Module): 包含的模块</span></span><br><span class="line"><span class="string">        name (str, optional): 权重参数名称</span></span><br><span class="line"><span class="string">        n_power_iterations (int, optional): 计算谱范数的幂迭代次数</span></span><br><span class="line"><span class="string">        eps (float, optional): epsilon 在计算范数时的数值稳定性</span></span><br><span class="line"><span class="string">        dim (int, optional): 输出个数对应的维度，默认为0，当为1时，作为ConvTranspose1/2/3d实例的模块，</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        The original module with the spectal norm hook 带有谱归一化hook的原始模块</span></span><br><span class="line"><span class="string">    Example::</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = spectral_norm(nn.Linear(20, 40))</span></span><br><span class="line"><span class="string">        Linear (20 -&gt; 40)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m.weight_u.size()</span></span><br><span class="line"><span class="string">        torch.Size([20])</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    input_dim_4d = (<span class="number">1</span>, input_dim[<span class="number">0</span>], input_dim[<span class="number">1</span>], input_dim[<span class="number">2</span>])</span><br><span class="line">    SpectralNormConv.apply(module, coeff, input_dim_4d, name, n_power_iterations, eps)</span><br><span class="line">    <span class="keyword">return</span> module</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Conv2D 层的软谱归一化（未强制，仅 &lt;= coeff）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SpectralNormConv</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="comment"># 每次 forward call 前后不变</span></span><br><span class="line">    <span class="comment">#   u = normalize(W @ v)</span></span><br><span class="line">    <span class="comment"># NB: 在初始化时，不强制执行此不变量</span></span><br><span class="line"></span><br><span class="line">    _version = <span class="number">1</span></span><br><span class="line">    <span class="comment"># At version 1:</span></span><br><span class="line">    <span class="comment">#   made  `W` not a buffer,</span></span><br><span class="line">    <span class="comment">#   added `v` as a buffer, and</span></span><br><span class="line">    <span class="comment">#   made eval mode use `W = u @ W_orig @ v` rather than the stored `W`.</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">apply</span>(<span class="params">module, coeff, input_dim, name, n_power_iterations, eps</span>):</span><br><span class="line">        <span class="keyword">for</span> k, hook <span class="keyword">in</span> module._forward_pre_hooks.items():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(hook, SpectralNormConv) <span class="keyword">and</span> hook.name == name:</span><br><span class="line">                <span class="keyword">raise</span> RuntimeError(<span class="string">&quot;Cannot register two spectral_norm hooks on &quot;</span></span><br><span class="line">                                   <span class="string">&quot;the same parameter &#123;&#125;&quot;</span>.<span class="built_in">format</span>(name))</span><br><span class="line"></span><br><span class="line">        fn = SpectralNormConv(coeff, input_dim, name, n_power_iterations, eps)</span><br><span class="line">        weight = module._parameters[name]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            num_input_dim = input_dim[<span class="number">0</span>]* input_dim[<span class="number">1</span>]* input_dim[<span class="number">2</span>]* input_dim[<span class="number">3</span>]</span><br><span class="line">            v = normalize(torch.randn(num_input_dim), dim=<span class="number">0</span>, eps=fn.eps)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># get settings from conv-module (for transposed convolution) 从 conv-module 获取设置（用于转置卷积）</span></span><br><span class="line">            stride = module.stride</span><br><span class="line">            padding = module.padding</span><br><span class="line">            <span class="comment"># forward call to infer the shape 推断shape</span></span><br><span class="line">            u = conv2d(v.view(input_dim), weight, stride=stride, padding=padding,</span><br><span class="line">                               bias=<span class="literal">None</span>)</span><br><span class="line">            fn.out_shape = u.shape</span><br><span class="line">            num_output_dim = fn.out_shape[<span class="number">0</span>]* fn.out_shape[<span class="number">1</span>]* fn.out_shape[<span class="number">2</span>]* fn.out_shape[<span class="number">3</span>]</span><br><span class="line">            <span class="comment"># overwrite u with random init 用随机初始化覆盖u</span></span><br><span class="line">            u = normalize(torch.randn(num_output_dim), dim=<span class="number">0</span>, eps=fn.eps)</span><br><span class="line"></span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute_weight</span>(<span class="params">self, module, do_power_iteration</span>):</span><br><span class="line">        <span class="comment"># NB: 如果设置了 `do_power_iteration`，`u` 和 `v` 向量将在幂迭代中实时更新。这很重要，因为在 `DataParallel` forward 中，向量（作为缓冲区）从并行化模块广播到每个模块副本，这是一个动态创建的新模块对象。每个副本运行自己的谱范数幂迭代。所以简单地将更新的向量分配给这个函数运行的模块将导致更新永远丢失。下次复制并行化模块时，相同的随机初始化向量将被广播并使用！</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 因此，为了使更改传播回来，我们依赖两个重要的行为（也通过测试强制执行）： </span></span><br><span class="line">        <span class="comment"># 1. 如果广播张量已经在正确的设备上，`DataParallel` 不会克隆存储； 并且它确保parallelized 模块已经在`device[0]` 上。</span></span><br><span class="line">        <span class="comment"># 2. 如果 `out=` kwarg 中的输出张量具有正确的形状，它会 # 只填充值。</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 因此，由于在所有设备上执行相同的幂迭代，只需就地更新张量将确保 `device[0]` 上的模块副本将更新并行化模块上的 _u 向量（通过共享存储）。</span></span><br><span class="line">       </span><br><span class="line">        <span class="comment">#然而，在我们就地更新 `u` 和 `v` 之后，我们需要在使用它们来标准化权重之前克隆它们。</span></span><br><span class="line">        <span class="comment">#这是为了支持通过两次前向传递进行反向传播，例如，GAN 训练中的常见模式：</span></span><br><span class="line">        <span class="comment">#loss = D(real) - D(fake)</span></span><br><span class="line">        <span class="comment">#否则，引擎将抱怨第一个前向后需要做的变量（即，`u` 和 `v` 向量）在第二个前向中改变。</span></span><br><span class="line">        </span><br><span class="line">        weight = <span class="built_in">getattr</span>(module, self.name + <span class="string">&#x27;_orig&#x27;</span>)</span><br><span class="line">        u = <span class="built_in">getattr</span>(module, self.name + <span class="string">&#x27;_u&#x27;</span>)</span><br><span class="line">        v = <span class="built_in">getattr</span>(module, self.name + <span class="string">&#x27;_v&#x27;</span>)</span><br><span class="line">        sigma_log = <span class="built_in">getattr</span>(module, self.name + <span class="string">&#x27;_sigma&#x27;</span>) <span class="comment"># for logging</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 从 conv-module 获取设置（用于转置卷积）</span></span><br><span class="line">        stride = module.stride</span><br><span class="line">        padding = module.padding</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> do_power_iteration: <span class="comment">#幂迭代</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.n_power_iterations):</span><br><span class="line">                    v_s = conv_transpose2d(u.view(self.out_shape), weight, stride=stride,padding=padding, output_padding=<span class="number">0</span>)</span><br><span class="line">                    <span class="comment"># Note: out flag for in-place changes就地更改的 out 标志</span></span><br><span class="line">                    v = normalize(v_s.view(-<span class="number">1</span>), dim=<span class="number">0</span>, eps=self.eps, out=v)</span><br><span class="line">                    </span><br><span class="line">                    u_s = conv2d(v.view(self.input_dim), weight, stride=stride, padding=padding,</span><br><span class="line">                           bias=<span class="literal">None</span>)</span><br><span class="line">                    u = normalize(u_s.view(-<span class="number">1</span>), dim=<span class="number">0</span>, eps=self.eps, out=u)</span><br><span class="line">                <span class="keyword">if</span> self.n_power_iterations &gt; <span class="number">0</span>:</span><br><span class="line">                    <span class="comment"># See above on why we need to clone 请参阅上文了解为什么我们需要克隆</span></span><br><span class="line">                    u = u.clone()</span><br><span class="line">                    v = v.clone()</span><br><span class="line">        weight_v = conv2d(v.view(self.input_dim), weight, stride=stride, padding=padding,</span><br><span class="line">                           bias=<span class="literal">None</span>)</span><br><span class="line">        weight_v = weight_v.view(-<span class="number">1</span>)</span><br><span class="line">        sigma = torch.dot(u.view(-<span class="number">1</span>), weight_v)  </span><br><span class="line">        <span class="comment"># enforce spectral norm only as constraint 仅将谱范数强制为约束</span></span><br><span class="line">        factorReverse = torch.<span class="built_in">max</span>(torch.ones(<span class="number">1</span>).to(weight.device),</span><br><span class="line">                                  sigma / self.coeff)</span><br><span class="line">        <span class="comment"># for logging</span></span><br><span class="line">        sigma_log.copy_(sigma.detach())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># rescaling</span></span><br><span class="line">        weight = weight / (factorReverse + <span class="number">1e-5</span>)  <span class="comment"># for stability</span></span><br><span class="line">        <span class="keyword">return</span> weight</span><br></pre></td></tr></table></figure><hr><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>我们证明了标准的 ResNet 体系结构可以使之<strong>可逆</strong>，从而允许将相同的模型用于分类，<strong>密度估计和生成</strong>。通常，实施可逆性需要<strong>划分维度</strong>(partitioning dimensions)或<strong>限制网络体系结构</strong>( restricting network architectures)。相反，我们的方法只需要在<strong>训练</strong>过程中添加一个简单的<strong>标准化步骤</strong>(normalization step)即可，这已经在标准框架中提供了。</p><p>Invertible ResNets 定义了一个生成模型，可以通过对未标记数据的<strong>最大似然</strong>进行训练。 为了计算似然，我们对 residual block 的雅可比对数行列式引入了<strong>易于处理的近似</strong>（tractable approximation）。</p><p>我们的经验评估表明，Invertible ResNets 在最先进的图像分类器和 flow-based 生成模型上均具有竞争力，这是以前用单一架构无法实现的。</p><hr><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1.  Introduction"></a>1.  Introduction</h2><p>基于神经网络的模型的主要吸引力之一是，单个模型体系结构通常可用于解决各种相关任务。 但是，最近的许多改进都基于针对特定领域（particular domains ）量身定制的专用解决方案。例如，无监督学习中的最新架构正在变得越来越具有领域特定性 （Van Den Oord，2016b; Kingma，2018; Parmar，2018; Karras，2018; Van  Den Oord，2016a）。另一方面，用于判别式学习的最成功的前馈架构之一是深度残差网络（He，2016; Zagoruyko，2016），与同类的生成网络有很大差异。</p><p>这种鸿沟使得为<strong>给定任务</strong>选择或设计合适的体系结构变得很复杂。这也使<strong>判别任务</strong>难以从<strong>无监督学习</strong>中受益。我们用在这两个领域都表现出色的新型架构来弥合这一差距。</p><p>为实现这一目标，我们专注于可逆网络，这些网络已证明在判别性（Gomez，2017; Jacobsen，2018）和生成性（Dinh，2014; 2017; Kingma，  2018）独立执行任务，尽管使用相同的模型范式（model paradigm）。</p><p>它们通常依赖于固定维拆分启发法，但与非体积保留（non-volume conserving ）元素交织的常见拆分受到限制，它们的选择对性能有重大影响（Kingma，2018; Dinh，2017）。这使得建立可逆网络成为一项艰巨的任务。在这项工作中，我们表明，这些具有竞争性的密度估计性能所必需的奇特（exotic）设计会严重损害判别性能。</p><p>为了克服这个问题，我们利用 ResNets 作为 ODE 的 Euler 离散化的观点（Haber，2018; Ruthotto，2018; Lu，2017; Ciccone，2018）并且证明了 invertible ResNets (iResNets) 只需更改标准 ResNets 的规范化方案即可构建。<span id="#fig1"></span></p><p><img src="assets/1621241932669.png" alt="1621241932669"></p><p><strong>Fig. 1:</strong> 标准 ResNet 网络(左)和 iResNet (右)的动力学。两个网络都将区间 $[2，2]$ 映射为: i)半深度处的噪声 <strong>$x^3$-函数</strong>；ii)全深度处的噪声<strong>恒等函数</strong>。Invertible ResNets 描述了一个双射连续动态，而 ResNets 导致了与非双射连续动态相对应的交叉和折叠路径(用白色圈起来)。由于折叠(collapsing)路径，ResNets 不是有效的密度模型。</p><p><strong>Fig. 1</strong> 可视化了标准和可逆ResNet所学到的动力学差异。该方法允许每个 residual block 具有不受约束的体系结构，而只需要<strong>每个 block 的 Lipschitz 常数小于一个常数</strong>。我们证明，在构建图像分类器时，此限制对性能的影响可以忽略不计-在对MNIST，CIFAR10和CIFAR100图像进行分类时，它们的性能与不可逆的性能相当。</p><p>然后，我们展示如何将 i-ResNets 训练为未标记数据上的最大似然生成模型。为了计算似然，我们对残差块的雅可比行列式引入了易于处理的（tractable approximation）近似。像FFJORD（Grathwohl，2019）一样，i-ResNet flows 具有不受约束的（free-form）雅可比矩阵，这使他们可以学习<strong>比</strong>使用的三角映射的<strong>其他可逆模型</strong>中<strong>更富有表现力</strong>的变换。我们的经验评估表明，i-ResNets 在最先进的图像分类器和 flow-based 的生成模型上均具有竞争力，使通用体系结构更接近现实。</p><hr><h2 id="2-Enforcing-Invertibility-in-ResNets"><a href="#2-Enforcing-Invertibility-in-ResNets" class="headerlink" title="2. Enforcing Invertibility in ResNets"></a>2. Enforcing Invertibility in ResNets</h2><p>在常微分方程初值问题上 ResNet 架构与 Euler 方法有显著的相似性</p><script type="math/tex; mode=display">\begin{equation} x_{t+1} \leftarrow x_{t}+g_{\theta_{t}}\left(x_{t}\right) \\ x_{t+1} \leftarrow x_{t}+h f_{\theta_{t}}\left(x_{t}\right) \end{equation}</script><p>其中 $ x_{t} \in \mathbb{R}^{d} $ 表示激活或状态，$t$ 表示层索引或时间，$h&gt; 0$ 是步长，$g_{θ_t}$ 是残差块。这种联系在深度学习和动力学系统的交叉点吸引了研究（Lu，2017; Haber，2018; Ruthottor，2018; Chen，2018）。 但是，很少有人关注时间倒退(backwards)的动力学。</p><script type="math/tex; mode=display">\begin{equation} x_{t} \leftarrow x_{t+1}-g_{\theta_{t}}\left(x_{t}\right) \\ x_{t} \leftarrow x_{t+1}-h f_{\theta_{t}}\left(x_{t}\right) \end{equation}</script><p>这相当于隐式向后的 Euler 离散化。特别地，及时解决动力学倒退将实现相应的 ResNet 的逆过程。 以下 <a href="#the1">Theorem 1</a> 指出，一个简单的条件足以使动力学可解，从而使 ResNet 可逆： </p><hr><h3 id="Theorem-1"><a href="#Theorem-1" class="headerlink" title="Theorem 1"></a>Theorem 1<span id="the1"></span></h3><p>可逆 ResNets 的充分条件</p><p>令 $ F_{\theta}: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d} $ ，其中 $ F_{\theta}=\left(F_{\theta}^{1} \circ \ldots \circ F_{\theta}^{T}\right) $ 定义一个ResNet，该网络内块 $ F_{\theta}^{t}=I+g_{\theta_{t}} $ 。然后如果满足以下条件:</p><script type="math/tex; mode=display">\begin{equation} \operatorname{Lip}\left(g_{\theta_{t}}\right)<1 \text{, for all  t=1,} \ldots, T \end{equation}</script><p>则 ResNet $F_{\theta}$ 可逆，其中 $\operatorname{Lip}\left(g_{\theta_{t}}\right)$ 是 $g_{\theta_{t}}$ 的 Lipschitz 常数。</p><p>请注意，<strong>此条件对于可逆性不是必需的</strong>。其他方法（NICE/RealNvp，2014; 2017; i-revnet，2018; Chang，2018; Glow，2018）依赖于<strong>划分维度</strong>或<strong>自回归结构</strong>来创建逆的解析解。</p><h4 id="Proof-Theorem-1"><a href="#Proof-Theorem-1" class="headerlink" title="Proof. (Theorem 1)"></a><strong>Proof. (Theorem 1)</strong></h4><p>因为 ResNet $ F_{\theta} $ 是函数的组合，因此如果每个块 $ F_{\theta}^{t} $ 是可逆的，则它是可逆的。令 $ x_{t+1} \in \mathbb{R}^{d} $ 为任意，并考虑反向的的欧拉离散化 $ x_{t}=x_{t+1}-h f_{\theta_{t}}\left(x_{t}\right)=x_{t+1}-g_{\theta_{t}}\left(x_{t}\right) $。 重写作为迭代形式</p><script type="math/tex; mode=display">\begin{equation} x_{t}^{0}:=x_{t+1} \quad \text{and} \quad x_{t}^{k+1}:=x_{t+1}- g_{\theta_{t}}\left(x_{t}^{k}\right) \end{equation}\tag{6}</script><p>如果迭代收敛，则 $ \lim _{k \rightarrow \infty} x_{t}^{k}=x_{t} $ 是不动点。 因为 $ g_{\theta_{t}}: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d} $ 是 Banach 空间上的算子，所以由于 Banach 不动点定理，收缩条件 $ \operatorname{Lip}\left(g_{\theta_{t}}\right)&lt;1 $ 保证了收敛。</p><h3 id="Algorithm-1"><a href="#Algorithm-1" class="headerlink" title="Algorithm 1."></a><strong>Algorithm 1.</strong><span id="algo1"></span></h3><p><img src="assets/1621245202635.png" alt="1621245202635"></p><p>当强制令 $\operatorname{Lip}\left(g_{\theta_{t}}\right)<1$ 使 ResNet 可逆，我们没有此逆的解析形式。但是，我们可以通过简单的定点迭代（fixed-point iteration）来获得它，请参见 [Algorithm 1](#algo1)。请注意，定点迭代的起始值可以是任何矢量，因为定点是唯一的。但是，将输出 $y = x + g(x)$ 用作初始化 $x^0:=y$ 是一个很好的起点，因为 $y$ 仅通过**恒等边界扰动**（a bounded perturbation of the identity）从 $x$ 中获得。根据巴纳赫不动点定理（Banach fixed-point theorem），我们有<span id="eq1">&lt;/span&gt;</p><script type="math/tex; mode=display">\begin{equation} \left\|x-x^{n}\right\|_{2} \leq \frac{\operatorname{Lip}(g)^{n}}{1-\operatorname{Lip}(g)}\left\|x^{1}-x^{0}\right\|_{2} \end{equation}\tag{1}</script><p>因此，收敛速度在迭代次数 $n$ 中是指数的，并且较小的 Lipschitz 常数将产生更快的收敛。</p><p>除了可逆性之外，压缩的（contractive）残差块还会使残差层变为 bi-Lipschitz（双射Lipschitz）。</p><hr><h3 id="Lemma-2"><a href="#Lemma-2" class="headerlink" title="Lemma 2"></a>Lemma 2<span id="lem2"></span></h3><p>（Forward and Inverse 正向和反向的 Lipschitz常数）。令 $ F(x)=x+g(x) $ 且 $ \operatorname{Lip}(g)=L&lt;1 $ 表示残差层。然后，它保持</p><script type="math/tex; mode=display">\begin{equation} \operatorname{Lip}(F) \leq 1+L \quad \text{and} \quad \operatorname{Lip}\left(F^{-1}\right) \leq \frac{1}{1-L} \end{equation}</script><p>因此通过设计，invertible ResNets 为它们的正向和反向映射都提供了稳定性保证。在以下部分中，我们讨论了增强 Lipschitz条件的方法。</p><h4 id="Proof-Lemma-2"><a href="#Proof-Lemma-2" class="headerlink" title="Proof. (Lemma 2)"></a>Proof. (Lemma 2)</h4><p>首先请注意，$ \operatorname{Lip}(F) \leq 1+L $ 直接来自Lipschitz 常数的加法运算。对于逆，考虑</p><script type="math/tex; mode=display">\begin{equation} \begin{aligned}\|F(x)-F(y)\|_{2} &=\|x-y+g(x)-g(y)\|_{2} \\ &=\|x-y-(-g(x)+g(y))\|_{2} \\ & \geq\left|\|x-y\|_{2}-\|-g(x)+g(y)\|_{2}\right| \\ & \geq\left|\|x-y\|_{2}-\|(-1)(g(x)-g(y))\|_{2}\right| \\ & \geq\|x-y\|_{2}-\|g(x)-g(y)\|_{2} \\ & \geq\|x-y\|_{2}-L\|x-y\|_{2}, \end{aligned} \end{equation}</script><p>在这里我们在上式中应用逆三角形不等式（reverse triangular inequality），并应用 $g$ 的Lipschitz 常数。 因为 $ F^{-1} $ 是射影，所以对于 $ z, w \in \mathbb{R}^{d} $，满足 $ x=F^{-1}(z) $ 和 $ y=F^{-1}(w) $ 是可能的。</p><script type="math/tex; mode=display">\begin{equation} \left\|F\left(F^{-1}(z)\right)-F\left(F^{-1}(w)\right)\right\|_{2} \geq(1-L)\left\|F^{-1}(z)-F^{-1}(w)\right\|_{2} \\ \Longleftrightarrow \quad \frac{1}{1-L}\|z-w\|_{2} \geq\left\|F^{-1}(z)-F^{-1}(w)\right\|_{2} \end{equation}</script><p>它适用于所有 $z,w$。</p><hr><h3 id="2-1-Satisfying-the-Lipschitz-Constraint"><a href="#2-1-Satisfying-the-Lipschitz-Constraint" class="headerlink" title="2.1. Satisfying the Lipschitz Constraint"></a>2.1. Satisfying the Lipschitz Constraint</h3><p>满足Lipschitz约束</p><p>我们将残差块实现为<strong>收缩非线性</strong> $ \phi $（例如ReLU，ELU，tanh）和<strong>线性映射的组合</strong>。</p><p>例如，在我们的卷积网络中，$ g = W_{3} \phi\left(W_{2} \phi\left(W_{1}\right)\right) $，其中 $W_i$ 是卷积层。因此，</p><script type="math/tex; mode=display">\begin{equation} \operatorname{Lip}(g)<1, \quad \text{if}\quad \left\|W_{i}\right\|_{2}<1 \end{equation}</script><p>其中 $ |\cdot|_{2} $ 表示谱范数 spectral norm。请注意，对 $g$ 的 Jacobian 谱范数进行正则化（Sokoli, 2017）仅会局部降低它，并不保证上述条件。因此，我们将对每一层强制执行 $ \left|W_{i}\right|_{2}&lt;1 $。</p><p>如（Miyato, 2018）所述，如果滤波器内核大于 $1 × 1$，那么参数矩阵上的幂迭代仅近似于 $| W_{i} |_{2} $ 上的界限，而不是真实的谱范数，有关界限的详细信息，请参见（Tsuzuku,2018）。因此，与（Miyato, 2018）不同。我们按照（Gouk,2018）的建议通过使用 $ W_{i} $ 和 $ W_{i}^{1} $ 进行功率迭代来直接估计 $ W_{i} $ 的谱范数。幂迭代产生了一个低估计值 under-estimate $ \tilde{\sigma}_{i} \leq\left|W_{i}\right|_{2} $。 使用此估算值，我们通过下式进行标准化：</p><script type="math/tex; mode=display">\begin{equation} \tilde{W}_{i}=\left\{\begin{array}{ll}c W_{i} / \tilde{\sigma}_{i}, & \text { if } c / \tilde{\sigma}_{i}<1 \\ W_{i}, & \text { else }\end{array}\right. \end{equation}\tag{2}</script><p>其中超参数 $c &lt;1$ 是缩放系数。由于 $ \tilde{\sigma}_{i} $ 是一个低估计值，因此无法保证 $ \left|W_{i}\right|_{2} \leq c $ 满足。 但是，经过训练后（Sedghi, 2019）提供了一种在傅立叶变换参数矩阵上使用 SVD 精确检查 $ \left|W_{i}\right|_{2} $  的方法，这将使我们能够证明 $ \operatorname{Lip}(g)&lt;1 $ 在所有情况下均成立。</p><hr><h2 id="3-Generative-Modelling-with-i-ResNets"><a href="#3-Generative-Modelling-with-i-ResNets" class="headerlink" title="3. Generative Modelling with i-ResNets"></a>3. Generative Modelling with i-ResNets</h2><p>我们可以通过首先对 $ z \sim p_{z}(z) $ 进行采样（其中 $ z \in \mathbb{R}^{d} $）然后为某些函数 $ \Phi: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d} $ 定义 $ x=\Phi(z) $ 来为数据 $ x \in \mathbb{R}^{d} $ 定义一个简单的生成模型。如果 $ \Phi$ 是可逆的，并且我们定义 $ F=\Phi^{-1} $，那么我们可以使用变量变化公式(change of variables formula)来计算该模型下任意 $x$ 的似然<span id="eq3"></span></p><script type="math/tex; mode=display">\begin{equation} \ln p_{x}(x)=\ln p_{z}(z)+\ln \left|\operatorname{det} J_{F}(x)\right| \end{equation}\tag{3}</script><p>其中 $ J_{F}(x) $ 是 $F$ 在 $x$ 处的雅可比行列式。这种形式的模型称为标准化流（Rezende，2015）。由于引入了功能强大的双射函数逼近器，它们最近已经成为高维数据的流行模型，其雅可比对数行列式可以被有效地计算（Dinh，2014; 2017; Kingma，2018; Chen，2018）或逼近（Grathwohl，2019）。</p><p>由于保证了 i-ResNets 是可逆的，因此我们可以使用它们在 <a href="#eq3">Eq. 3</a> 中对 $F$ 进行参数化。 可以通过首先对 $ z \sim p(z) $ 进行采样，然后使用 <a href="#algo1">Algorithm 1</a>. 计算 $ x=F^{-1}(z) $ 来抽取该模型的样本。在 <strong>Fig. 2</strong> 中，我们与 Glow 相比，显示了使用 i-ResNet 在某些二维数据集上定义生成模型的示例（Kingma，2018）。</p><p><img src="assets/1621944333639.png" alt="1621944333639"></p><p><strong>Fig. 2</strong> Visual comparison of i-ResNet flow and Glow. Details of this experiment can be found in <a href="#appC3">Appendix C.3</a>.</p><hr><h3 id="3-1-Scaling-to-Higher-Dimensions"><a href="#3-1-Scaling-to-Higher-Dimensions" class="headerlink" title="3.1. Scaling to Higher Dimensions"></a>3.1. Scaling to Higher Dimensions</h3><p>缩放到更高的尺寸</p><p>尽管 i-ResNets 的可逆性使我们可以使用它们来定义归一化流，但我们必须计算 $ \ln \left|\operatorname{det} J_{F}(x)\right| $。 评估模型下的数据密度。计算此数量通常需要 $ \mathcal{O}\left(d^{3}\right) $ 的时间成本，这使得单纯地缩放至高维数据成为不可能。</p><p>为了绕过该约束，我们在 <a href="#eq3">Eq. 3</a> 中给出了对数行列式项的易于处理的近似，它将按比例缩放到高维 $d$。 此前，（Ramesh，2018）将对数行列式估计应用于没有 i-ResNets 特定结构的不可逆深度生成模型。</p><p>首先，我们注意到 Lipschitz 约束恒等式的扰动 $x + g(x)$ 产生正行列式，因此</p><script type="math/tex; mode=display">\begin{equation} \left|\operatorname{det} J_{F}(x)\right|=\operatorname{det} J_{F}(x) \end{equation}</script><p>参见 <a href="#lem6">Lemma 6</a> in Appendix A。将这个结果与非奇异 $ A \in \mathbb{R}^{d \times d} $ 的矩阵恒等式 $ \ln \operatorname{det}(A)=\operatorname{tr}(\ln (A)) $ 结合起来（Withers，2010）</p><script type="math/tex; mode=display">\begin{equation} \ln \left|\operatorname{det} J_{F}(x)\right|=\operatorname{tr}\left(\ln J_{F}\right) \end{equation}</script><p>其中 $\operatorname{tr}$ 表示矩阵的迹，$\ln $表示矩阵取对数。 因此，对于 $ z=F(x)=(I+g)(x) $，它有：</p><script type="math/tex; mode=display">\begin{equation} \ln p_{x}(x)=\ln p_{z}(z)+\operatorname{tr}\left(\ln \left(I+J_{g}(x)\right)\right) \end{equation}</script><p>矩阵对数的迹可以表示为幂列（Hall，2015）<span id="eq4"></span></p><script type="math/tex; mode=display">\begin{equation} \operatorname{tr}\left(\ln \left(I+J_{g}(x)\right)\right)=\sum_{k=1}^{\infty}(-1)^{k+1} \frac{\operatorname{tr}\left(J_{g}^{k}\right)}{k} \end{equation}\tag4</script><p>当 $ \left|J_{g}\right|_{2}&lt;1 $ 时，则列收敛。因此，由于Lipschitz约束，我们可以在保证收敛的情况下通过上述幂级数计算对数行列式。</p><p>在给出上述幂级数的随机近似值之前，我们观察到 i-ResNets 的以下属性：由于 $ \operatorname{Lip}\left(g_{t}\right)&lt;1 $ 对于每层 $t$ 的残差块，我们可以在其对数行列式上提供上下限:</p><script type="math/tex; mode=display">\begin{equation} d \sum_{t=1}^{T} \ln \left(1-\operatorname{Lip}\left(g_{t}\right)\right) \leq \ln \left|\operatorname{det} J_{F}(x)\right| \\ d \sum_{t=1}^{T} \ln \left(1+\operatorname{Lip}\left(g_{t}\right)\right) \geq \ln \left|\operatorname{det} J_{F}(x)\right| \end{equation}</script><p>对于所有 $ x \in \mathbb{R} $ 都满足上式，请参见 <a href="#lem7">Lemma 7</a> in Appendix A。因此，层数 $T$ 和 Lipschitz 常数都会影响 i-ResNets 的收缩和扩展范围，在设计此类体系结构时必须将其考虑在内。</p><hr><h3 id="3-2-Stochastic-Approximation-of-log-determinant"><a href="#3-2-Stochastic-Approximation-of-log-determinant" class="headerlink" title="3.2. Stochastic Approximation of log-determinant"></a>3.2. Stochastic Approximation of log-determinant</h3><p>对数行列式的随机逼近<span id="sec32"></span></p><p>用 <a href="#eq4">Eq. 4</a> 中的幂级数来表达对数行列式有三个主要的计算缺陷 drawback：</p><ul><li>1）计算 $ \operatorname{tr}\left(J_{g}\right) $ 的复杂度为 $ \mathcal{O}\left(d^{2}\right) $，或者大约需要对 $g$ 进行 $d$ 个评估，作为对角线的每个对角线项。Jacobian 需要计算 $g$ 的单独导数（Grathwohl，2019）。  </li><li>2）需要矩阵幂 $ J_{g}^{k} $，这需要完备的Jacobian知识。  </li><li>3）级数是无限的。</li></ul><p>幸运的是，可以减轻缺陷 1 和 2。首先，向量-雅可比积 $ v^{T} J_{g} $ 可以通过与逆向模式自动微分求值 $g$ 近似相同的成本来计算。其次，$ A \in \mathbb{R}^{d \times d} $ 的矩阵迹的随机逼近</p><script type="math/tex; mode=display">\begin{equation} \operatorname{tr}(A)=\mathbb{E}_{p(v)}\left[v^{T} A v\right] \end{equation}</script><p>称为 Hutchinsons 迹估算器，可用于估算 $ \operatorname{tr}\left(J_{g}^{k}\right) $。分布 $ p(v) $ 需要满足 $ \mathbb{E}[v]=0 $ 和 $ \operatorname{cov}(v)=1 $，参见（Hutchinson，1990； Avron，2011）。</p><p>虽然这允许对矩阵迹进行无偏估计，但要获得有限的计算成本，<a href="#eq4">Eq. 4</a> 中的幂级数将在索引 $n$ 处被截断，以解决缺陷 3。 <a href="#algo2">Algorithm 2</a> 总结了基本步骤。 截断将无偏估计量变为有偏估计量，其中偏置bias取决于截断误差truncation error。幸运的是，这个错误可以得到限制，如下所示。</p><p><span id="algo2"></span></p><p><img src="assets/1621949113990.png" alt="1621949113990"></p><p>为了提高使用此估计器时优化的稳定性，我们建议使用具有连续导数的非线性激活，例如ELU（Clever，2015）或 softplus 的而不是 ReLU（<a href="#appc3">Appendix C.3</a>）。</p><hr><h3 id="3-3-Error-of-Power-Series-Truncation"><a href="#3-3-Error-of-Power-Series-Truncation" class="headerlink" title="3.3. Error of Power Series Truncation"></a>3.3. Error of Power Series Truncation</h3><p>幂级数截断错误</p><p>我们使用<strong>有限</strong>幂级数估计 $ \ln \left|\operatorname{det}\left(I+J_{g}\right)\right| $</p><script type="math/tex; mode=display">\begin{equation} P S\left(J_{g}, n\right):=\sum_{k=1}^{n}(-1)^{k+1} \frac{\operatorname{tr}\left(J_{g}^{k}\right)}{k} \end{equation}\tag{5}</script><p>其中 $ P S\left(J_{g}, \infty\right)= \operatorname{tr}\left(\ln \left(I+J_{g}\right)\right)$。 我们感兴趣的是将对数行列式的截断误差限制为数据维 $d$ ，Lipschitz 常数 $Lip(g)$ 和级数 $n$ 中项数的函数。</p><hr><h3 id="Theorem-3"><a href="#Theorem-3" class="headerlink" title="Theorem 3"></a>Theorem 3</h3><p>（loss 的近似误差）。令 $g$ 表示残差函数，$J_g$ 表示雅可比行列式。 然后，在第 $n$ 项处的幂级数被截断的误差定为</p><script type="math/tex; mode=display">\begin{equation} \begin{aligned} &\left|P S\left(J_{g}, n\right)-\ln \operatorname{det}\left(I+J_{g}\right)\right| \\ \leq &-d\left(\ln (1-\operatorname{Lip}(g))+\sum_{k=1}^{n} \frac{\operatorname{Lip}(g)^{k}}{k}\right) . \end{aligned} \end{equation}</script><p>尽管上面的结果给出了评估 loss 耗的误差范围，但在训练过程中，loss 梯度的误差引起了人们的极大兴趣。类似地，我们可以获得以下界限。 证明在 <a href="#th3proof">Appendix A</a> 中给出。</p><h4 id="Proof-Theorem-3"><a href="#Proof-Theorem-3" class="headerlink" title="Proof. (Theorem 3)"></a>Proof. (Theorem 3)</h4><p>我们首先注意到</p><script type="math/tex; mode=display">\begin{equation} \begin{aligned}\left|P S\left(J_{g}, n\right)-\operatorname{tr} \ln \left(J_{g}\right)\right| &=\left|\sum_{k=n+1}^{\infty}(-1)^{k+1} \frac{\operatorname{tr}\left(J_{g}^{k}\right)}{k}\right| \\ & \leq \sum_{k=n+1}^{\infty}\left|(-1)^{k+1} \frac{\operatorname{tr}\left(J_{g}^{k}\right)}{k}\right| \\ & \leq \sum_{k=n+1}^{\infty}\left|\frac{\operatorname{tr}\left(J_{g}^{k}\right)}{k}\right| \\ & \leq d \sum_{k=n+1}^{\infty} \frac{\operatorname{Lip}(g)^{k}}{k}, \end{aligned} \end{equation}</script><p>该不等式从下式得到<span id="estimation9"></span></p><script type="math/tex; mode=display">\begin{equation} \begin{aligned}\left|\operatorname{tr}\left(J^{k}\right)\right| & \leq\left|\sum_{i=d}^{d} \lambda_{i}\left(J^{k}\right)\right| \leq \sum_{i=d}^{d}\left|\lambda_{i}\left(J^{k}\right)\right| \leq d \rho\left(J^{k}\right) \\ & \leq d\left\|J^{k}\right\|_{2} \leq d\|J\|_{2}^{k} \leq d \operatorname{Lip}(g)^{k} \end{aligned} \end{equation}</script><p>我们注意到，全数列 $ \sum_{k=1}^{\infty} \frac{\operatorname{Lip}(g)^{k}}{k}=-\ln (1-\operatorname{Lip}(g)) $ 因此可以将近似误差限制为</p><script type="math/tex; mode=display">\begin{equation} \left|P S\left(J_{g}, n\right)-\operatorname{tr} \ln \left(J_{g}\right)\right| \leq-d\left(\ln (1-\operatorname{Lip}(g))+\sum_{k=1}^{n} \frac{\operatorname{Lip}(g)^{k}}{k}\right) \end{equation}</script><hr><h3 id="Theorem-4"><a href="#Theorem-4" class="headerlink" title="Theorem 4"></a>Theorem 4</h3><p>（梯度近似的收敛速度）。设 $ \theta \in \mathbb{R}^{p} $ 表示网络 $F$ 的参数，令 $g$ 表示残差函数，$J_g$ 表示雅可比行列式。此外，假设有界输入和具有 Lipschitz 导数的 Lipschitz 激活函数。然后，我们得出收敛速度</p><script type="math/tex; mode=display">\begin{equation} \left.\| \nabla_{\theta}\left(\ln \operatorname{det}\left(I+J_{g}\right)\right)-P S\left(J_{g}, n\right)\right) \|_{\infty}=\mathcal{O}\left(c^{n}\right) \end{equation}</script><p>其中 $ c:=\operatorname{Lip}(g) $，$n$ 为幂级数中使用的项数。</p><p>在实践中，仅需采用 5-10 项即可使每个维度小于 0.001 位的偏差，通常报告其精度高达 0.01 精度（ <a href="#appE">Appendix E</a> ）。</p><h4 id="Proof-Theorem-4"><a href="#Proof-Theorem-4" class="headerlink" title="Proof. (Theorem 4)"></a>Proof. (Theorem 4)</h4><p>首先，我们通过微分幂级数并使用跟踪算子的线性来导出。 我们获得</p><script type="math/tex; mode=display">\begin{equation} \begin{aligned} \frac{\partial}{\partial \theta_{i}} \ln \operatorname{det}\left(I+J_{g}(x, \theta)\right) &=\frac{\partial}{\partial \theta_{i}}\left(\sum_{k=1}^{\infty}(-1)^{k+1} \frac{\operatorname{tr}\left(J_{g}^{k}(x, \theta)\right)}{k}\right) \\ &=\operatorname{tr}\left(\sum_{k=1}^{\infty} \frac{k(-1)^{k+1}}{k} J_{g}^{k-1}(x, \theta) \frac{\partial\left(J_{g}(x, \theta)\right)}{\partial \theta_{i}}\right) \\ &=\operatorname{tr}\left(\sum_{k=0}^{\infty}(-1)^{k} J_{g}^{k}(x, \theta) \frac{\partial\left(J_{g}(x, \theta)\right)}{\partial \theta_{i}}\right) . \end{aligned} \end{equation}</script><p>通过定义 <script type="math/tex">\|\cdot\|_{\infty}</script></p><script type="math/tex; mode=display">\begin{equation} \left\|\nabla_{\theta} P S\left(J_{g}(\theta), \infty\right)-\nabla_{\theta} P S\left(J_{g}(\theta), n\right)\right\|_{\infty}=\max _{i=1, \ldots, p}\left|\frac{\partial}{\partial \theta_{i}} P S\left(J_{g}(\theta), \infty\right)-\frac{\partial}{\partial \theta_{i}} P S\left(J_{g}(\theta), n\right)\right| \end{equation}</script><p>这就是为什么我们从现在开始考虑任意 $i$。 这是</p><script type="math/tex; mode=display">\begin{equation} \begin{aligned}\left|\frac{\partial}{\partial \theta_{i}} P S\left(J_{g}(\theta), \infty\right)-\frac{\partial}{\partial \theta_{i}} P S\left(J_{g}(\theta), n\right)\right| &=\sum_{k=n+1}^{\infty}(-1)^{k} \operatorname{tr}\left(J_{g}^{k}(x, \theta) \frac{\partial\left(J_{g}(x, \theta)\right)}{\partial \theta_{i}}\right) \\ & \leq d \sum_{k=n+1}^{\infty} \operatorname{Lip}(g)^{K}\left\|\frac{\partial J_{g}(x, \theta)}{\partial \theta_{i}}\right\|_{2} \end{aligned} \end{equation}</script><p>这里我们使用了与 Theorem 3 的证明中中间<a href="#estimation9">估计</a>的相同论点。</p><p>为了束缚 $ \left|\frac{\partial J_{g}(x, \theta)}{\partial \theta_{i}}\right|_{2} $ 我们需要研究残差块的设计。我们假设收缩激活和元素激活函数（因此 $ \phi^{\prime}(\cdot)&lt;1 $）和残差块中的 $N$ 个线性层 $W_i$ 。 然后，我们可以将雅可比行列式写成矩阵乘积 </p><script type="math/tex; mode=display">\begin{equation} J_{g}(x, \theta)=W_{N}^{T} D_{N} \cdots W_{1}^{T} D_{1} \end{equation}</script><p>其中 $ D_{i}=\operatorname{diag}\left(\phi^{\prime}\left(z_{i-1}\right)\right) $ 具有预激活 $ z_{i-1} \in \mathbb{R}^{d} $</p><p>由于我们需要相对于权重 $ \theta_{i} $ 约束 Jacobian 的导数，因此必须进行两次反向传播（Drucke，1992）。通常$ \left|W_{i}^{T}\right|_{2},\left|D_{i}\right|_{2},\left|D_{i}^{*}\right|_{2}:=\left|\operatorname{diag}\left(\phi^{\prime \prime}\left(z_{i-1}\right)\right)\right|_{2},\left|\left(\frac{\partial W_{i}}{\partial \theta_{i}}\right)\right|_{2} $ 和 $ |x|_{2} $ 项出现在导数的约束内。 因此，为了约束 $ \left|\frac{\partial J_{g}(x, \theta)}{\partial \theta_{i}}\right|_{2} $ ，我们将前面的项约束如下</p><script type="math/tex; mode=display">\begin{equation} \begin{aligned}\left\|W_{i}^{T}\right\|_{2} & \leq \operatorname{Lip}(g) \\\left\|D_{i}\right\|_{2} & \leq \text { const } \\\left\|D_{i}^{*}\right\|_{2} & \leq \text { const } \\\|x\|_{2} & \leq \text { const } \\\left\|\left(\frac{\partial W_{i}}{\partial \theta_{i}}\right)^{T}\right\|_{2} & \leq\left\|W_{i}\right\|_{F}+s . \end{aligned} \end{equation}</script><p>特别地，上第二行归因于 Lipschitz 激活函数的假设，而上第三行归因于假设激活函数的 Lipschitz 导数。请注意，我们使用的是连续可区分的激活函数（因此，不是ReLU），其中这种假设适用于ELU，softplus和tanh等常见函数。此外上第四行通过假设有界输入和由于网络为 Lipschitz 而成立。为了理解约束上第五行，我们将 $s$ 表示为 $θ_i$ 的参数共享量。 例如，如果 $θ_i$ 是卷积核的入口，则 $ s=w * h $，具有 $w$ 空间宽度和 $h$ 空间高度。 然后</p><script type="math/tex; mode=display">\begin{equation} \left\|\left(\frac{\partial W_{i}}{\partial \theta_{i}}\right)^{T}\right\|_{2} \leq\left\|W_{i}\right\|_{F}+s \end{equation}</script><p>因为</p><script type="math/tex; mode=display">\begin{equation} \frac{\partial W_{l m}(x, \theta)}{\partial \theta_{i}}=\left\{\begin{array}{ll}1, & \text { if } W_{l m}=\theta_{i} \\ 0, & \text { else }\end{array}\right. \end{equation}</script><p>因此，随着出现在二阶导数 ||$ \frac{\partial J_{g}(x, \theta)}{\partial \theta_{i}}||_{2} $ 中的每个项有界，我们可以引入常数 $ a(g, \theta, x)&lt;\infty $，其取决于参数，$g$ 的实现和输入 $x$ 。 请注意，我们没有给出 ||$ \frac{\partial J_{g}(x, \theta)}{\partial \theta_{i}} |_{2} $ 的确切界限，因为我们仅对存在这样的界限感兴趣，以便证明权利要求的收敛性。</p><hr><h2 id="4-Related-Work"><a href="#4-Related-Work" class="headerlink" title="4. Related Work"></a>4. Related Work</h2><h3 id="4-1-Reversible-Architectures"><a href="#4-1-Reversible-Architectures" class="headerlink" title="4.1. Reversible Architectures"></a>4.1. Reversible Architectures</h3><p>我们将重点放在具有高效逆计算的可逆架构上，即NICE（Dinh，2014），iRevNet（Jacobsen，2018），Real-NVP（Dinh，2017），Glow（Kingma，2018）和 Neural ODEs（Chen，2018）及其随机密度估计量FFJORD（Grathwohl，2019）。 下表总结了不同可逆网络之间的比较。</p><p><img src="assets/image-20210526183306977.png" alt="image-20210526183306977"></p><p>Table 1.  Non-volume preserving 是指允许收缩和膨胀（contraction and expansions）的能力，exact likelihood 是指精确计算变量变化。unbiased estimator 是对数行列式的随机近似值，见 <a href="#sec32">Sec. 3.2</a> 。</p><p>NICE，i-RevNet，Real-NVP 和 Glow 中使用的维度分解方法可以进行正向和逆向映射分析。但是，此限制要求在Glow 中引入其他步骤，例如可逆 1×1 卷积（Kingma，2018）。 这些 1×1 卷积需要在数值上进行求逆，从而使Glow 完全不可解析地求逆。 相比之下，i-ResNet 可以看作是一种中间方法，其中前向映射是通过分析给出的，而逆向可以通过<strong>定点迭代</strong>来计算。</p><p>此外，i-ResNet 块具有正向和逆向的 Lipschitz 边界（ <a href="#lem2">Lemma2</a> ），而其他方法在设计上不具有此属性。 因此，对于诸如逆向问题（Ardizzone，2019）或基于不变性的对抗性漏洞（Jacobsen，2019）等对稳定性至关重要的应用而言，i-ResNets 可能是一个有趣的途径。</p><p>Neural ODEs（Chen，2018）允许类似于 i-ResNets 的  free-form dynamics，这意味着只要输入和输出<strong>维度相同</strong>，就可以使用任何体系结构。为了获得离散的正向和逆向动力学，NODE 依赖于自适应 ODE 求解器，从而可以在精度与速度之间进行权衡。然而，对于诸如高分辨率图像之类的非常高的输入维度的可扩展性仍然不清楚。</p><hr><h3 id="4-2-Ordinary-Differential-Equations"><a href="#4-2-Ordinary-Differential-Equations" class="headerlink" title="4.2. Ordinary Differential Equations"></a>4.2. Ordinary Differential Equations</h3><p>由于 ResNet 和 Euler 离散化的相似性，i-ResNet 和 ODE 之间存在许多联系，我们将在本节中进行回顾。</p><p><strong>Relationship of i-ResNets to Neural ODEs:</strong></p><p>将深度网络视为随时间变化的动态的观点提供了两种基本的学习方法</p><p>1）使用诸如 ResNets 的<strong>离散</strong>体系结构直接学习动力学（Haber，2018; Ruthotto，2018; Lu，2017; Ciccone，2018）。 </p><p>2）通过使用神经网络对 ODE 进行<strong>参数化</strong>来间接学习动力学（Chen, 2018; Grathwohl, 2019）等。</p><p>固定 ResNet $ F_{\theta} $ 的动力学 $ x(t) $ 仅在对应于每个块 $ g \theta_{t} $ 的时间点 $ t_{i} $ 定义。但是，可以使用<strong>时间上的线性插值</strong>来生成连续动态。见 <a href="#fig1">Fig. 1</a> ，其中显示了线性内插可逆 ResNet 的连续动力学与标准ResNet的连续动力学。可逆ResNets 沿着连续路径是<strong>双射</strong>的，而常规 ResNets 可能会导致<strong>交叉或合并</strong>路径。另一方面，直接学习 ODE 的间接方法是基于 ODE 求解器来<strong>适应离散化</strong>，但是与 i-ResNet 相比，它没有固定的计算预算。</p><p><strong>Stability of ODEs:</strong></p><p>有两种主要方法可以研究 ODE 的稳定性：</p><p>1）$ t \rightarrow \infty $ 的行为</p><p>2）有限时间间隔 $ [0, T] $ 的Lipschitz 稳定性。  </p><p>基于时间不变动力学 $ f(x(t)) $ ，(Ciccone，2018) 使用<strong>反对称层</strong>构造了渐近稳定的 ResNet，使得 $ \operatorname{Re}\left(\lambda\left(J_{x}\right)\right)&lt;0 $ ，其中 $ \operatorname{Re}(\lambda(\cdot)) $ 表示特征值的实部，$ \rho(\cdot) $ 为谱半径，$ J_{x} g $ 为点 $x$ 处的雅可比行列式。通过 Gershgorin circle theorem(<strong>该定理就是用来估计矩阵的特征值的值范围</strong>) 投影权重，他们进一步满足 $ \rho\left(J_{x} g\right)&lt;1 $，从而产生渐近稳定的ResNet，并且各层<strong>共享权重</strong>。 </p><p>另一方面（Haber，2018; Ruthotto，2018）考虑了对应于标准ResNet的时间相关动力学 $ f(x(t), \theta(t)) $ 。通过使用<strong>反对称的层和权重的投影</strong>来保证稳定性。</p><p>相反，对于Lipschitz 连续动力学，$ [0, T] $ 上的初值问题是恰当的（Ascher，2008）。因此，$ \operatorname{Lip}(f)&lt;1 $ 的可逆 ResNet 可以理解为步长 $h = 1$ 的 ODE 的稳定器，而<strong>不受反对称层的限制</strong>。</p><hr><h3 id="4-3-Spectral-Sum-Approximations"><a href="#4-3-Spectral-Sum-Approximations" class="headerlink" title="4.3. Spectral Sum Approximations"></a>4.3. Spectral Sum Approximations</h3><p>谱总和逼近</p><p>对于许多机器学习问题（例如高斯过程回归）（Dong，2017），像对数行列式这样的谱总和的逼近引起了广泛的兴趣。</p><p>除此之外，使用类似于我们的方法的对数行列式的泰勒逼近（Boutsidis，2017），或切比雪夫多项式方法（Han，2016）。</p><p>（Boutsidis，2017）针对对称正定矩阵给出了随机迹估计和（通过截断幂级数的进行估计的）误差范围。 但是，$ I+J_{g} $ 不是对称的，因此，此处的分析不适用。</p><p>最近，有人提出了对称正定矩阵的无偏估计（Adams，2018）和无偏梯度估计（Hanetal，2018）。 </p><p>此外，切比雪夫多项式已用于逼近深度神经网络中的雅可比对数行列式的以进行密度匹配和 GAN 的似然评估（Ramesh和LeCun，2018）。</p><hr><h2 id="5-Experiments"><a href="#5-Experiments" class="headerlink" title="5. Experiments"></a>5. Experiments</h2><p>我们完成了对 i-ResNets 的全面实验调查。 首先，我们用数值方法验证 i-ResNets 的可逆性。 然后，我们在许多常见的图像分类数据集上研究了它们的判别能力。此外，我们将 i-ResNets 与其他可逆网络的判别性能进行了比较。 最后，我们研究如何使用 i-ResNets 定义生成模型。</p><hr><h3 id="5-1-Validating-Invertibility-and-Classification"><a href="#5-1-Validating-Invertibility-and-Classification" class="headerlink" title="5.1. Validating Invertibility and Classification"></a>5.1. Validating Invertibility and Classification</h3><p>为了将 i-ResNets 与标准 ResNet 架构的<strong>判别性能</strong>和<strong>可逆性</strong>进行比较，我们在 CIFAR10，CIFAR100 和 MNIST 上训练了这两种模型。  </p><p>CIFAR 和 MNIST 模型的模型分别具有 <code>54</code> 和 <code>21</code> 个残差块，我们对所有其他超参数使用相同的设置。为了确保双射性，我们将  <code>strided downsampling</code> 替换为 <code>invertible downsampling</code> 操作（Jacobsen，2018），有关训练和网络架构的详细信息，见 <a href="#appc2">Appendix C.2</a> 。 </p><p>我们通过填充零将输入通道的数量增加到16。 这与在模型的输入端使用标准卷积层将数据投影到更高维空间的标准做法类似，但是这种映射是可逆的。为了获得数值逆，我们为每个块应用了100个定点迭代（ <a href="#eq1">Eq. 1</a>）。 </p><p>选择此数字是为了确保对 vanilla ResNet 的不良重建（ <a href="#fig3">Fig. 3</a> ）不是由于使用了太少的迭代而引起的。在实践中，迭代次数就足够少了，如 <a href="#appd">Appendix D</a> 中分析的重建误差和迭代次数之间的权衡所示。</p><p><img src="assets/image-20210526192356031.png" alt="image-20210526192356031"></p><p><strong>Fig. 3</strong> 原始图像（top）和来自 <code>c=0.9</code> 的i-ResNet（middle）和具有相同体系结构的标准ResNet（bottom）的重构，表明在没有 Lipschitz 约束的情况下，定点迭代无法恢复输入。</p><p>基线预激活 ResNet-164 的分类和重建结果，ResNet-164是具有类似 iResNets 的架构，没有Lipschitz 约束的ResNet（表示为 vanilla）<a href="#tab2">Table. 2</a> 中显示了五个具有不同光谱归一化系数的可逆ResNet。结果说明，对于较大的分层Lipschitz常数c设置，我们提出的可逆ResNet在分类性能方面与基线具有竞争性，而可证明是可逆的 。当应用非常保守的归一化（小c）时，所有测试的数据集的分类误差都会更高。</p><p><img src="assets/image-20210526192710447.png" alt="image-20210526192710447"></p><p><strong>Table. 2</strong> 通过系数 c 将 i-ResNet 与具有不同 Lipschitz 约束的类似深度和宽度的 ResNet-164 基线架构进行比较。Vanilla 与 i-ResNet 共享相同的体系结构，没有 Lipschitz 约束。</p><p>为了证明我们的归一化方案是有效的并且标准的 ResNet 通常不是可逆的，我们使用 <a href="#algo1">Algorithm 1</a> 从每个模型的特征重构输入。有趣的是，我们的分析还揭示了在 MNIST 上训练后不受约束的 ResNet 是可逆的（<a href="#fig7">Fig 7.</a> in Appendix B），而在 <code>CIFAR10/100</code> 上则不是。此外，我们发现在使用 <code>CIFAR10</code> 进行训练后，带有和不带有BatchNorm 的 ResNet 都是不可逆的，这也可以从（<a href="#fig6">Fig 6.</a> in Appendix B）中的奇异值图看出。4个具有1个谱标准化迭代的 GeForce GTX 1080 GPU 的运行时间为 0.5 秒，用于具有128个样本的批处理的正向和反向传递，而在不进行频谱归一化的情况下则为 0.2 秒。有关运行时的详细信息，请参见C.1节（附录）。</p><p>重建误差迅速衰减，并且经过 5-20 次迭代后误差是无法察觉的，这是前向传播的 5-20 倍，并且对应于重建 100 张 <code>CIFAR10</code> 图像所需的 0.15-0.75 秒。</p><p>即使对于最大的标准化系数，计算逆函数也很快，但是在更强的归一化条件下，计算逆函数变得更快。将谱标准化系数降低 0.2 时，完全收敛所需的迭代次数大约减少了一半，<a href="#fig8">Fig 8.</a> in Appendix D。 我们还运行了一个 i-RevNet（Jacobsen，2018），它具有与 ResNet164 相当的超参数，并且其性能与 ResNet-164 相当，为5.6％。但是请注意，i-RevNets 像 NICE（Dinh，2014）一样，是体积节省的，因此不太适合生成模型。</p><p>总而言之，我们观察到没有附加约束来实现可逆性是不可能的，但是很难预测网络是否将具有此属性。在我们提出的模型中，我们可以保证逆的存在而不会显着损害分类性能。</p><hr><h3 id="5-2-Comparison-with-Other-Invertible-Architectures"><a href="#5-2-Comparison-with-Other-Invertible-Architectures" class="headerlink" title="5.2. Comparison with Other Invertible Architectures"></a>5.2. Comparison with Other Invertible Architectures</h3><p>在本节中，我们将 i-ResNet 分类器与 state-of-the-art  invertible flow-based 模型 Glow 进行比较。我们采用（Kingma，2018）的实现并对其进行修改以对 <code>CIFAR10</code> 图像进行分类（不包含生成模型组件）。 我们创建了一个 i-ResNet，其结构与 CIFAR10 上的默认 Glow 模型（表示为 i-ResNet Glow 样式）尽可能接近，并将其与 Glow 的两个变体进行比较，其中一个变体使用了学习的（1×1卷积） 和 affine block 结构，另一个变体使用逆向排序（Real-NVP）和 additive block 结构。</p><p>该实验的结果可以在 <a href="#tab3">Table 3.</a> 中找到。我们可以看到 i-ResNets 在此区分性任务上的性能优于 Glow 基础的所有版本，即使使网络深度和宽度适应 Glow 的情况也是如此。 这表明，与 Glow 相比，i-ResNets 在其块结构中对于区分性任务具有<strong>更合适的感应偏差</strong>(suitable inductive bias)。</p><p><img src="assets/image-20210526231642665.png" alt="image-20210526231642665"></p><p><strong>Table 3.</strong> 将CIFAR10分类结果与最新流 Glow 作为分类器进行比较。 我们比较了 Glow 的两个版本以及 i-ResNet 架构，它们的层和通道数与 Glow 尽可能相似，称为“i-ResNet, Glow-Style”。</p><p>我们还发现，与这些其他模型相比，i-ResNets 的训练要容易得多。我们能够使用 SGD 训练动量和学习率为 0.1 的i-ResNets，而我们测试的所有 Glow 版本都需要 Adam 或Adamax（Kingma，2014）和小得多的学习率来避免发散。</p><hr><h3 id="5-3-Generative-Modeling"><a href="#5-3-Generative-Modeling" class="headerlink" title="5.3. Generative Modeling"></a>5.3. Generative Modeling</h3><p>我们进行了许多实验，以验证 iResNets 在构建生成模型中的实用性。 首先，我们在简单的二维数据集上比较 i-ResNet Flows 和 Glow（Kingma，2018）。<a href="#fig2">Fig 2.</a> 定性地显示了由 Glow 模型获得的密度，该模型具有 100 个耦合层和 100 个可逆线性变换。我们将其与 i-ResNet 进行比较，在 i-ResNet 中，耦合层被具有相同数量参数的<strong>可逆残差块</strong>替换，可逆线性变换被 <strong>actnorm</strong>替换（Kingma，2018）。 这导致 i-ResNet 模型的参数略少，同时保持了相等的层数。在本实验中，由于数据是二维的，因此我们使用蛮力计算的对数行列式训练 i-ResNets。</p><p>我们发现，i-ResNets 能够更准确地<strong>适应这些简单的密度</strong>。 如（Grathwohl, 2019）所述 ，我们认为这是由于我们的<strong>模型能够避免划分维度</strong>。(avoid partitioning dimensions)</p><p>接下来，我们将评估 MNIST 和 CIFAR10 上的图像的作为生成模型的 i-ResNets。我们的模型由多个 i-ResNet 块组成，然后是可逆向下采样或“压缩”尺寸以对空间尺寸进行向下采样。我们使用类似于（RealNvp;Glow）的多尺度体系结构。在这些实验中，我们使用对数行列式逼近训练i-ResNet，<a href="#algo2">Algorithm 2</a> 。完整的体系结构，实验和评估的详细信息，请参阅 <a href="#appc3">Appendix C.3</a> 我们的 CIFAR10 模型的示例如 <a href="#fig5">Fig 5.</a> 所示，而我们的 MNIST 模型的示例可以在 <a href="#appf">Appendix F</a> 中找到。</p><p><img src="assets/image-20210526232348670.png" alt="image-20210526232348670"></p><p><strong>Fig 5.</strong> CIFAR10来自我们 <code>i-ResNet flow</code> 的样本。 更多样本可以在 <a href="#appf">Appendix F</a> 中找到。</p><p>与分类模型相比，使用 5 个 series terms 的对数行列式逼近将计算时间大致增加了 4 倍。我们的对数行列式估计器的偏差和方差如  <a href="#fig4">Fig 4.</a>  所示。</p><p><img src="assets/image-20210526232628797.png" alt="image-20210526232628797"></p><p><strong>Fig 4.</strong> 随着幂级数项的增加，我们的对数行列式估计器的偏差和标准偏差。差异归因于<strong>随机迹估计器</strong>。</p><p>结果和与其他生成模型的比较可以在  <a href="#tab4">Table 4.</a>  中找到。尽管我们的模型不如 Glow 和 FFJORD 表现出色，但令人惊讶的是 ResNets 只需进行很少的修改就可以创建与这些高度工程化的模型竞争的生成模型 。我们认为，性能差异主要是由于我们使用了有偏对数行列式估计器，并且使用无偏方法（Han，2018）可以帮助弥补这一差距。</p><p><img src="assets/image-20210526232452041.png" alt="image-20210526232452041"></p><p><strong>Table 4.</strong> MNIST和CIFAR10 bits/dim 结果。$†$ 使用 ZCA 预处理，因此结果无法直接比较。</p><hr><h2 id="6-Other-Applications"><a href="#6-Other-Applications" class="headerlink" title="6. Other Applications"></a>6. Other Applications</h2><p>在许多应用中，次要的无监督学习或生成建模目标是与主要的判别任务结合起来制定的。  i-ResNets 在这里具有吸引力，因为它们在区分性任务和生成性任务上都设法取得了出色的性能。 我们总结了一些应用领域，以强调 i-ResNets 有望解决的任务繁多：</p><ul><li>混合密度和判别模型，用于联合分类和检测或公平应用（Nalisnick et al., 2018; Louizos et al., 2016)</li><li>下游任务的无监督学习 (Hjelm et al., 2019; Van Den Oord et al., 2018)</li><li>从几个标记示例中进行半监督学习 (Oliver et al., 2018; Kingma et al., 2014)</li><li>用混合回归和生成损失解决逆问题 (Ardizzone et al., 2019)</li><li>基于似然性生成模型的对抗鲁棒性 (Schott et al., 2019; Jacobsen et al., 2019)</li></ul><p>最后，在i-ResNet的各层上的 <strong>Lipschitz 边界</strong>可以帮助优化的<strong>梯度稳定性</strong>以及对抗性鲁棒性，这似乎是有道理的。</p><h2 id="7-Conclusions"><a href="#7-Conclusions" class="headerlink" title="7. Conclusions"></a>7. Conclusions</h2><p>我们引入了一种新的体系结构i-ResNets，它允许自由形式的层体系结构，同时仍然提供易于处理的密度估计。雅可比行列式的无限制形式允许通过残差块进行扩展和收缩，而基于分区的模型（Dinh，2014； 2017； Kingma，2018）必须包括仿射块和缩放层，以实现非体积保持。</p><p>在未来的工作中仍有一些挑战有待解决。首先，我们对数行列式的估计是有偏的。 但是，最近在为对数行列式建立无偏估计量方面取得了进展（Han，2018），我们认为这可以改善生成模型的性能。其次，学习和设计具有 <strong>Lipschitz 约束</strong>的网络具有挑战性。例如，我们需要约束块中的每个线性层，而不是能够直接控制块的 Lipschitz 常数，请参见（Anil，2018） 提出了一种解决该问题的有前途的方法。</p><hr><h2 id="Acknowledgments"><a href="#Acknowledgments" class="headerlink" title="Acknowledgments"></a>Acknowledgments</h2><hr><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><h2 id="A-Additional-Lemmas-and-Proofs"><a href="#A-Additional-Lemmas-and-Proofs" class="headerlink" title="A. Additional Lemmas and Proofs"></a>A. Additional Lemmas and Proofs</h2><p><strong>Proof. (Theorem 3)</strong><span id="th3proof"></span></p><p>我们首先注意到</p><script type="math/tex; mode=display">\begin{equation} \begin{aligned}\left|P S\left(J_{g}, n\right)-\operatorname{tr} \ln \left(J_{g}\right)\right| &=\left|\sum_{k=n+1}^{\infty}(-1)^{k+1} \frac{\operatorname{tr}\left(J_{g}^{k}\right)}{k}\right| \\ & \leq \sum_{k=n+1}^{\infty}\left|(-1)^{k+1} \frac{\operatorname{tr}\left(J_{g}^{k}\right)}{k}\right| \\ & \leq \sum_{k=n+1}^{\infty}\left|\frac{\operatorname{tr}\left(J_{g}^{k}\right)}{k}\right| \\ & \leq d \sum_{k=n+1}^{\infty} \frac{\operatorname{Lip}(g)^{k}}{k} \end{aligned} \end{equation}</script><p>且上不等式满足：</p><script type="math/tex; mode=display">\begin{equation} \begin{aligned}\left|\operatorname{tr}\left(J^{k}\right)\right| & \leq\left|\sum_{i=d}^{d} \lambda_{i}\left(J^{k}\right)\right| \leq \sum_{i=d}^{d}\left|\lambda_{i}\left(J^{k}\right)\right| \leq d \rho\left(J^{k}\right) \\ & \leq d\left\|J^{k}\right\|_{2} \leq d\|J\|_{2}^{k} \leq d \operatorname{Lip}(g)^{k} \end{aligned} \end{equation}</script><p>我们注意到整个序列 $ \sum_{k=1}^{\infty} \frac{\operatorname{Lip}(g)^{k}}{k}=-\ln (1-\operatorname{Lip}(g)) $ ，因此我们可以将近似误差限制为</p><script type="math/tex; mode=display">\begin{equation} \left|P S\left(J_{g}, n\right)-\operatorname{tr} \ln \left(J_{g}\right)\right| \leq-d\left(\ln (1-\operatorname{Lip}(g))+\sum_{k=1}^{n} \frac{\operatorname{Lip}(g)^{k}}{k}\right) \end{equation}</script><hr><h3 id="Lemma-6"><a href="#Lemma-6" class="headerlink" title="Lemma 6"></a>Lemma 6<span id="lem6"></span></h3><p>（残差层的雅可比行列式为正行列式）。令 $ F(x)=(I+g(\cdot))(x) $ 表示残差层，且 $ J_{F}(x)=I+J_{g}(x) $ 表示其在 $ x \in \mathbb{R}^{d} $ 的雅可比行列。如果 $ \operatorname{Lip}(g)&lt;1 $，则它对所有 $x$ 都保持 $ J_{F}(x) $ 的 $λ_i$ 为正，因此</p><script type="math/tex; mode=display">\begin{equation} \left|\operatorname{det}\left[J_{F}(x)\right]\right|=\operatorname{det}\left[J_{F}(x)\right] \end{equation}</script><p>其中 $λ_i$ 表示特征值。</p><p><strong>Proof. (Lemma 6)</strong></p><p>首先，由于 $ \operatorname{Lip}(g)&lt;1 $，因此对于所有的 $x$，我们有 $ \lambda_{i}\left(J_{F}\right)=\lambda_{i}\left(J_{g}\right)+1 $ 和 $ \left|J_{g}(x)\right|_{2}&lt;1 $。</p><p>由于谱半径 $ \rho\left(J_{g}\right) \leq\left|J_{g}\right|_{2} $，所以 $ \left|\lambda_{i}\left(J_{g}\right)\right|&lt;1 $ 。</p><p>因此有 $ \operatorname{Re}\left(\lambda_{i}\left(J_{F}\right)\right)&gt;0 $，则得到 $ \operatorname{det} J_{F}=\prod_{i}\left(\lambda_{i}\left(J_{g}\right)+1\right)&gt;0 $。</p><hr><h3 id="Lemma-7"><a href="#Lemma-7" class="headerlink" title="Lemma 7"></a>Lemma 7<span id="lem7"></span></h3><p>（invertible ResNet 的对数行列式的上下界）。令 $ F_{\theta}: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d} $ 且 $ F_{\theta}= \left(F_{\theta}^{1} \circ \ldots \circ F_{\theta}^{T}\right) $ 表示具有块 $ F_{\theta}^{t}=I+g_{\theta_{t}} $ 的 invertible ResNet。 然后，我们可以获得以下界限</p><script type="math/tex; mode=display">\begin{equation} d \sum_{t=1}^{T} \ln \left(1-\operatorname{Lip}\left(g_{t}\right)\right) \leq \ln \left|\operatorname{det} J_{F}(x)\right|\\ d \sum_{t=1}^{T} \ln \left(1+\operatorname{Lip}\left(g_{t}\right)\right) \geq \ln \left|\operatorname{det} J_{F}(x)\right| \end{equation}</script><p>对于所有 $ x \in \mathbb{R}^{d} $ 都满足上式</p><p><strong>Proof. (Lemma 7)</strong></p><p>首先，各层的总和归因于函数组成，因为 $ J_{F}(x)=\prod_{t} J_{F^{t}}(x) $ 并且</p><script type="math/tex; mode=display">\begin{equation} \ln \left|\operatorname{det} J_{F}(x)\right|=\ln \left(\prod_{t=1}^{T} \operatorname{det} J_{F^{t}}(x)\right)=\sum_{t=1}^{T} \ln \operatorname{det} J_{F^{t}}(x) \end{equation}</script><p>在这里我们使用了 <a href="#lem6">Lemma 6</a> 行列式大于 0 的性质。此外，请注意，</p><script type="math/tex; mode=display">\begin{equation} \sigma_{d}(A)^{d} \leq \prod_{i} \sigma_{i}(A)=|\operatorname{det} A| \leq \sigma_{1}(A)^{d} \end{equation}</script><p>对于矩阵 $A$ ，最大奇异值为 $\sigma_{1}$ 和最小奇异值为 $\sigma_{d}$。 此外，我们有 <a href="#lem2">Lemma 2</a> 得出的 $ \sigma_{i}\left(J_{F^{t}}\right) \leq\left(1+\operatorname{Lip}\left(g_{t}\right)\right) $ 和 $ \sigma_{d}\left(J_{F^{t}}\right) \leq\left(1-\operatorname{Lip}\left(g_{t}\right)\right) $。将其插入并最终应用对数规则得出要求的范围。</p><hr><h2 id="B-Verification-of-Invertibility"><a href="#B-Verification-of-Invertibility" class="headerlink" title="B. Verification of Invertibility"></a>B. Verification of Invertibility</h2><p><strong>Inveritibility of Learned Mappings</strong> </p><p>在此实验中，我们训练具有各种分层 Lipschitz 系数（$ c \in\{.3, .5, .7, .9\} $）的标准 ResNets 和 i-ResNets。 训练后，我们根据（Sedghi，2019）的方法，通过计算每个线性映射的最大奇异值，检查每一层学习到的变换。 可以清楚地看到（Figure 6 left），标准模型和 BatchNorm 模型具有许多高于 1 的奇异值，从而使其残差连接不可逆。相反，在 i-ResNet 模型（Figure 6 right）中，所有奇异值都小于1（并大致等于 $c$ ），表明它们的残差连接是可逆的。</p><p><img src="assets/image-20210526225907790.png" alt="image-20210526225907790"></p><p><strong>Fig 6.</strong> Cifar10 上各种经过训练的 ResNet 的每层卷积算子的最大奇异值。left：Vanilla和Batchnorm ResNet 的奇异值。 基线 ResNet 很可能是不可逆的，因为大约三分之二的层的奇异值都在1之上，这使得这些块没有约束力。right：我们的4个谱标准化 ResNet 的奇异值。 正则化是有效的，并且在每种情况下，单个 ResNet 块都保持收缩。</p><p><strong>Computing Inverses with Fixed-Point Iteration</strong></p><p>在这里，我们使用<strong>不动点迭代</strong>对训练模型中的逆进行数值计算， <a href="#algo1">Algorithm 1</a> 。我们使用 100 次迭代对每个残差连接进行求逆（以确保收敛）。 我们看到，使用此方法可以反转 i-ResNets，而使用标准 ResNets 不能保证（Figure 7 top）。有趣的是，在MNIST上，我们发现在MNIST上进行训练后，标准ResNets确实是可逆的（Figure 7 bottom）。</p><p><img src="assets/image-20210526230310002.png" alt="image-20210526230310002"></p><p><strong>Fig 7.</strong> 原始图像（上），$c = 0.9$ 的i-ResNets（中）和从Vanilla中重建的图像（下）。 出人意料的是，即使没有显式强制执行 Lipschitz 常数，<code>MNIST</code> 重建对于这两个模型也几乎是精确的。但是，在 <code>CIFAR10</code> 上，对于原始的ResNet而言，重建完全失败，但是对于我们提出的网络，定性和定量是精确的。</p><hr><h2 id="C-Experimental-Details"><a href="#C-Experimental-Details" class="headerlink" title="C. Experimental Details"></a>C. Experimental Details</h2><h3 id="C-2-Classification"><a href="#C-2-Classification" class="headerlink" title="C.2. Classification "></a>C.2. Classification <span id="appc2"></span></h3><p><strong>Architecture</strong> </p><p>我们使用具有 <code>39</code> 个卷积瓶颈块的预激活 ResNet，每个卷积瓶颈块具有 <code>3</code> 个卷积层，内核大小分别为 <code>3x3</code>、<code>1x1</code>、<code>3x3</code>。 所有模型都使用 <code>ELU</code> 非线性（Clevert，2015）。 </p><p>在批量归一化方面，我们在每个<strong>非线性前</strong>应用 BN，在<strong>可逆</strong>模型中，我们在每个<strong>残差块前</strong>使用 <code>ActNorm</code>（Kingma，2018）。</p><p>该网络在 <code>13</code> 和 <code>26</code> 个块之后有 <code>2</code> 个下采样阶段，其中使用<strong>维度压缩</strong>操作来降低空间分辨率。 这在每个方向上将 spatial dimension 减小了 2 倍，同时将 channels 数增加了 4 倍。 </p><p>所有模型都将数据转换为 <code>8x8x256</code> 张量，我们将 BN，a nonlinearity 和 average pooling 应用于256-维向量。在此表示法之上使用<strong>线性分类器</strong>。</p><p><strong>Injective Padding</strong> 单射填充</p><p>由于我们的可逆模型无法<strong>增加其潜在表示的维数</strong>，因此我们使用<strong>单射填充</strong>（Jacobsen，2018），该方法将 0 的通道连接到输入，从而增加了转换张量的大小。</p><p>这与在模型输入端使用非 ResNet 卷积将<strong>数据投影到高维空间</strong>的标准做法相类似，但是这种映射是可逆的。</p><p>我们将 <code>13</code> 个通道的 <code>0</code> 加到所有测试的模型中，因此第一个残差块的输入是张量为 <code>32x32x16</code> 的张量。我们尝试删除此步骤，但发现对于我们的 CIFAR10 模型，其精度降低了约 <code>2%</code>。</p><p><strong>Training</strong></p><p>以 <code>momentum SGD</code> 和权重衰减 <code>5e-4</code> 训练 <code>200</code>个 epoch。 学习率设置为 <code>0.1</code>，并在 <code>60</code>、<code>120</code> 和 <code>160</code> 个 epoch 后衰减 <code>0.2</code> 倍。 </p><p>对于数据增强，我们在训练过程中对 <code>MNIST</code> 应用 <strong>upt随机偏移</strong> 到两个像素，对<code>CIFAR(10/100)</code> 应用 <strong>shift /随机水平翻转</strong>。 </p><p>通过减去平均值并除以训练集的标准差将将<code>MNIST</code> 和 <code>CIFAR(10/100)</code>  的输入归一化为 <code>[-0.5,0.5]</code>。</p><hr><h3 id="C-3-Generative-Modeling"><a href="#C-3-Generative-Modeling" class="headerlink" title="C.3. Generative Modeling"></a>C.3. Generative Modeling</h3><p><span id="appC3"></span></p><p><strong>Toy Densities</strong></p><p>我们使用了 100 个残差块，其中每个残差连接是一个具有状态大小 2-64-64-64-2 的多层感知器和 ELU 非线性(Clevert，2015)。我们在每次残差块之后都使用 ActNorm (Glow) 。通过在训练期间构造完整的雅可比矩阵来精确计算对数密度的变化可视化。</p><p><strong>MNIST and CIFAR</strong></p><p>我们的生成模型的结构与Glow非常相似。该模型包括 “尺度块” 是以不同空间分辨率运行的 i-ResNet 块组。在每个 “尺度块” 之后，分开最后，我们执行压缩操作，将每个维度的空间分辨率降低 2 倍，并进行乘法运算通道数乘以 4 (可逆下采样)。</p><p>我们的 MNIST 和 CIFAR10 型号有三个尺度块。每个尺度块有 32 个 i-ResNet 块。每个 i-ResNet 块由 <code>3 × 3</code>、<code>1 × 1</code>、<code>3 × 3</code> 滤波器的三个卷积组成，其间具有 ELU 非线性。每个卷积层在 MNIST 模型中有 32 个滤波器，在CIFAR10 模型中有 512 个滤波器。</p><p>我们使用 Adamax (Kingma，2014)优化器进行了200个时期的训练，学习率为0.003。全程培训我们使用幂级数近似( <a href="#eq4">Eq. 4</a>  )估计 <a href="#eq3">Eq. 3</a>  中的对数行列式，其中十项用于 MNIST 模式和 CIFAR10 模式的 5 个术语。</p><p><strong>Evaluation</strong></p><p>在评估过程中，我们使用第3.3节中给出的界限来确定需要给出的术语数量偏差小于0 . 0001比特/秒的估计。然后，我们对来自哈钦森估计器的足够多的样本进行平均标准误差小于. 001 bit/dim，因此我们可以安全地报告我们模型的bit/dim精度，误差不超过.0002.</p><p><strong>Choice of Nonlinearity</strong></p><p>求对数行列式估计量的微分需要我们计算神经网络的输出。如果我们使用具有不连续导数的非线性，那么这些值是在某些地区没有定义。这会导致不稳定的优化。为了保证优化所需的数量总是存在的，我们建议使用具有连续导数的非线性，例如ELU (Clevert等人，2015)或softplus。在我们所有的实验中，我们都使用ELU。</p><hr><h2 id="D-Fixed-Point-Iteration-Analysis"><a href="#D-Fixed-Point-Iteration-Analysis" class="headerlink" title="D. Fixed Point Iteration Analysis"></a>D. Fixed Point Iteration Analysis</h2><p><img src="assets/image-20210526231105911.png" alt="image-20210526231105911"></p><p><strong>Fig 8.</strong> 在不动点迭代次数与重构误差（对数标度）之间进行权衡，以计算（在CIFAR10上）训练后的可逆ResNets的不同归一化系数的反函数。 重建误差迅速衰减。5-20 次迭代分别足以获得视觉上完美的重建效果。请注意，一次迭代对应于一次 <code>foward pass</code> 的时间，因此逆向比推理慢大约 5 到 20 倍。 对于一批具有 5-20 次迭代的 100 张CIFAR10图像，这对应于 0.15-0.75 秒的重建时间，而经过 100 次迭代，则对应于 4.3 秒的重建时间。</p><h2 id="E-Evaluating-the-Bias-of-Our-Log-determinant-Estimator"><a href="#E-Evaluating-the-Bias-of-Our-Log-determinant-Estimator" class="headerlink" title="E. Evaluating the Bias of Our Log-determinant Estimator"></a>E. Evaluating the Bias of Our Log-determinant Estimator</h2><p>在这里，我们在数值上评估用于训练我们的生成模型的对数行列式估计量的偏差（ <a href="#eq4">Eq.4</a> ）。</p><p>当幂级数中的项数增加时，我们将真实值（通过蛮力计算）与估算器的均值和标准差进行比较。 在 10 个 terms 下，估算器的偏差可以忽略，而在 20 个 terms 后，估算器的偏差在数值上为 0。这是超过 1000 个测试示例的平均值。</p><p><img src="assets/image-20210526182953611.png" alt="image-20210526182953611"></p><p><strong>Fig. 9</strong> 当改变幂级数中使用的项数时，对数行列式估计器的近似误差收敛。该差异归因于随机迹估计器。</p><h2 id="F-Additional-Samples-of-i-ResNet-flow"><a href="#F-Additional-Samples-of-i-ResNet-flow" class="headerlink" title="F. Additional Samples of i-ResNet flow"></a>F. Additional Samples of i-ResNet flow</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>G_INF</title>
      <link href="/2022/03/28/G-INF/"/>
      <url>/2022/03/28/G-INF/</url>
      
        <content type="html"><![CDATA[<h1 id="Implicit-Normalizing-Flows"><a href="#Implicit-Normalizing-Flows" class="headerlink" title="Implicit Normalizing Flows"></a>Implicit Normalizing Flows</h1><p>ICLR2021_Spot</p><hr><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>归一化流通过<strong>显式可逆变换</strong>(explicit invertible transformation) $ \mathbf{z}=f(\mathbf{x}) $ 定义概率分布。 在这项工作中，我们提出了<strong>隐式归一化流</strong>（implicit normalizing flows, ImpFlows），它通过允许由方程 $ F(\mathbf{z}, \mathbf{x})=0 $ 的根隐式定义映射来<strong>泛化</strong>（generalize）归一化流。 ImpFlows 建立在残差流（ResFlows）上，<strong>在表达性和可处理性之间保持适当的平衡</strong>（a proper balance between expressiveness and tractability）。<br><span id="more"></span></p><p>通过理论分析（theoretical analysis），我们发现 ImpFlow 的<strong>函数空间</strong>比 ResFlows 的函数空间<strong>严格丰富</strong>（the function space of ImpFlow is strictly richer than that of ResFlows）。此外，对于具有<strong>固定数量的块</strong>（a fixed number of blocks）的任何ResFlow，存在一些函数使 ResFlow 具有<strong>不可忽略的近似误差</strong>（a non-negligible approximation error）。</p><p>但是，该函数可以由单块（single-block） ImpFlow <strong>精确表示</strong>。我们提出了一种<strong>可扩展</strong>（scalable）的算法来<strong>训练</strong>和从 ImpFlows 中<strong>提取样本</strong>。根据经验（Empirically），我们在几个分类和密度建模任务上评估 ImpFlow，并且在所有基准测试中，ImpFlow 的<strong>参数数量</strong>（a comparable amount of parameters）均优于 ResFlow。</p><hr><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>标准化流（NFs）（Variational inference with normalizing flows，ICML 2015; Nice，ICLR2014）是用于密度建模的有前途的方法。NFs 通过指定从 $x$ 到另一个随机变量 $z$ 的可逆变换 $f(x)$ 来定义模型分布 $ p_{\mathbf{x}}(\mathbf{x}) $。 通过变量变化(change-of-variable)公式，模型密度为<span id="#eq1"></span></p><script type="math/tex; mode=display">\begin{equation} \ln p_{\mathbf{x}}(\mathbf{x})=\ln p_{\mathbf{z}}(f(\mathbf{x}))+\ln \mid \operatorname{det}\left(J_{f}(\mathbf{x})\right) |\end{equation}\tag{1}</script><p>其中 $ p_{\mathbf{x}}(\mathbf{z}) $ 遵循简单分布，例如高斯分布。NFs 由于其易处理性而特别吸引人，即可以将模型密度 $ p_{\mathbf{x}}(\mathbf{x}) $ 直接评估为 <strong>Eq.1</strong>。为了实现这种可处理性，NFs模型应该满足<strong>两个要求</strong>：（i）$x$ 和 $z$ 之间的映射是可逆的；  （ii）雅可比行列式 $J_{f}(\mathbf{x})$ 的对数行列式是易处理的。寻找满足这些可控性约束 (tractability constraints) 的丰富模型族(rich model families)对于 Nfs 的研究至关重要。对于第二个要求，早期的工作，例如逆自回归流（Kingma，NIPS2016）和RealNVP（Dinh，ICLR2017）将模型族（model family）限制为具有三角形雅可比矩阵的模型族。</p><p>最近，出现了一些<strong>自由形式</strong> (free-form) 的 <strong>Jacobian 方法</strong>，例如残差流（ResFlows）（Invertible residual networks，ICML2019; Residual flows for invertible generative modeling，NIPS2019）。他们通过利用<strong>对数行列式</strong>的<strong>随机估计器</strong>（stochastic estimator）来放宽<strong>三角形雅可比约束</strong>，从而<strong>丰富了模型族</strong>。但是，每个<strong>转换块</strong>（transformation block）的Lipschitz <strong>常数</strong>均受<strong>可逆性约束</strong>。通常，这不是可取的，因为将简单的<strong>先验分布</strong>映射到潜在的<strong>复杂数据分布</strong>可能需要具有<strong>非常大</strong>的<strong>Lipschitz常数的转换</strong>（见<strong>Fig. 3</strong>）。此外，所有上述方法（aforementioned methods）都假定存在一个明确的（explicit）前向映射 $ \mathbf{z}=f(\mathbf{x}) $ 。具有显式正向映射的双射仅覆盖了第一个要求所建议的<strong>广义可逆函数的一小部分</strong>（a fraction of the broad class of invertible functions），这可能会限制模型的容量。</p><p><img src="assets/1621156780419.png" alt="1621156780419"></p><p><strong>Fig. 3:</strong>  Checkerboard data density and the results of a 8-block ResFlow and a 4-block ImpFlow. 棋盘数据密度 以及 8-block ResFlow 和 4-block ImpFlow的结果。</p><p>在本文中，我们提出了 implicit flows（ImpFlows）来<strong>泛化</strong>NFs，<strong>允许转换被</strong> $ F(\mathbf{z}, \mathbf{x})=0 $ <strong>隐式定义</strong>。给定 $x$（或$z$），可以通过隐式的根查找过程（root-finding procedure） $ \mathbf{z}=\operatorname{RootFind}(F(\cdot, \mathbf{x})) $ 来计算另一个变量。可以将先前 NFs 中使用的显式映射 $z = f(x)$ 视为 <strong>ImpFlow 的特殊情况</strong>，形式为 $F(z，x)= f(x)− z =0$. </p><p>为了在<strong>表达性和可处理性</strong>之间取得平衡，我们从 ImpFlows 中提出了一个特殊的定义，其中每个 block 是由 <strong>ResFlow block 和另一个ResFlow block的逆</strong>来组成。我们从理论上研究<strong>函数空间中</strong> ResFlows 和 ImpFlows 的<strong>模型容量</strong>。 通过<strong>放宽 Lipschitz 约束</strong>，我们证明了 single-block ImpFlow 的<strong>函数族</strong>比 two-block ResFlow的函数族<strong>严格丰富</strong>。此外，对于任何具有固定块数的ResFlow，都存在某些可逆函数，使 ResFlow 具有<strong>不可忽略的近似误差</strong>，但是ImpFlow可以精确建模。</p><p>在实践方面，我们开发了一种<strong>可伸缩</strong>的（scalable）算法来估计概率密度及其梯度，并从ImpFlows中提取样本。 该算法利用（leverages）<strong>隐式微分公式</strong>（implicit differentiation formula）。尽管功能更强大，但是ImpFlow的梯度计算与 ResFlows 的梯度计算大部分相似，除了在<strong>根查找方面有一些额外的开销</strong>。我们在几个分类和生成建模任务上测试了 ImpFlow 的有效性。ImpFlow 在所有基准测试上均优于 ResFlow，具有可比的模型大小和计算成本。（comparable model sizes and computational cost）</p><hr><h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h2><h3 id="2-1-Expressive-Normalizing-Flows"><a href="#2-1-Expressive-Normalizing-Flows" class="headerlink" title="2.1. Expressive Normalizing Flows"></a>2.1. Expressive Normalizing Flows</h3><p>有许多工作致力于提高NFs的能力。例如，Dinh等（ICLR2014, Nice; ICLR2017, RealNVP）; Kingma &amp; Dhariwal（NIPS2018, Glow）;  Ho等（ICML2019, Flow++: Improving flow-based generative models with variational dequantization and architecture design）; 宋等（NIPS2019, Mintnet: Building invertible neural networks with masked convolutions）;  Hoogeboom等（ICML2019, Emerging convolutions for generative<br>normalizing flows）;  De Cao等（UAI2020, Block neural autoregressive flow）；  Durkan等（NIPS2019,  Neural spline flows）用<strong>易处理的Jacobian</strong>设计<strong>专用的模型架构</strong>。 </p><p>最近，Grathwohl等（ICLR2019, <strong>Ffjord</strong>:Free-form continuous dynamics for scalable reversible generative models）;  Behrmann等 （ICML2019, <strong>Invertible residual networks</strong>）;  Chen等（NIPS2019,<strong>Residual flows for invertible generative modeling</strong>）提出了具有<strong>自由形式雅可比行列式</strong>(不限制三角矩阵)的NFs，它们用<strong>随机估计量近似了行列式</strong>。 </p><p>在架构设计的同时，Chen等（ICML2020, <strong>Vflow</strong>: More expressive generative flows with variational data augmentation）； Huang等（arXiv2020,  <strong>Augmented normalizing flows</strong>: Bridging the gap between generative flows and latent variable models）； Cornish等（ICML2020,  <strong>Relaxing bijectivity constraints</strong> with continuously indexed normalising flows）；  Nielsen等（arXiv2020, <strong>Survae flows</strong>: Surjections to bridge the gap between vaes and flows）通过在<strong>更高维度的空间中操作</strong>来提高NFs的能力。</p><p>正如引言中提到的，所有这些现有作品都采用<strong>显式正向映射</strong>，这仅是广泛的<strong>可逆函数类的子集</strong>。相反，我们认为的<strong>隐式函数族更丰富</strong>。 虽然我们在本文中主要讨论 ResFlows 的<strong>隐式泛化</strong>（Chen, NIPS2019, <strong>Residual flows for invertible generative modeling</strong>），但利用隐式可逆函数的一般思想也可能会应用于其他模型。 最后，张等（ICML2020, Approximation capabilities of neural odes and invertible residual networks）正式证明 ResFlows 的<strong>模型能力受到残差块尺寸的限制</strong>。相比之下，我们根据<strong>有界 Lipschitz 常数</strong>研究 ResFlows 的另一个局限性，并以可比较的深度比较 ResFlows 和 ImpFlows 的<strong>函数族</strong>。</p><hr><h3 id="2-2-Continuous-Time-Flows-CTFs"><a href="#2-2-Continuous-Time-Flows-CTFs" class="headerlink" title="2.2. Continuous Time Flows (CTFs)"></a>2.2. Continuous Time Flows (CTFs)</h3><p>（Chen，NIPS2018b; Grathwohl，ICLR2019; Chen，ICML2018a）是用于生成模型的<strong>离散时间流</strong>的灵活替代方案。 他们通常将<strong>可逆变换</strong>视为一个<strong>动力系统</strong>，该动力系统由<strong>常微分方程</strong>（ODE）<strong>求解器近似模拟</strong>。相反，本文考虑的隐式函数族<strong>不包含微分方程</strong>，仅需要<strong>定点解算器</strong>(fixed point solvers)。而且，理论上的保证是不同的。 尽管 CTFs 通常研究<strong>连续时间</strong>（即“无限深度”限制）情况下的<strong>通用逼近能力</strong>（universal approximation），但我们在<strong>有限数量的转换步骤</strong>（a finite number of transformation steps）下考虑了 ImpFlows 和 ResFlows 的模型能力。最后，尽管CTFs 很灵活，但由于<strong>不稳定性</strong>（Liu，CVPR2020; Massaroli，arXiv2020）和<strong>过多的ODE求解器步骤</strong>（Finlay，ICML2020），它们的学习具有挑战性，使其<strong>大规模应用</strong>仍然是一个未解决的问题。</p><hr><h3 id="2-3-Implicit-Deep-Learning"><a href="#2-3-Implicit-Deep-Learning" class="headerlink" title="2.3. Implicit Deep Learning"></a>2.3. Implicit Deep Learning</h3><p>利用<strong>隐式函数可增强神经网络的灵活性</strong>，从而以<strong>特定于问题的方式进行网络层的设计</strong>(problem-specific way)。 例如，Bai（NIPS2019）提出了一种深度均衡(equilibrium)模型，作为递归网络的紧凑替代;  Amos＆Kolter（ICML2017,  Differentiable optimization as a layer in neural networks.）<strong>泛化了每一层以解决优化问题</strong>；Wang（ICML2019）将<strong>逻辑推理整合到神经网络中</strong>;  Reshniak＆Webster（2019）利用<strong>隐式Euler</strong>方法来提高<strong>残差块正向和反向过程的稳定性</strong>; Sitzmann（2020）引入<strong>周期函数</strong>以进行表征学习。<strong>与这些将隐式函数替换为前馈网络的工作不同</strong>，我们为 NFs 开发了的<strong>可逆的隐式函数</strong>，讨论了此类函数存在的条件，并从理论上研究了我们提出的 ImpFlow 在该函数空间中的模型的能力。</p><hr><h2 id="3-Implicit-Normalizing-Flows"><a href="#3-Implicit-Normalizing-Flows" class="headerlink" title="3. Implicit Normalizing Flows"></a>3. Implicit Normalizing Flows</h2><p>现在，我们将从对现有工作的简要概述开始(by starting with a brief overview of existing work)，介绍隐式规范化流程。</p><hr><h3 id="3-1-Normalizing-Flows"><a href="#3-1-Normalizing-Flows" class="headerlink" title="3.1. Normalizing Flows"></a>3.1. Normalizing Flows</h3><p>如 <a href="#eq1">Eq. 1</a> 所示，标准化流 $ f: \mathbf{x} \mapsto \mathbf{z} $ 是一个可逆函数，它使用变量变化公式（change-of-variable formula）定义概率分布。标准化流的建模能力取决于可逆函数 $f$ 的表达。Residual flows （ResFlows）（Chen，2019; Behrmann，2019）由于其<strong>自由形式</strong> (free-form) 的 <strong>Jacobian 形式</strong>而成为一类特别强大的NFs。ResFlows 使用 $ f=f_{L} \circ \cdots \circ f_{1} $ 来构造<strong>可逆映射</strong>，其中每一层 $f_l$ 是具有 <strong>Lipschitz约束</strong> 并由固定常数 $κ$ 限制的可逆残差网络： </p><script type="math/tex; mode=display">\begin{equation} f_{l}(\mathbf{x})=\mathbf{x}+g_{l}(\mathbf{x}), \quad \operatorname{Lip}\left(g_{l}\right) \leq \kappa<1 \end{equation}\tag{2}</script><p>其中 $\operatorname{Lip}\left(g\right)$ 是函数 $g$ 的 Lipschitz常数（详细信息见 <a href="#sec41">Sec. 4.1</a>）。尽管有 free-form 的Jacobian，ResFlows的模型<strong>能力仍受可逆函数的 Lipschitz 常数限制</strong>。每个ResFlow block $f_l$ 的 <strong>Lipschitz 常数不能超过2</strong>（Behrmann，2019），因此 <strong>L-block 的 ResFlow的 Lipschitz 常数不能超过</strong> $2^L$。但是，为了将简单的<strong>先验分布转换为潜在的复杂数据分布</strong>，通常<strong>要求转换的Lipschitz常数足够大</strong>。因此，仅仅<strong>满足Lipschitz约束</strong>，<strong>ResFlows可能会很深</strong>（见 <strong>Fig. 3</strong>）。下面，我们介绍隐式流（ImpFlows）以<strong>放松Lipschitz约束</strong>。</p><p><img src="assets/1621156780419.png" alt="1621156780419"></p><p><strong>Fig. 3:</strong>  Checkerboard data density and the results of a 8-block ResFlow and a 4-block ImpFlow. 棋盘数据密度 以及 8-block ResFlow 和 4-block ImpFlow的结果。</p><hr><h3 id="3-2-Model-Specification"><a href="#3-2-Model-Specification" class="headerlink" title="3.2. Model Specification"></a>3.2. Model Specification</h3><p>通常，将隐式流（ImpFlow）定义为 $d$ 维随机变量 $\mathbf{x}$ 和 $\mathbf{z}$ 之间的可逆映射，并通过找到 $ F(\mathbf{z}, \mathbf{x})=\mathbf{0} $ 的根，其中 $F$ 是从 $\mathbb{R}^{2d}$ 到 <script type="math/tex">\mathbb{R}^{d}</script> 的函数。特别的，先前 flow 实例中使用的显式映射 $ \mathbf{z}=f(\mathbf{x}) $（Chen，2019; Kingma＆Dhariwal，2018）可以表示为隐式函数，形式为 $\begin{equation}<br> F(\mathbf{z}, \mathbf{x})=f(\mathbf{x})-\mathbf{z}=\mathbf{0}<br>\end{equation}$。虽然 ImpFlows 是一个强大的族，但通常不能保证它们满足 NFs 所要求的<strong>对数行列式的可逆性</strong>和<strong>易处理性</strong>。在本文中，我们将重点放在以下特定形式上，该形式在<strong>表达性和可延展性</strong>之间取得了良好的平衡，并为以后的研究留下了其他可能性。</p><h4 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition 1."></a>Definition 1.<span id="#def1"></span></h4><p>令 $ g_{\mathbf{z}}: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d} $ 和 $ g_{\mathbf{x}}: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d} $  是两个函数，使得 $ \operatorname{Lip}\left(g_{\mathbf{x}}\right)<1 $ 和 $ \operatorname{Lip}\left(g_{\mathbf{z}}\right)<1 $，其中 $ \operatorname{Lip}\left(g\right) $ 是函数 $g$ 的Lipschitz 常数。ImpFlows 的**特定形式**定义为<span id="eq3">&lt;/span&gt;</p><script type="math/tex; mode=display">\begin{equation} F(\mathbf{z}, \mathbf{x})=\mathbf{0},  \quad\text{where}  \quad F(\mathbf{z}, \mathbf{x})=g_{\mathbf{x}}(\mathbf{x})-g_{\mathbf{z}}(\mathbf{z})+\mathbf{x}-\mathbf{z} \end{equation} \tag{3}</script><p><a href="#eq3">Eq. 3</a> 的根组解在 $\mathbb{R}^{d} \times \mathbb{R}^{d}$中形成一个子集，它实际上定义了唯一可逆函数 $f$ 的赋值规则(assignment rule)。</p><p>对于任何的 $\mathbf{x}_0$，根据 <a href="#def1">Definition 1</a>，我们可以构造一个收缩 $ h_{\mathbf{x}_{0}}(\mathbf{z})=F\left(\mathbf{z}, \mathbf{x}_{0}\right)+\mathbf{z} $, 它具有唯一的固定点，对应于唯一的根（关于 $\mathbf{z}$ ）  $ F\left(\mathbf{z}, \mathbf{x}_{0}\right)=\mathbf{0} $，由 $ f\left(\mathbf{x}_{0}\right) $ 表示。 </p><p>类似地，在反向过程中，给定 $\mathbf{z}_{0}$，$ F\left(\mathbf{z}_{0}, \mathbf{x}\right)=\mathbf{0} $ 的根（关于 $\mathbf{x}$）也存在并且是唯一的，用 $ f^{-1}\left(\mathbf{z}_{0}\right) $ 表示。 如 <a href="#the1">Theorem 1</a> 总结，这两个属性足以确保 $f$ 的存在和可逆。 </p><h4 id="Theorem-1"><a href="#Theorem-1" class="headerlink" title="Theorem 1. "></a>Theorem 1. <span id="#the1"></span></h4><p><a href="#eq3">Eq. 3</a> 定义了一个唯一的映射 $ f: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d}, \mathbf{z}=f(\mathbf{x}) $，并且 $f$ 是可逆的。</p><p>见 <a href="#app1">Appendix A.1</a> 中的证明。<a href="#the1">Theorem 1</a> 表征了（characterizes） <a href="#def1">Definition 1</a> 中引入的 ImpFlow 的有效性（the validness of）。实际上，a single ImpFlow 是 a single ResFlow 和另一个 single ResFlow的逆 的<strong>堆栈</strong>，这将在 <strong>Sec. 4</strong> 中正式说明。我们将在 <strong>Sec. 4</strong> 中研究ImpFlows的函数族的表达性，并在 <strong>Sec. 5</strong> 提出一种可扩展的算法来学习基于 <strong>Sec 4</strong> 中的 ImpFlows 的<strong>深度生成模型</strong>。  </p><hr><h2 id="4-Expressiveness-Power"><a href="#4-Expressiveness-Power" class="headerlink" title="4. Expressiveness Power"></a>4. Expressiveness Power</h2><p>我们首先在 <a href="#sec41">Sec. 4.1</a> 介绍一些关于 <strong>Lipschitz 连续函数</strong>的初步知识。 然后正式研究 ImpFlows 的表达能力，尤其是与 ResFlows 相比。特别的，我们在 <a href="#sec42">Sec. 4.2</a> 证明了 ImpFlows 的函数空间比的 ResFlows 的函数空间严格丰富，见 <strong>Fig. 1(a)</strong>。 此外，对于具有固定数量的块的任何ResFlow，存在一些函数，使 ResFlow 具有不可忽略的近似误差。 但是，该函数可以由 single-block ImpFlow精确表示。 结果显示在 <strong>Fig. 1(b)</strong> 中，并在 <a href="#sec43">Sec. 4.3</a> 中正式提出。</p><p><img src="assets/1621161998415.png" alt="1621161998415"></p><p><strong>Fig. 1:</strong> An illustration of our main theoretical results on the expressiveness power of ImpFlows and ResFlows. Panel (a) and Panel (b) correspond to results in Sec. 4.2 and Sec. 4.3 respectively.</p><hr><h3 id="4-1-Lipschitz-Continuous-Functions"><a href="#4-1-Lipschitz-Continuous-Functions" class="headerlink" title="4.1. Lipschitz Continuous Functions"></a>4.1. Lipschitz Continuous Functions<span id="sec41"></span></h3><p>对于任何可微函数 $ f: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d} $ 和任何 $ \mathbf{x} \in \mathbb{R}^{d} $，我们将 $f$ 在 $\mathbf{x}$ 处的雅可比矩阵表示为 $ J_{f}(\mathbf{x}) \in \mathbb{R}^{d \times d} $</p><h4 id="Definition-2"><a href="#Definition-2" class="headerlink" title="Definition 2."></a>Definition 2.</h4><p>如果存在常数 $L$ 满足下式，则函数 $ \mathbb{R}^{d} \rightarrow \mathbb{R}^{d} $ 称为Lipschitz连续。</p><script type="math/tex; mode=display">\begin{equation} \left\|f\left(\mathbf{x}_{1}\right)-f\left(\mathbf{x}_{2}\right)\right\| \leq L\left\|\mathbf{x}_{1}-\mathbf{x}_{2}\right\|, \forall \mathbf{x}_{1}, \mathbf{x}_{2} \in \mathbb{R}^{d} \end{equation}</script><p>满足不等式 (inequality) 的最小 $L$ 称为 $f$ 的 Lipschitz常数，表示为 $ \operatorname{Lip}(f) $。</p><p>通常， $ \operatorname{Lip}(f) $ 的定义取决于 <script type="math/tex">|| ·||</script>的选择，为简单起见，本文默认使用L2-范数。</p><hr><h4 id="Definition-3"><a href="#Definition-3" class="headerlink" title="Definition 3."></a>Definition 3.</h4><p>如果函数 $ f: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d} $ 是 Lipschitz 连续的并且具有逆映射 $f^{-1}$（且逆映射也是Lipschitz连续），则称函数 $f$ 为 bi-Lipschitz 连续。</p><p>在下面的分析中考虑 Lipschitz 常数的等效定义是很有用的。</p><hr><h4 id="Proposition-1"><a href="#Proposition-1" class="headerlink" title="Proposition 1."></a>Proposition 1.</h4><p>命题1</p><p>Rademacher（Federer（1969），Theorem 3.1.6）</p><p>如果 $ f: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d} $ 是 Lipschitz 连续的，则 $f$ 几乎在任何地方都是可微的，并且</p><script type="math/tex; mode=display">\begin{equation} \operatorname{Lip}(f)=\sup _{\mathbf{x} \in \mathbb{R}^{d}}\left\|J_{f}(\mathbf{x})\right\|_{2} \end{equation}</script><p>其中 $ |M|_{2}=\sup _{\left\{\mathbf{v}:|\mathbf{v}|_{2}=1\right\}} |M \mathbf{v}|_{2}  $ 是矩阵 $ M \in \mathbb{R}^{d \times d} $ 的算子范数</p><hr><h3 id="4-2-Comparision-to-Two-Block-ResFlows"><a href="#4-2-Comparision-to-Two-Block-ResFlows" class="headerlink" title="4.2. Comparision to Two-Block ResFlows"></a>4.2. Comparision to Two-Block ResFlows<span id="sec42"></span></h3><p><img src="assets/1621164873148.png" alt="1621164873148"></p><p><strong>Fig. 1a:</strong> Relationship between $\mathcal{R}_2$ and $\mathcal{I}$.</p><p><img src="assets/1621164967646.png" alt="1621164967646"></p><p><strong>Fig. 2:</strong>  A 1-D motivating example. 一维激励的例子。（a）目标函数图。（b）使用具有不同块数的ResFlows拟合目标函数的结果。由于Lipschtiz约束，所有函数都有不可忽略的（non-negligible）逼近误差。（c）可以精确表示目标函数的 ImpFlow。（d）合成 <strong>ResFlow block</strong> 和<strong>另一个 ResFlow block 的逆</strong>以构造ImpFlow block 的可视化视图。 详细设置可以在 <a href="#appd">Appendix D</a> 中找到。</p><p>我们正式比较了 a single-block ImpFlow 和 a two-block ResFlow 的表达能力。我们在 <strong>Fig. 1a</strong> 的这一小节中突出了理论结果的结构，并在 <strong>Fig. 2</strong> 中给出了一个一维激活的例子。所有的证明都可以在 <a href="#appa">Appendix. A</a> 中找到。 另一方面，根据 ResFlow 的定义，single-block ResFlow 的函数族为 <span id="eq4"></span></p><script type="math/tex; mode=display">\begin{equation} \mathcal{R}:=\left\{f: f=g+\mathrm{Id}, g \in C^{1}\left(\mathbb{R}^{d}, \mathbb{R}^{d}\right), \operatorname{Lip}(g)<1\right\} \end{equation}\tag{4}</script><p>其中 $ C^{1}\left(\mathbb{R}^{d}, \mathbb{R}^{d}\right) $ 包含从 $ \mathbb{R}^{d} $ 到 $ \mathbb{R}^{d} $ 的所有具有连续导数的函数，$\mathrm{Id}$ 表示恒等图。 此外，$\ell$-block ResFlows 的函数族由以下组成定义： <span id="eq5"></span></p><script type="math/tex; mode=display">\begin{equation} \mathcal{R}_{\ell}:=\left\{f: f=f_{\ell} \circ \cdots \circ f_{1}\right. \text{for some } \left.f_{1}, \cdots, f_{\ell} \in \mathcal{R}\right\} \end{equation}\tag{5}</script><p>根据 <a href="#eq4">Eq. 4</a> 和 <a href="#eq5">Eq. 5</a>，$ \mathcal{R}_{1}=\mathcal{R} $。</p><p>另一方面，根据 <a href="#eq3">Eq. 3</a> 中 ImpFlow 的定义，我们可以获得 $(g_{\mathbf{x}} + \mathrm{Id})(\mathbf{x})=g_{\mathbf{x}}(\mathbf{x})+\mathbf{x}=g_{\mathbf{z}} (\mathbf{z})+\mathbf{z}=\left(g_{\mathbf{z}}+\mathrm{Id}\right)(\mathbf{z}) $，其中 $◦$ 表示函数的组成。同理，我们有 $ \mathbf{z}=\left(\left(g_{\mathbf{z}}+\mathrm{Id}\right)^{-1} \circ\left(g_{\mathbf{x}}+\mathrm{Id}\right)\right)(\mathbf{x}) $ ，这意味着 single-block ImpFlow 的函数族是 </p><script type="math/tex; mode=display">\begin{equation} \mathcal{I}=\left\{f: f=f_{2}^{-1} \circ f_{1}\right. \text{for some } \left.f_{1}, f_{2} \in \mathcal{R}\right\} \end{equation}\tag{6}</script><p>直观上，a single-block ImpFlow 可以解释为 <strong>一个 ResFlow block 和另一个ResFlow block 的逆函数</strong>的组成，它们可能没有明确的形 explicit form（有关1D示例，见 <strong>Fig. 2c</strong> 和 <strong>Fig. 2d</strong> ）。因此，研究  $\mathcal{I}$ 和 $\mathcal{R}_2$ 之间的关系是很自然的。</p><p>在此之前，我们首先介绍一个没有明显 Lipschitz 约束的“单调递增函数”族（monotonically increasing functions），并证明它严格大于 $\mathcal{R}$ 。</p><h4 id="Lemma-1"><a href="#Lemma-1" class="headerlink" title="Lemma 1."></a>Lemma 1.<span id="le1"></span></h4><p>引理1</p><script type="math/tex; mode=display">\begin{equation} \mathcal{R} \varsubsetneqq \mathcal{F}:=\left\{f \in \mathcal{D}: \underset{\mathbf{x} \in \mathbb{R}^{d}, \mathbf{v} \in \mathbb{R}^{d},\|\mathbf{v}\|_{2}=1}{ \operatorname{inf}} \mathbf{v}^{T} J_{f}(\mathbf{x}) \mathbf{v}>0\right\} \end{equation}</script><p>其中 $\mathcal{D}$ 是从 $ \mathbb{R}^{d} $ 到 $ \mathbb{R}^{d} $ 的所有 bi-Lipschitz $C^1$-diffeomorphisms(同态)的集合，而 $ A \varsubsetneqq B $ 表示 $A$ 是 $B$ 的真子集（proper subset）。</p><p>请注意，它遵循 Behrmann（2019，Lemma2），所有在 $ \mathcal{R} $ 中的函数都是 bi-Lipschitz 的，所以 $ \mathcal{R} \varsubsetneqq \mathcal{D} $ . 在1D 输入情况下，我们可以得到 $ \mathcal{R}=\left\{f \in C^{1}(\mathbb{R}): \inf _{x \in \mathbb{R}} f^{\prime}(x)&gt;0, \sup _{x \in \mathbb{R}} f^{\prime}(x)<2\right\} $，并且 $ \mathcal{F}=\left\{f \in C^{1}(\mathbb{R}): \inf _{x \in \mathbb{R}} f^{\prime}(x)>0\right\} $。在高维情况下，$\mathcal{R}$ 和 $\mathcal{F}$ 难以阐述。尽管如此，$\mathcal{R}$ 中函数的 Lipschitz 常数小于 2（Behrmann，2019），但 $\mathcal{F}$ 中函数的 Lipschitz 常数可以任意大。</p><p>基于 <a href="le1">Lemma 1</a>，我们证明ImpFlows $ \mathcal{I} $ 的函数族由 $\mathcal{F}$ 中两个函数的组成组成，因此严格大于 $ \mathcal{R}_2 $ ，如以下定理所总结。</p><h4 id="Theorem-2"><a href="#Theorem-2" class="headerlink" title="Theorem 2."></a>Theorem 2.</h4><p>a single-block ImpFlow的函数族的等效形式（Equivalent form）。</p><script type="math/tex; mode=display">\begin{equation} \mathcal{I}=\mathcal{F}_{2}:=\left\{f: f=f_{2} \circ f_{1}\right. \text{for some } \left.f_{1}, f_{2} \in \mathcal{F}\right\} \end{equation}</script><p>注意，恒等映射 $ I d \in \mathcal{F} $，很容易得到 $ \mathcal{F} \subset \mathcal{I} $。因此，a single ImpFlow 的 Lipschitz 常数（及其逆）可以任意（arbitrarily）大。 由于 $ \mathcal{R} \varsubsetneqq \mathcal{F} $ ，并且 $ \mathcal{I} \backslash \mathcal{R}_{2} $ 中存在一些函数（参见 <a href="#sec43">Sec 4.3</a> 中的构造示例），因此可以得出以下推论。</p><h4 id="Corollary-1"><a href="#Corollary-1" class="headerlink" title="Corollary 1."></a>Corollary 1.<span id="cor1"></span></h4><script type="math/tex; mode=display"> \mathcal{R} \varsubsetneqq \mathcal{R}_{2} \varsubsetneqq \mathcal{F}_{2}=\mathcal{I}</script><p><strong>Fig. 2b and 2c</strong> 中一维示例的结果与 <a href="#cor1">Corollary 1</a>一致。此外， <a href="#cor1">Corollary 1</a> 可以推广到具有 $2\ell$-block ResFlows 和 $\ell$-block ImpFlows的情况，这强烈地推动了normalizing flows中的隐式层的使用。</p><hr><h3 id="4-3-Comparison-with-Multi-Block-ResFlows"><a href="#4-3-Comparison-with-Multi-Block-ResFlows" class="headerlink" title="4.3. Comparison with Multi-Block ResFlows"></a>4.3. Comparison with Multi-Block ResFlows<span id="sec43"></span></h3><p><img src="assets/1621167418876.png" alt="1621167418876"></p><p><strong>Fig. 1b</strong>  Relationship between $ \mathcal{R}_{0} $ and $ \mathcal{I} $</p><p>如 <strong>Fig. 1b</strong> 所示，我们进一步研究了 $ \mathcal{R}_{\ell} $ ($\ell&gt;2$)和 <script type="math/tex">\mathcal{I}</script> 之间的关系。对于固定的 $\ell$，$ \mathcal{R}_{\ell} $ 中函数的 Lipschitz 常数仍然是有界的，并且有无限个不存在于 $ \mathcal{R}_{\ell} $ 中但在 <script type="math/tex">\mathcal{I}</script> 中的函数。我们构造了一个这样的函数族：对于任何$ L, r \in \mathbb{R}^{+} $，定义</p><script type="math/tex; mode=display">\begin{equation} \mathcal{P}(L, r)=\left\{f: f \in \mathcal{F}, \exists \mathcal{B}_{r} \subset \mathbb{R}^{d}, \forall \mathbf{x}, \mathbf{y} \in \mathcal{B}_{r},\|f(\mathbf{x})-f(\mathbf{y})\|_{2} \geq L\|\mathbf{x}-\mathbf{y}\|_{2}\right\} \end{equation}\tag{9}</script><p>其中 $\mathcal{B}_{r}$ 是半径为 $r$ 的 $d$ 维球。显然，$\mathcal{P}(L, r)$ 是一个无限集。下面，我们将展示 $ \forall 0&lt;\ell&lt;\log _{2}(L)$，$\mathcal{R}_{\ell} $ 对于$\mathcal{P}(L, r)$ 中的函数具有不可忽略的近似误差。 但是，它们完全可以由 <script type="math/tex">\mathcal{I}</script> 中的函数表示。</p><h4 id="Theorem-3"><a href="#Theorem-3" class="headerlink" title="Theorem 3."></a>Theorem 3.<span id="the3"></span></h4><p>给定 $ L&gt;0 $ 和 $ r&gt;0 $，我们有</p><ul><li><p>$ \mathcal{P}(L, r) \subset \mathcal{I} $</p></li><li><p>$ \forall 0&lt;\ell&lt;\log _{2}(L),  \mathcal{P}(L, r) \cap \mathcal{R}_{\ell}=\varnothing  $. 此外，对于任何具有 $d$ 维球 $\mathcal{B}_{r}$ 的 $ f \in \mathcal{P}(L, r) $，用 $ \mathcal{R}_{\ell} $ 函数拟合 $\mathcal{B}_{r}$ 中的 $f$ 的最小误差满足</p><script type="math/tex; mode=display">\begin{equation} \inf _{g\in \mathcal{R}_{\ell}} \sup _{\mathbf{x} \in \mathcal{B}_{r}}\|f(\mathbf{x})-g(\mathbf{x})\|_{2} \geq \frac{r}{2}\left(L-2^{\ell}\right) \end{equation}\tag{10}</script></li></ul><p>遵循 <a href="#the3">Theorem 3</a>，要建模 $ f \in \mathcal{P}(L, r) $，我们只需要 a single-block ImpFlow，但至少需要a -$ \log _{2}(L) $-block  ResFlow。在 <strong>Fig. 2b</strong> 中，我们展示了 1D 情况，其中a 3-block ResFlow 无法拟合 a single ImpFlow 可以精确表示的函数。此外，我们还证明了 ImpFlows 的其他一些属性。特别是 $ \mathcal{R}_{3} \not \subset \mathcal{I} $。我们将结果正式呈现在 <a href="#appb">Appendix B</a> 中。</p><hr><h2 id="5-Generative-Modeling-With-ImpFlows"><a href="#5-Generative-Modeling-With-ImpFlows" class="headerlink" title="5. Generative Modeling With ImpFlows"></a>5. Generative Modeling With ImpFlows</h2><p>ImpFlows can be parameterized by neural networks and stacked to form a deep generative model to<br>model high-dimensional data distributions. We develop a scalable algorithm to perform inference,<br>sampling and learning in such models. For simplicity, we focus on a single-block during derivation.<br>Formally, a parametric ImpFlow block z = f(x;θ) is defined by</p><p>可以通过神经网络对ImpFlows进行参数化，然后将其堆叠以形成一个深度生成模型，以对高维数据分布进行建模。 我们开发了一种可扩展的算法，可以在此类模型中执行推理，采样和学习。 为简单起见，我们将重点放在推导过程中的单个块上。<br>   形式上，参数ImpFlow块z = f（x;θ）定义为</p><p>and Lip(g x ) &lt; 1, Lip(g z ) &lt; 1. Let θ denote all the parameters in g x and g z (which does NOT mean<br>g x and g z share parameters). Note that x refers to the input of the layer, not the input data.<br>The inference process to compute z given x in a single ImpFlow block is solved by finding the root<br>of F(z,x;θ) = 0 w.r.t. z, which cannot be explicitly computed because of the implicit formulation.<br>Instead, we adopt a quasi-Newton method (i.e. Broyden’s method (Broyden, 1965)) to solve this<br>problem iteratively, as follows:</p><p>和Lip（g x）&lt;1，Lip（g z）&lt;1。令θ表示g x和g z中的所有参数（这并不意味着g x和g z共享参数）。 请注意，x是指图层的输入，而不是输入数据。<br> 通过找到F（z，x;θ）= 0 w.r.t的根来求解在给定x的单个ImpFlow块中计算z的推理过程。  z，由于隐式公式而无法显式计算。<br>   相反，我们采用拟牛顿法（即Broyden法（Broyden，1965年））来迭代地解决此问题，如下所示： </p><p>where B is a low-rank approximation of the Jacobian inverse 1 and α is the step size which we use<br>line search method to dynamically compute. The stop criterion is kF(z [i] ,x;θ)k 2 &lt; ? f , where ? f<br>is a hyperparameter that balances the computation time and precision. As Theorem 1 guarantees the<br>existence and uniqueness of the root, the convergence of the Broyden’s method is also guaranteed,<br>which is typically faster than a linear rate.</p><p>其中B是Jacobian逆1的低阶近似，而α是我们使用线搜索方法动态计算的步长。 停止标准为kF（z [i]，x;θ）k 2 &lt;？  f，在哪里？  f是在计算时间和精度之间取得平衡的超参数。 由于定理1保证了根的存在和唯一性，因此也保证了Broyden方法的收敛性，通常比线性速率快。</p><p>Another inference problem is to estimate the log-likelihood. Assume that z ∼ p(z) where p(z) is a<br>simple prior distribution (e.g. standard Gaussian). The log-likelihood of x can be written by</p><p>另一个推断问题是估计对数似然性。 假设z〜p（z），其中p（z）是一个简单的先验分布（例如标准高斯分布）。  x的对数似然可以写成</p><p>where J f (x) denotes the Jacobian matrix of a function f at x. See Appendix. A.4 for the detailed<br>derivation. Exact calculation of the log-determinant term requires O(d 3 ) time cost and is hard to<br>scale up to high-dimensional data. Instead, we propose the following unbiased estimator of lnp(x)<br>using the same technique in Chen et al. (2019) with Skilling-Hutchinson trace estimator (Skilling,<br>1989; Hutchinson, 1989):</p><p>其中J f（x）表示x处函数f的雅可比矩阵。 见附录。  A.4为详细推导。 对数行列式项的精确计算需要O（d 3）时间成本，并且很难扩展到高维数据。 相反，我们使用Chen等人的相同技术提出了lnp（x）的以下无偏估计量。  （2019）和Skilling-Hutchinson追踪估算器（Skilling，1989; Hutchinson，1989）：</p><p>where p(N) is a distribution supported over the positive integers.</p><p>其中p（N）是在正整数上支持的分布。</p><p>The sampling process to compute x given z can also be solved by the Broyden’s method, and the<br>hyperparameters are shared with the inference process.</p><p>   计算给定z的x的采样过程也可以通过Broyden方法解决，并且超参数与推理过程共享。</p><p>In the learning process, we perform stochastic gradient descent to minimize the negative log-<br>likelihood of the data, denoted as L. For efficiency, we estimate the gradient w.r.t. the model<br>parameters in the backpropagation manner. According to the chain rule and the additivity of the<br>log-determinant, in each layer we need to estimate the gradients w.r.t. x and θ of Eqn. (13). In<br>particular, the gradients computation involves two terms: one is<br>∂<br>∂(·)<br>lndet(I + J g (x;θ)) and the other is<br>∂L<br>∂z<br>∂z<br>∂(·) , where g is a function satisfying Lip(g) &lt; 1 and (·) denotes x or θ. On the one<br>hand, for the log-determinant term, we can use the same technique as Chen et al. (2019), and obtain<br>an unbiased gradient estimator as follows.<br>   在学习过程中，我们执行随机梯度下降以最小化数据的负对数似然性（表示为L）。为了提高效率，我们估计了梯度w.r.t。 模型参数采用反向传播方式。 根据链式规则和对数行列式的可加性，在每一层中，我们需要估计梯度w.r.t。 等式的x和θ。  （13）。 特别地，梯度计算涉及两个术语：一个是∂（·）lndet（I + J g（x;θ）），而另一个是 other是∂L∂z∂z∂（·），其中g是满足Lip（g）&lt;1的函数，而（·）表示x或θ。 一方面，对于对数行列式，我们可以使用与Chen等人相同的技术。  （2019），并获得如下的无偏梯度估计量。</p><p>where p(N) is a distribution supported over the positive integers. On the other hand,<br>∂L<br>∂z<br>∂z<br>∂(·)<br>can be<br>computed according to the implicit function theorem as follows (See details in Appendix A.5):</p><p>其中p（N）是在正整数上支持的分布。 另一方面，可以根据隐函数定理如下计算computedL∂z∂z∂（·）（请参阅附录A.5中的详细信息）：</p><p>In comparision to directly calculate the gradient through the quasi-Newton iterations of the forward<br>pass, the implicit gradient above is simple and memory-efficient, treating the root solvers as a black-<br>box. Following Bai et al. (2019), we compute<br>∂L<br>∂z J<br>−1<br>G<br>(z) by solving a linear system iteratively, as<br>detailed in Appendix C.1. The training algorithm is formally presented in Appendix C.4.</p><p>为了通过前向传递的拟牛顿迭代直接计算梯度，上面的隐式梯度简单且存储效率高，将根求解器视为黑盒。 继Bai等。  （2019年），我们通过迭代求解线性系统来计算∂L∂zJ -1 G（z），如附录C.1所述。 训练算法在附录C.4中正式提出。</p><h2 id="A-Additional-Lemmas-And-Proofs"><a href="#A-Additional-Lemmas-And-Proofs" class="headerlink" title="A. Additional Lemmas And Proofs"></a>A. Additional Lemmas And Proofs<span id ="appa"></span></h2><p>引理和证明</p><h3 id="A-1-Proof-For-Theorem-1"><a href="#A-1-Proof-For-Theorem-1" class="headerlink" title="A.1 Proof For Theorem 1"></a>A.1 Proof For <a href="#the1">Theorem 1</a><span id ="app1"></span></h3><p>Proof. <a href="#the1">Theorem 1</a></p><p>首先，对任意的 $ \forall \mathbf{x}_{0} \in \mathbb{R}^{d} $，映射</p><script type="math/tex; mode=display">\begin{equation} h_{\mathbf{x}_{0}}(\mathbf{z})=F\left(\mathbf{z}, \mathbf{x}_{0}\right)+\mathbf{z} \end{equation}</script><p>是一个对映(contrative)映射，可以通过 $g_{z}$ 的 Lipschitz 条件表示：</p><script type="math/tex; mode=display">\begin{equation} \left(F\left(\mathbf{z}_{1}, \mathbf{x}_{0}\right)+\mathbf{z}_{1}\right)-\left(F\left(\mathbf{z}_{2}, \mathbf{x}_{0}\right)+\mathbf{z}_{2}\right)\|=\| g_{z}\left(\mathbf{z}_{1}\right)-g_{z}\left(\mathbf{z}_{2}\right)\|<\| \mathbf{z}_{1}-\mathbf{z}_{2} \mid \end{equation}</script><p>因此，$ h_{\mathbf{x}_{0}}(\mathbf{z}) $ 有一个唯一的不动点，用 $ f\left(\mathbf{x}_{0}\right) $ 表示：</p><script type="math/tex; mode=display">\begin{equation} h_{\mathbf{x}_{0}}\left(f\left(\mathbf{x}_{0}\right)\right)=f\left(\mathbf{x}_{0}\right) \Leftrightarrow F\left(f\left(\mathbf{x}_{0}\right), \mathbf{x}_{0}\right)=0 \end{equation}</script><p>类似地，我们还有：$ \forall \mathbf{z}_{0} \in \mathbb{R}^{d} $，存在一个满足 $ F\left(\mathbf{z}_{0}, g\left(\mathbf{z}_{0}\right)\right)=0 $ 的唯一 $ g\left(\mathbf{z}_{0}\right) $。</p><p>此外，令 $ \mathbf{z}_{0}=f\left(\mathbf{x}_{0}\right) $，我们有 $ F\left(f\left(\mathbf{x}_{0}\right), g\left(f\left(\mathbf{x}_{0}\right)\right)\right)=0 $。通过唯一性，我们有 $ g\left(f\left(\mathbf{x}_{0}\right)\right)=\mathbf{x}_{0} $，$\forall \mathbf{x}_{0} \in \mathbb{R}^{d}$。 同样，$ f\left(g\left(\mathbf{x}_{0}\right)\right)=\mathbf{x}_{0} $，$ \forall \mathbf{x}_{0} \in \mathbb{R}$。 因此，$f$ 是唯一且可逆的。</p><h2 id="B"><a href="#B" class="headerlink" title="B. "></a>B. <span id ="appb"></span></h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>C_DL_W5</title>
      <link href="/2022/03/28/C-DL-W5/"/>
      <url>/2022/03/28/C-DL-W5/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习工程师"><a href="#深度学习工程师" class="headerlink" title="深度学习工程师"></a>深度学习工程师</h1><p>由 deeplearning.ai 出品，网易引进的正版授权中文版深度学习工程师微专业课程，让你在了解丰富的人工智能应用案例的同时，学会在实践中搭建出最先进的神经网络模型，训练出属于你自己的 AI。<br><span id="more"></span></p><p>deeplearning.ai</p><p><a href="https://www.coursera.org/learn/neural-networks-deep-learning?action=enroll">https://www.coursera.org/learn/neural-networks-deep-learning?action=enroll</a></p><p><a href="https://study.163.com/my#/smarts">https://study.163.com/my#/smarts</a></p><p><a href="https://www.bilibili.com/video/av66647398">https://www.bilibili.com/video/av66647398</a></p><p><strong>note</strong></p><p><a href="https://redstonewill.blog.csdn.net/article/details/79446105">https://redstonewill.blog.csdn.net/article/details/79446105</a></p><p><a href="http://www.ai-start.com/dl2017/">http://www.ai-start.com/dl2017/</a></p><p><strong>课后作业</strong></p><p><a href="https://blog.csdn.net/u013733326/article/details/79827273">https://blog.csdn.net/u013733326/article/details/79827273</a></p><p><a href="https://www.heywhale.com/mw/project/5e20243e2823a10036b542da">https://www.heywhale.com/mw/project/5e20243e2823a10036b542da</a></p><h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><ul><li>[ ] 特殊应用：人脸识别和神经风格转换-<a href="#4.7">4.7 CNN可视化解释</a>，伪影</li></ul><h2 id="序列模型"><a href="#序列模型" class="headerlink" title="序列模型"></a>序列模型</h2><h3 id="第一周-循环序列模型"><a href="#第一周-循环序列模型" class="headerlink" title="第一周 循环序列模型"></a>第一周 循环序列模型</h3><h4 id="1-1-为什么选择序列模型"><a href="#1-1-为什么选择序列模型" class="headerlink" title="1.1 为什么选择序列模型"></a>1.1 为什么选择序列模型</h4><p><img src="assets/20180305154333482" alt="这里写图片描述"></p><ul><li><strong>语音识别</strong>：给定输入音频片段 X，输出一段文字 Y。输入输出都是序列模型，因为 X 是一个按时序播放的音频片段，Y 是一系列单词。</li><li><strong>音乐发生器</strong>：输入数据 X 可以是空集，也可以是单一的整数（表示音乐风格），也可能是生成的前几个音符。输出音乐序列 Y。</li><li><strong>情感分类</strong>：输入 X 是文字序列，输出评价指标。</li><li><strong>DNA序列分析</strong>：输入<strong>DNA</strong>序列 A、C、G、T 组成，输出各部分匹配的某种蛋白质。</li><li><strong>机器翻译</strong>：输入句子，输出另一种语言的翻译结果。</li><li><strong>视频动作识别</strong>：输入视频帧，输出识别其中的行为。</li><li><strong>命名实体识别</strong>：输入句子，暑促识别出句中的人名。</li></ul><p>这些序列模型基本都属于监督式学习，输入 X 和输出 Y 不一定都是序列模型。如果都是序列模型的话，模型长度不一定完全一致。</p><hr><h4 id="1-2-数学符号"><a href="#1-2-数学符号" class="headerlink" title="1.2 数学符号"></a>1.2 数学符号</h4><p>下面以命名实体识别为例，介绍序列模型的命名规则。示例语句为：</p><p><strong>Harry Potter and Hermione Granger invented a new spell.</strong></p><p>输入 x 包含 9 个单词，输出 y 即为 1 x 9 向量，每位表征对应单词是否为人名的一部分，1 表示是，0 表示否。很明显，该句话中“Harry”，“Potter”，“Hermione”，“Granger”均是人名成分，所以，对应的输出y可表示为：</p><script type="math/tex; mode=display">y=[1\quad 1\quad  0\quad  1\quad  1\quad  0\quad  0\quad  0\quad  0]</script><p>一般约定使用 $y^{<t>}$ 表示序列对应位置的输出，使用 $T_y$ 表示输出序列长度，则 $1≤t≤T_y$。</p><p>对于输入 x，表示为：</p><script type="math/tex; mode=display">[x^{<1>}\quad x^{<2>}\quad x^{<3>}\quad x^{<4>}\quad x^{<5>}\quad x^{<6>}\quad x^{<7>}\quad x^{<8>}\quad x^{<9>}]</script><p>同样， $x^{<t>}$ 表示序列对应位置的输入，$T_x$ 表示输入序列长度。注意，此例中，$T_x=T_y=9$，但是也存在 $T_x≠T_y$ 的情况。</p><p>如何来表示每个 $x^{<t>}$ 呢？方法是首先建立一个词汇库 vocabulary，尽可能包含更多的词汇。例如一个包含 10000 个词汇的词汇库为：</p><script type="math/tex; mode=display">\left[\begin{matrix}a \\and \\\cdot \\\cdot \\\cdot \\harry \\\cdot \\\cdot \\\cdot \\potter \\\cdot \\\cdot \\\cdot \\zulu\end{matrix}\right]</script><p>该词汇库可看成是 10000 x 1 的向量。值得注意的是自然语言处理 NLP 实际应用中的词汇库可达百万级别的词汇量。</p><p>然后，使用 one-hot 编码，例句中的每个单词 $x^{<t>}$ 都可以表示成10000 x 1的向量，词汇表中与 $x^{<t>}$ 对应的位置为 1，其它位置为 0。该 $x^{<t>}$ 为one-hot向量。值得一提的是如果出现词汇表之外的单词，可以使用 <strong>UNK</strong> （<strong>Unknow Word</strong>）或其他字符串来表示。</p><p>对于多样本，以上序列模型对应的命名规则可表示为：$x^{(i)<t>}$，$y^{(i)<t>}$，$T_x^{(i)}$，$T_y^{(i)}$。其中，$i$ 表示第 $i$ 个样本。不同样本的 $T_x^{(i)}$ 或 $T_y^{(i)}$ 都有可能不同。</p><hr><h4 id="1-3-循环神经网络模型"><a href="#1-3-循环神经网络模型" class="headerlink" title="1.3 循环神经网络模型"></a>1.3 循环神经网络模型</h4><p>对于序列模型，如果使用标准的神经网络，其模型结构如下：</p><p><img src="assets/20180305180556590" alt="这里写图片描述"></p><p>使用标准的神经网络模型存在两个问题：</p><p>第一个问题，<strong>不同样本的输入序列长度或输出序列长度不同</strong>，即 $T_x^{(i)}\neq T_x^{(j)}$，$T_y^{(i)}\neq T_y^{(j)}$，造成模型难以统一。解决办法之一是设定一个最大序列长度，对每个输入和输出序列<strong>补零</strong>并统一到最大长度。但是这种做法实际效果并不理想。</p><p>第二个问题，也是主要问题，这种标准神经网络结构并<strong>不共享</strong>从文本的不同位置上<strong>学到的特征</strong>。例如，如果 $x^{<1>}$ 是“Harry”是人名成分，我们希望当句子其它位置 $x^{<5>}$ 出现了 “Harry”，可以用到位置 1 已经学到的特征将它识别出来，这是<strong>共享特征</strong>的结果，如同 CNN 网络特点一样（将部分图片里学到的内容快速推广到图片的其他部分）。但是，上图所示的网络不具备共享特征的能力。值得一提的是，共享特征还有助于减少神经网络中的参数数量，一定程度上减小了模型的计算复杂度。例如上图所示的标准神经网络，假设每个 $x^{<t>}$ 扩展到最大序列长度为 100，且词汇表长度为 10000，则输入层就已经包含了 100 x 10000 个神经元了，权重参数很多，运算量将是庞大的。</p><p>标准的神经网络不适合解决序列模型问题，而循环神经网络（RNN）是专门用来解决序列模型问题的。RNN 模型结构如下：</p><p><img src="assets/20180305203908747" alt="这里写图片描述"></p><p>序列模型从左到右，依次传递，此例中， $T_x= T_y$。 $x^{<t>}$ 到 $y^{<t>}$ 之间是隐藏神经元。$a^{<t>}$ 会传入到第 $t+1$ 个元素中，作为输入。其中，$a^{<0>}$ 一般为零向量。</p><blockquote><p>如果从左到右的顺序读这个句子，将第一个词 $x^{<1>}$ 输入一个神经网络层，可以让神经网络尝试预测输出 $\hat y^{<1>}$，判断这是否是人名的一部分。当读到句中的第二个单词 $x^{<2>}$ 时，它不是仅用 $x^{<2>}$ 就预测出 $\hat y^{<2>}$，它也会输入一些来自时间步 1 的信息。具体而言，时间步 1 的激活值就会传递到时间步 2。然后，在下一个时间步，循环神经网络输入了单词 $x^{<3>}$ ，然后它尝试预测输出了预测结果 $\hat y^{<3>}$，等等，一直到最后一个时间步，输入 $x^{<T_x>}$ ，然后输出 $\hat y^{<T_y>}$。</p><p>如果 $T_x$ 和 $T_y$ 不相同，结构会需要作出一些改变。所以<strong>在每一个时间步中，循环神经网络传递一个激活值到下一个时间步中用于计算</strong>。</p></blockquote><p>RNN模型包含三类权重系数，分别是 $W_{ax}$，$W_{aa}$，$W_{ya}$。且不同元素之间同一位置共享同一权重系数。$W_ax$ 来表示管理着从 $x^{<1>}$ 到隐藏层的连接的一系列参数，每个时间步使用的都是<strong>相同的参数</strong> $W_ax$。而激活值也就是水平联系是由参数 $W_{aa}$ 决定的，同时每一个时间步都使用<strong>相同的参数</strong> $W_{aa}$，同样的输出结果由 $W_{ya}$ 决定 。</p><p><img src="assets/20180305212325555" alt="这里写图片描述"></p><p>RNN的正向传播（Forward Propagation）过程为：</p><script type="math/tex; mode=display">a^{<t>}=g(W_{aa}\cdot a^{<t-1>}+W_{ax}\cdot x^{<t>}+ba)\\\hat y^{<t>}=g(W_{ya}\cdot a^{<t>}+b_y)</script><p>其中，$g(⋅)$ 表示激活函数，不同的问题需要使用不同的激活函数。</p><p>为了简化表达式，可以对 $a^{<t>}$ 项进行整合：</p><script type="math/tex; mode=display">W_{aa}\cdot a^{<t-1>}+W_{ax}\cdot x^{<t>}=[W_{aa}\ \ W_{ax}]\left[\begin{matrix}a^{<t-1>} \\x^{<t>}\end{matrix}\right]\rightarrow W_a[a^{<t-1>},x^{<t>}]</script><p>则正向传播可表示为：</p><script type="math/tex; mode=display">a^{<t>}=g(W_a[a^{<t-1>},x^{<t>}]+b_a)\\\hat y^{<t>}=g(W_{y}\cdot a^{<t>}+b_y)</script><p>值得一提的是，以上所述的RNN为单向RNN，即按照从左到右顺序，单向进行，$\hat y^{<t>}$ 只与左边的元素有关。但是，有时候 $\hat y^{<t>}$ 也可能与右边元素有关。例如下面两个句子中，单凭前三个单词，无法确定 “Teddy” 是否为人名，必须根据右边单词进行判断。</p><p>He said, “Teddy Roosevelt was a great President.”</p><p>He said, “Teddy bears are on sale!”</p><p>因此，有另外一种RNN结构是双向RNN，简称为BRNN。$\hat y^{<t>}$ 与左右元素均有关系，我们之后再详细介绍。</p><hr><h4 id="1-4-通过时间的反向传播"><a href="#1-4-通过时间的反向传播" class="headerlink" title="1.4 通过时间的反向传播"></a>1.4 通过时间的反向传播</h4><p></p><p></p><h4 id="1-5-不同类型的循环神经网络"><a href="#1-5-不同类型的循环神经网络" class="headerlink" title="1.5 不同类型的循环神经网络"></a>1.5 不同类型的循环神经网络</h4><p></p><p></p><h4 id="1-6-语言模型和序列生成"><a href="#1-6-语言模型和序列生成" class="headerlink" title="1.6 语言模型和序列生成"></a>1.6 语言模型和序列生成</h4><p></p><p></p><h4 id="1-7-对新序列采样"><a href="#1-7-对新序列采样" class="headerlink" title="1.7 对新序列采样"></a>1.7 对新序列采样</h4><p></p><p></p><h4 id="1-8-带有神经网络的梯度消失"><a href="#1-8-带有神经网络的梯度消失" class="headerlink" title="1.8 带有神经网络的梯度消失"></a>1.8 带有神经网络的梯度消失</h4><p></p><p></p><h4 id="1-9-GRU-单元"><a href="#1-9-GRU-单元" class="headerlink" title="1.9 GRU 单元"></a>1.9 GRU 单元</h4><p></p><p></p><h4 id="1-10-长短期记忆（LSTM）"><a href="#1-10-长短期记忆（LSTM）" class="headerlink" title="1.10 长短期记忆（LSTM）"></a>1.10 长短期记忆（LSTM）</h4><p></p><p></p><h4 id="1-11-双向神经网络"><a href="#1-11-双向神经网络" class="headerlink" title="1.11 双向神经网络"></a>1.11 双向神经网络</h4><p></p><p></p><h4 id="1-12-深层循环神经网络"><a href="#1-12-深层循环神经网络" class="headerlink" title="1.12 深层循环神经网络"></a>1.12 深层循环神经网络</h4><p></p><p></p><h3 id="第二周-自然语言处理与词嵌入"><a href="#第二周-自然语言处理与词嵌入" class="headerlink" title="第二周 自然语言处理与词嵌入"></a>第二周 自然语言处理与词嵌入</h3><h4 id="2-1-词汇表征"><a href="#2-1-词汇表征" class="headerlink" title="2.1 词汇表征"></a>2.1 词汇表征</h4><p></p><h4 id="2-2-使用词嵌入"><a href="#2-2-使用词嵌入" class="headerlink" title="2.2 使用词嵌入"></a>2.2 使用词嵌入</h4><p></p><h4 id="2-3-词嵌入的特性"><a href="#2-3-词嵌入的特性" class="headerlink" title="2.3 词嵌入的特性"></a>2.3 词嵌入的特性</h4><p></p><h4 id="2-4-嵌入矩阵"><a href="#2-4-嵌入矩阵" class="headerlink" title="2.4 嵌入矩阵"></a>2.4 嵌入矩阵</h4><p></p><h4 id="2-5-学习词嵌入"><a href="#2-5-学习词嵌入" class="headerlink" title="2.5 学习词嵌入"></a>2.5 学习词嵌入</h4><p></p><h4 id="2-6-Word2Vec"><a href="#2-6-Word2Vec" class="headerlink" title="2.6 Word2Vec"></a>2.6 Word2Vec</h4><p></p><h4 id="2-7-负采样"><a href="#2-7-负采样" class="headerlink" title="2.7 负采样"></a>2.7 负采样</h4><p></p><h4 id="2-8-GloVe-词向量"><a href="#2-8-GloVe-词向量" class="headerlink" title="2.8 GloVe 词向量"></a>2.8 GloVe 词向量</h4><p></p><h4 id="2-9-情绪分类"><a href="#2-9-情绪分类" class="headerlink" title="2.9 情绪分类"></a>2.9 情绪分类</h4><p></p><h4 id="2-10-词嵌入除偏"><a href="#2-10-词嵌入除偏" class="headerlink" title="2.10 词嵌入除偏"></a>2.10 词嵌入除偏</h4><p></p><p></p><h3 id="第三周-序列模型和注意力机制"><a href="#第三周-序列模型和注意力机制" class="headerlink" title="第三周 序列模型和注意力机制"></a>第三周 序列模型和注意力机制</h3><h4 id="3-1-基础模型"><a href="#3-1-基础模型" class="headerlink" title="3.1 基础模型"></a>3.1 基础模型</h4><p></p><p></p><h4 id="3-2-选择最可能的句子"><a href="#3-2-选择最可能的句子" class="headerlink" title="3.2 选择最可能的句子"></a>3.2 选择最可能的句子</h4><p></p><p></p><h4 id="3-3-定向搜索"><a href="#3-3-定向搜索" class="headerlink" title="3.3 定向搜索"></a>3.3 定向搜索</h4><p></p><p></p><h4 id="3-4-改进定向搜索"><a href="#3-4-改进定向搜索" class="headerlink" title="3.4 改进定向搜索"></a>3.4 改进定向搜索</h4><p></p><p></p><h4 id="3-5-定向搜索的误差分析"><a href="#3-5-定向搜索的误差分析" class="headerlink" title="3.5 定向搜索的误差分析"></a>3.5 定向搜索的误差分析</h4><p></p><p></p><h4 id="3-6-Bleu-得分（选修）"><a href="#3-6-Bleu-得分（选修）" class="headerlink" title="3.6 Bleu 得分（选修）"></a>3.6 Bleu 得分（选修）</h4><p></p><p></p><h4 id="3-7-注意力模型直观理解"><a href="#3-7-注意力模型直观理解" class="headerlink" title="3.7 注意力模型直观理解"></a>3.7 注意力模型直观理解</h4><p></p><p></p><h4 id="3-8-注意力模型"><a href="#3-8-注意力模型" class="headerlink" title="3.8 注意力模型"></a>3.8 注意力模型</h4><p></p><p></p><h4 id="3-9-语音辨识"><a href="#3-9-语音辨识" class="headerlink" title="3.9 语音辨识"></a>3.9 语音辨识</h4><p></p><p></p><h4 id="3-10-触发字检测"><a href="#3-10-触发字检测" class="headerlink" title="3.10 触发字检测"></a>3.10 触发字检测</h4><p></p><p></p><h4 id="3-11-结论和致谢"><a href="#3-11-结论和致谢" class="headerlink" title="3.11 结论和致谢"></a>3.11 结论和致谢</h4><p></p><p></p>]]></content>
      
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C_DL_W4</title>
      <link href="/2022/03/28/C-DL-W4/"/>
      <url>/2022/03/28/C-DL-W4/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习工程师"><a href="#深度学习工程师" class="headerlink" title="深度学习工程师"></a>深度学习工程师</h1><p>由 deeplearning.ai 出品，网易引进的正版授权中文版深度学习工程师微专业课程，让你在了解丰富的人工智能应用案例的同时，学会在实践中搭建出最先进的神经网络模型，训练出属于你自己的 AI。<br><span id="more"></span></p><p><strong>CNN可视化</strong></p><p><a href="https://poloclub.github.io/cnn-explainer/">https://poloclub.github.io/cnn-explainer/</a></p><p>deeplearning.ai</p><p><a href="https://www.coursera.org/learn/neural-networks-deep-learning?action=enroll">https://www.coursera.org/learn/neural-networks-deep-learning?action=enroll</a></p><p><a href="https://study.163.com/my#/smarts">https://study.163.com/my#/smarts</a></p><p><a href="https://www.bilibili.com/video/av66646276">https://www.bilibili.com/video/av66646276</a></p><p><strong>note</strong></p><p><a href="https://redstonewill.blog.csdn.net/article/details/79055467">https://redstonewill.blog.csdn.net/article/details/79055467</a></p><p><a href="http://www.ai-start.com/dl2017/">http://www.ai-start.com/dl2017/</a></p><p><a href="https://www.zhihu.com/column/DeepLearningNotebook">https://www.zhihu.com/column/DeepLearningNotebook</a></p><p><strong>课后作业</strong></p><p><a href="https://blog.csdn.net/u013733326/article/details/79827273">https://blog.csdn.net/u013733326/article/details/79827273</a></p><p><a href="https://www.heywhale.com/mw/project/5e20243e2823a10036b542da">https://www.heywhale.com/mw/project/5e20243e2823a10036b542da</a></p><h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><ul><li>[ ] 特殊应用：人脸识别和神经风格转换-<a href="#4.7">4.7 CNN可视化解释</a>，伪影</li><li>[ ] 特殊应用：人脸识别和神经风格转换-<a href="#二维向量点积">4.10 style 损失函数-二维向量点积</a></li><li>[ ] 额外知识：白化</li></ul><h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><h3 id="第一周-卷积神经网络"><a href="#第一周-卷积神经网络" class="headerlink" title="第一周 卷积神经网络"></a>第一周 卷积神经网络</h3><h4 id="1-1-计算机视觉"><a href="#1-1-计算机视觉" class="headerlink" title="1.1 计算机视觉"></a>1.1 计算机视觉</h4><p>首先，计算机视觉的高速发展标志着新型应用产生的可能，这是几年前，人们所不敢想象的。通过学习使用这些工具，你也许能够创造出新的产品和应用。</p><p>其次，即使到头来你未能在计算机视觉上有所建树，也可以将<strong>所学的知识应用到其他算法和结构</strong>。</p><p>一张 64x64x3 的图片，神经网络输入层的维度为12288。一张 1000x1000x3 的图片，神经网络输入层的维度将达到 3M，使得网络权重 W 非常庞大。这样会造成两个后果，</p><ul><li>一是神经网络结构复杂，数据量相对不够，容易出现过拟合；</li><li>二是所需内存、计算量较大。</li></ul><p>解决这一问题的方法就是使用卷积神经网络（CNN）。</p><hr><h4 id="1-2-边缘检测示例"><a href="#1-2-边缘检测示例" class="headerlink" title="1.2 边缘检测示例"></a>1.2 边缘检测示例</h4><p>神经网络由浅层到深层，分别可以检测出图片的边缘特征 、局部特征（例如眼睛、鼻子等）、整体面部轮廓。</p><p><img src="assets/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMTI4MDkyMTM1NzA5" alt="这里写图片描述"></p><p>最常检测的图片边缘有两类：一是垂直边缘（vertical edges），二是水平边缘（horizontal edges）。</p><p><img src="assets/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMTI4MDkyODA1NTUz" alt="这里写图片描述"></p><p>图片的边缘检测可以通过与相应<strong>滤波器</strong>进行卷积来实现。以垂直边缘检测为例，原始图片尺寸为6x6，滤波器filter尺寸为3x3，卷积后的图片尺寸为4x4，得到结果如下：</p><p><img src="assets/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMTI4MTAwMzAwMDg1" alt="这里写图片描述"></p><p>卷积过程动态示意图</p><p><img src="assets/v2-6428cf505ac1e9e1cf462e1ec8fe9a68_b.webp" alt="img"></p><hr><h4 id="1-3-更多边缘检测内容"><a href="#1-3-更多边缘检测内容" class="headerlink" title="1.3 更多边缘检测内容"></a>1.3 更多边缘检测内容</h4><p>还有很多其他的滤波器（检测算子）</p><p><img src="assets/image-20210411155016785.png" alt="image-20210411155016785"></p><p>随着深度学习的发展，我们学习的其中一件事就是当你真正想去检测出复杂图像的边缘，你不一定要去使用那些研究者们所选择的这九个数字，但你可以从中获益匪浅。把这矩阵中的9个数字当成9个参数，并且在之后你可以学习使用<strong>反向传播</strong>算法，其目标就是去<strong>理解这9个参数</strong>。</p><p><img src="assets/image-20210411155020970.png" alt="image-20210411155020970"></p><p>将这9个数字当成参数的思想，已经成为计算机视觉中最为有效的思想之一。</p><hr><h4 id="1-4-Padding"><a href="#1-4-Padding" class="headerlink" title="1.4 Padding"></a>1.4 Padding</h4><p><strong>本小节步长全部为1</strong></p><p>valid convolution : no padding</p><p>输入 <em> 卷积核 → 输出维度   （n, n） </em> （f, f） →  （n - f + 1, n - f + 1）</p><p>same convolution: padding   一搬填充为0</p><p>输入 <em> 卷积核 → 输出维度   （n + 2p, n + 2p） </em> （f, f） →  （n  + 2p - f + 1, n  + 2p - f + 1）</p><p>如果希望输出维度和原始输入维度一样，则计算得</p><script type="math/tex; mode=display">p = \frac{f-1}{2}</script><p>这里也诠释了为什么卷积核一般为奇数尺寸。并且奇数有中心像素点，便于索引滤波器的位置。</p><p>odd number 奇数</p><p>even number 偶数</p><hr><h4 id="1-5-卷积步长"><a href="#1-5-卷积步长" class="headerlink" title="1.5 卷积步长"></a>1.5 卷积步长</h4><p>给定 padding : p 、strider: s</p><p>则有输入 <em> 卷积核 → 输出维度   （n, n） </em> （f, f） →  （$\frac{n+2p-f}{s}+1$, $\frac{n+2p-f}{s}+1$）</p><p>如果商不为整，向下取整 <code>floor</code>，有一部分超出范围就不进行计算。</p><p>相关系数（cross-correlations）与卷积（convolutions）之间是有区别的。真正的卷积运算（数学/信号处理）会先将filter绕其中心旋转180度，然后再将旋转后的filter在原始图片上进行滑动计算。filter旋转如下所示：</p><p><img src="assets/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMTI4MjAwNDU1MjI2" alt="这里写图片描述"></p><p>而在深度学习领域，默认不需要反转，直接求积。严格意义来讲我们<strong>平时使用的方法不叫卷积而叫互相关</strong>。</p><p>之所以可以这么等效，是因为<strong>滤波器算子一般是水平或垂直对称的</strong>，180度旋转影响不大；而且最终滤波器算子需要通过CNN网络梯度下降算法计算得到，<strong>旋转部分可以看作是包含在CNN模型算法</strong>中。总的来说，忽略旋转运算可以大大提高CNN网络运算速度，而且不影响模型性能。</p><hr><h4 id="1-6-三维卷积"><a href="#1-6-三维卷积" class="headerlink" title="1.6 三维卷积"></a>1.6 三维卷积</h4><p><img src="assets/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMTI4MjAzODUzNTI2" alt="这里写图片描述"></p><p>对于3通道的RGB图片，其对应的滤波器算子同样也是3通道的。例如一个图片是6 x 6 x 3，分别表示图片的高度（height）、宽度（weight）和通道（channel）。</p><p>过程是将每个单通道（R，G，B）与对应的filter进行卷积运算求和，然后再将<strong>3通道的和相加</strong>，得到输出图片的一个像素值。</p><p><strong>不同通道的滤波算子可以不相同</strong>。例如<strong>R</strong>通道filter实现<strong>垂直</strong>边缘检测，<strong>G和B</strong>通道<strong>不进行</strong>边缘检测，全部置零，或者将R，G，B三通道filter全部设置为水平边缘检测。</p><p>为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。</p><p><img src="assets/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMTI4MjMwNzA0Mjk3" alt="这里写图片描述"></p><p>则有输入 * 卷积核 → 输出维度   </p><script type="math/tex; mode=display">（n, n, n_c） * n_k（f, f, n_c） →  （\frac{n+2p-f}{s}+1, \frac{n+2p-f}{s}+1, n_k）</script><p>$n$ 为图片尺寸大小，也可用 h 和 w 表示高和宽，例中为 6 ；</p><p>$f$ 为卷积核尺寸大小，例中为 3 ；</p><p>$n_c$ 为图片通道数目，例中为2；</p><p>$n_k$ 为滤波器组个数，例中为2；</p><p>padding : p 为填充数，例中为0，无填充；</p><p>strider: s 为步长，例中为1。则有：</p><script type="math/tex; mode=display">（6, 6, 3） * 2（3, 3, 3） →  （4, 4, 2）</script><hr><h4 id="1-7-单层卷积网络"><a href="#1-7-单层卷积网络" class="headerlink" title="1.7 单层卷积网络"></a>1.7 单层卷积网络</h4><p><img src="assets/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMTI4MjMzMjQyNDk0" alt="这里写图片描述"></p><p>相比之前的卷积过程，CNN 的单层结构多了激活函数 ReLU 和偏移量b。整个过程与标准的神经网络单层结构非常类似：</p><script type="math/tex; mode=display">Z^{[l]}=W^{[l]} A^{[l-1]}+b\\A^{[l]}=g^{[l]}\left(Z^{[l]}\right)</script><p>输出 = 非线性激活函数（线性函数+偏差），例中 W 为卷积核，A 为输入图像，b 为偏置，g为 <code>relu</code> 。相当于有两个个待学习的参数：<strong>卷积核，偏差</strong></p><p>总结CNN单层结构的所有标记符号，设层数为 $l$。</p><p><strong>filter size:</strong> $f^{[l]}$                    滤波器尺寸</p><p><strong>padding:</strong> $p^{[l]}$                       填充</p><p><strong>stride:</strong> $s^{[l]}$                            步长</p><p><strong>number of filters:</strong> $n_{c}^{[l]}$      滤波器个数</p><p><strong>input:</strong> $n_{H}^{[l-1]} \times n_{\omega}^{[l-1]} \times n_{c}^{[l-1]} $     输入维度，l-1层</p><p><strong>output:</strong>  $n_{H}^{[l]} \times n_{\omega}^{[l]} \times n_{c}^{[l]}$             输出维度，l层</p><p>其中  </p><script type="math/tex; mode=display">\left.\begin{array}{l}n_{H}^{[l]}=\left[\frac{n_{H}^{[l-1]}+2 p^{[l]}-f^{[l]}}{s^{[l]}}+1\right. \\n_{W}^{[l]}=\left\lfloor\frac{n_{W}^{[l-1]}+2 p^{[l]}-f^{[l]}}{s^{[l]}}+1\right.\end{array}\right]</script><p><strong>filter:</strong> $f^{[l]} \times f^{[l]} \times n_{c}^{[l-1] }$                           滤波器维度，最后一维与输入channel相同</p><p><strong>weights:</strong> $f^{[l]} \times f^{[l]} \times n_{c}^{[l-1]} \times n_{c}^{[l]}$           权重维度 = 滤波器维度 * 滤波器个数 </p><p><strong>bias:</strong> $1 \times 1 \times 1 \times n_{c}^{[l]}$                                偏置维度，只与滤波器个数有关</p><p><strong>activations:</strong> $n_{H}^{[l]} \times n_{W}^{[l]} \times n_{c}^{[l]}$                  激活函数维度，与输出维度完全相同</p><p>如果<strong>mini-batch</strong>有m个样本，进行向量化运算，相应的输出维度为 $m \times n_{H}^{[l]} \times n_{\omega}^{[l]} \times n_{c}^{[l]}$</p><p>假设你有10个过滤器，神经网络的一层是3×3×3，那么，这一层有多少个参数呢？</p><p>我们来计算一下，每一层都是一个3×3×3的矩阵，因此每个过滤器有27个参数，也就是27个数。然后加上一个偏差，用参数表示，现在参数增加到28个现在我们有10个过滤器，加在一起是28×10，也就是280个参数。</p><hr><h4 id="1-8-简单卷积网络示例"><a href="#1-8-简单卷积网络示例" class="headerlink" title="1.8 简单卷积网络示例"></a>1.8 简单卷积网络示例</h4><p><img src="assets/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMTMwMTA1NTQ2MzIx" alt="这里写图片描述"></p><p>CNN模型各层结构如上图所示。需要注意的是，$a^{[3]}$ 的维度是 <code>7 x 7 x 40</code>，将 $a^{[3]}$ 排列成 1 列，维度为 <code>1960 x 1</code>，然后连接最后一级输出层。输出层可以是一个神经元，即二元分类（logistic）；也可以是多个神经元，即多元分类（softmax）。最后得到预测输出 $\hat y$ 。值得一提的是，随着CNN层数增加，$n_H^{[l]}$  和 $n_W^{[l]}$ 一般逐渐减小，而$n_c^{[l]}$ 一般逐渐增大。</p><p>CNN有三种类型的layer：</p><ul><li>Convolution层（CONV）</li><li>Pooling层（POOL）</li><li>Fully connected层（FC）</li></ul><hr><h4 id="1-9-池化层"><a href="#1-9-池化层" class="headerlink" title="1.9 池化层"></a>1.9 池化层</h4><p>缩减模型大小，提高计算速度，提高所提取特征的鲁棒性。</p><p><strong>最大池化</strong></p><p><img src="assets/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMTI5MjAyMzIyMzA2" alt="这里写图片描述"></p><p>这就像是应用了一个规模为2的过滤器，因为我们选用的是2×2区域，步幅是2，这些就是最大池化的超参数。</p><p><img src="assets/image-20210412151328057.png" alt="image-20210412151328057"></p><p><img src="assets/image-20210412151343259.png" alt="image-20210412151343259"></p><p><strong>数字大意味着可能探测到了某些特定的特征</strong>，左上象限具有的特征可能是一个垂直边缘，一只眼睛。显然左上象限中存在这个特征，这个特征可能是一只猫眼探测器。必须承认，使用最大池化的主要原因是此方法在很多实验中效果都很好。计算卷积层输出大小的公式同样适用于最大池化，即 $\frac{n+2p-f}{s}+1$</p><p><strong>平均池化</strong></p><p>选取的不是每个过滤器的最大值，而是平均值。</p><p><img src="assets/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMTI5MjAzODQxMzM2" alt="这里写图片描述"></p><p>目前来说，最大池化比平均池化更常用。但也有例外，就是深度很深的神经网络，可以用平均池化来分解规模为7×7×1000的网络的表示层，在整个空间内求平均值，得到1×1×1000。</p><p><strong>参数</strong></p><p>池化的超级参数包括过滤器大小 $f$ 和步幅 $s$ ,常用的参数值为 $f=2, s=2$，效果相当于高度和宽度缩减一半。很少用到超参数 padding。最常用的 padding 值是0，输入为$n_{H} \times n_{W} \times n_{c}$，输出为$ \lfloor\frac{n_{H}-f}{s}+1\rfloor \times\lfloor\frac{n_{\mathrm{w}}-f}{s}+ 1\rfloor \times n_{c}$。</p><p>输入与输出<strong>通道数相同</strong>，因为我们对每个通道都做了池化。需要注意的一点是，池化过程中<strong>没有需要学习的参数</strong>。执行反向传播时，反向传播没有参数适用于最大池化。这些设置过的超参数，可能是手动设置的，也可能是通过交叉验证设置的。</p><hr><h4 id="1-10-卷积神经网络示例"><a href="#1-10-卷积神经网络示例" class="headerlink" title="1.10 卷积神经网络示例"></a>1.10 卷积神经网络示例</h4><p>计算网络层数，通常是带有权重和参数的才算一层，想池化层和激活层就不算单独的一层。</p><p><img src="assets/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcxMTMwMTAyNTMwNTQ0" alt="这里写图片描述"></p><p>图中，<code>CON</code> 层后面紧接一个 <code>POOL</code> 层，<code>CONV1</code> 和 <code>POOL1</code> 构成第一层，<code>CONV2</code> 和 <code>POOL2</code> 构成第二层。特别注意的是 <code>FC3</code> 和 <code>FC4</code> 为全连接层 <code>FC</code>，它跟标准的神经网络结构一致。最后的输出层（softmax）由10个神经元构成。</p><p>随着神经网络深度的加深，<strong>高度和宽度都会减小</strong>，从 32×32 到 28×28，到 14×14，到 10×10，再到 5×5；<strong>而通道数量会增加</strong>，从 3 到 6 到 16 不断增加，然后得到一个全连接层。</p><p>接下来我们讲讲神经网络的<strong>激活值形状</strong>，<strong>激活值大小</strong>和<strong>参数数量</strong>。有几点要注意，第一，池化层没有参数；第二，<strong>卷积层的参数相对较少</strong>，第三，<strong>全连接层参数较多</strong>，其实许多参数都存在于神经网络的全连接层。观察可发现，<strong>随着神经网络的加深，激活值size会逐渐变小，如果激活值size下降太快，也会影响神经网络性能</strong>。</p><p>整个网络各层的尺寸和参数如下表格所示：</p><p><img src="assets/20200208104004691.png" alt="在这里插入图片描述"></p><p><code>CONV1</code> 参数$ = 6 \times （5\times5\times3+1）$    //+1为bias</p><p><code>CONV2</code> 参数$ = 16 \times （5\times5\times6+1）$</p><p><code>FC2</code> 参数$ = （400\times120）+120$</p><p><code>FC3</code> 参数$ = （120\times84）+84$</p><p><code>softmax</code> 参数$ = （84\times10）+10$</p><p>上边的conv算法是每个通道滤波器做的事情不一样，如果每个通道滤波器一致，则参数量要除以通道数。</p><p>常规做法是，<strong>尽量不要自己设置超参数</strong>，而是<strong>查看文献中别人采用了哪些超参数</strong>，<strong>选一个在别人任务中效果很好的架构</strong>，那么它也有可能适用于你自己的应用程序。</p><hr><h4 id="1-11-为什么使用卷积？"><a href="#1-11-为什么使用卷积？" class="headerlink" title="1.11 为什么使用卷积？"></a>1.11 为什么使用卷积？</h4><p>与全连接层相比，卷积层的两个主要优势在于</p><p><strong>参数共享</strong>：一个特征检测器（例如垂直边缘检测）对图片A的某块区域有用，同时也可能作用在图片A的其它区域。即不用对图像不同区域使用不同的滤波器，所有区域只使用一个滤波器处理即可。（如果不参数共享，滤波器滑一次变一次，即下一步用新的参数滑，参数过多）</p><p><strong>稀疏连接</strong>：因为滤波器算子尺寸限制，每一层的每个输出只与输入<strong>部分区域</strong>内有关。而且其它像素值都不会对输出产生任影响。</p><p><strong>平移不变性</strong>：神经网络的卷积结构使得即使移动几个像素，这张图片依然具有非常相似的特征，应该属于同样的输出标记。</p><p>除此之外，由于 CNN 参数数目较小，所需的训练样本就相对较少，从而一定程度上不容易发生过拟合现象。而且，CNN比较擅长捕捉区域位置偏移。也就是说CNN进行物体检测时，不太受物体所处图片位置的影响，增加检测的准确性和系统的健壮性。</p><hr><h4 id="1-12-interview-yann-lecun"><a href="#1-12-interview-yann-lecun" class="headerlink" title="1.12 interview yann-lecun"></a>1.12 interview yann-lecun</h4><p>lenet</p><p>Conditional Random Field 条件随机场</p><p>给开源社区做贡献</p><hr><h3 id="第二周-深度卷积网络：实例探究"><a href="#第二周-深度卷积网络：实例探究" class="headerlink" title="第二周 深度卷积网络：实例探究"></a>第二周 深度卷积网络：实例探究</h3><h4 id="2-1-为什么要进行实例探究？"><a href="#2-1-为什么要进行实例探究？" class="headerlink" title="2.1 为什么要进行实例探究？"></a>2.1 为什么要进行实例探究？</h4><p>典型的CNN模型包括：</p><ul><li><strong>LeNet-5</strong>-1998 LeCun</li><li><strong>AlexNet</strong>-2012年ImageNet竞赛冠军获得者Hinton和他的学生Alex Krizhevsky设计</li><li><strong>VGG</strong>-2014年ILSVRC竞赛的第二名，第一名是GoogLeNet。</li></ul><p>除了这些性能良好的CNN模型之外，Residual Network（ResNet）的特点是可以构建很深很深的神经网络（目前最深的好像有152层）。Inception Neural Network。</p><hr><h4 id="2-2-经典网络"><a href="#2-2-经典网络" class="headerlink" title="2.2 经典网络"></a>2.2 经典网络</h4><p><strong>LeNet-5</strong></p><p><img src="assets/20171211150034018" alt="这里写图片描述"></p><p>5 层，6W 个参数，平均池化，sigmoid 和 tanh 函数，直接输出类别</p><blockquote><p>Gradient-Based Learning Applied to Document Recognition</p></blockquote><p><strong>AlexNet</strong></p><p><img src="assets/20171211155720094" alt="这里写图片描述"></p><p>60M 个参数，最大池化，relu 函数，局部响应归一化层 Local Response Normalization，softmax 输出各类别概率</p><blockquote><p>ImageNet Classification with Deep Convolutional Neural Networks</p></blockquote><p><strong>VGG-16</strong></p><p><img src="assets/20171211175203203" alt="这里写图片描述"></p><p>16 层，138M 个参数，只用 3x3 same 卷积，最大池化，专注于构建卷积层的简单网络，简化了神经网络架构</p><p>随着网络的加深，<strong>图像缩小的比例和通道数增加的比例是有规律的</strong>。很吸引人。</p><blockquote><p>very deep convolutional networks for large-scale image recognition</p><p>Visual Geometry Group Network - 视觉几何群网络</p></blockquote><hr><h4 id="2-3-残差网络"><a href="#2-3-残差网络" class="headerlink" title="2.3 残差网络"></a>2.3 残差网络</h4><p>Residual Networks (ResNets)</p><p>非常深的网络会出现梯度消失和梯度爆炸问题</p><p>skip connection / short cut</p><blockquote><p>Deep Residual Learning for Image Recognition</p></blockquote><p><strong>残差块</strong></p><p><img src="assets/20171211204756960" alt="这里写图片描述"></p><p>上图中红色部分就是skip connection，直接建立 $a[l]$ 与 $a[l+2]$ 之间的隔层联系。相应的表达式如下：</p><script type="math/tex; mode=display">\begin{equation}z^{[l+1]}=W^{[l+1]} a^{[l]}+b^{[l+1]}\\a^{[l+1]}=g\left(z^{[l+1]}\right)\\z^{[l+2]}=W^{[l+2]}a^{[l+1]}+b^{[l+2]}\\a^{[l+2]}=g\left(z^{[l+2]}+a^{[l]}\right)\end{equation}</script><p>$a[l]$ 直接隔层与下一层的线性输出相连，与 $z[l+2]$ 共同通过激活函数（ReLU）输出$a[l+2]$。</p><p><img src="assets/image-20210414155426103.png" alt="image-20210414155426103"></p><p>由多个 Residual block 组成的神经网络就是 Residual Network。实验表明，这种模型结构对于训练非常深的神经网络，效果很好。Residual Network的结构如下图所示。</p><p><img src="assets/20171211211417392" alt="这里写图片描述"></p><p>另外，为了便于区分，我们把非 Residual Networks 称为 Plain Network。与 Plain Network 相比，Residual Network 能够训练更深层的神经网络，有效避免发生发生梯度消失和梯度爆炸。从下面两张图的对比中可以看出，随着神经网络层数增加，Plain Network 实际性能会变差，training error 甚至会变大。然而，Residual Network 的训练效果却很好，training error 一直呈下降趋势。</p><p><img src="assets/20171211213835572" alt="这里写图片描述"></p><hr><h4 id="2-4-残差网络为什么有用？"><a href="#2-4-残差网络为什么有用？" class="headerlink" title="2.4 残差网络为什么有用？"></a>2.4 残差网络为什么有用？</h4><p>网络在训练集上表现好，才能在验证集和测试集上表现好。</p><p><img src="assets/20171211215418919" alt="这里写图片描述"></p><p>如上图所示，输入 $x$ 经过很多层神经网络后输出 $a^{[l]}$ ，$a^{[l]}$ 经过一个 Residual block 输出$a^{[l+2]}$。$a^{[l+2]}$ 的表达式为：</p><script type="math/tex; mode=display">\begin{equation}a^{[l+2]}=g\left(z^{[l+2]}+a^{[l]}\right)=g\left(W^{[l+2]} a^{[l+1]}+b^{[l+2]}+a^{[l]}\right)\end{equation}</script><p>输入 $x$ 经过Big NN后，若 $W^{[l+2]}≈0$ ，$b^{[l+2]}≈0$，则有：</p><script type="math/tex; mode=display">\begin{equation}a^{[l+2]}=g\left(a^{[l]}\right)=\operatorname{ReL} U\left(a^{[l]}\right)=a^{[l]} \quad when \quad a^{[l]} \geq 0\end{equation}</script><p>可以看出，即使发生了梯度消失，$W^{[l+2]}≈0$ ，$b^{[l+2]}≈0$，也能直接建立 $a^{[l+2]}$ 与 $a^{[l]}$ 的线性关系，且 $a^{[l+2]}=a^{[l]}$，这其实就是 Identity function。$a^{[l]}$ 直接连到 $a^{[l+2]}$，从效果来说，<strong>相当于直接忽略了$a^{[l]}$之后的这两层神经层</strong>。</p><p>这样，看似很深的神经网络，其实由于许多 Residual blocks 的存在，<strong>弱化削减了某些神经层之间的联系</strong>，实现<strong>隔层线性传递</strong>，而<strong>不是一味追求非线性关系</strong>，模型本身也就能“容忍”更深层的神经网络了。而且从性能上来说，这两层额外的 Residual blocks 也不会降低 Big NN的性能。当然，如果 Residual blocks <strong>确实能训练得到非线性关系</strong>，那么也<strong>会忽略 short cut</strong>，跟 Plain Network 起到同样的效果。</p><p>有一点需要注意的是，ResNet中使用了<strong>same卷积</strong>，使得$a^{[l]}$ 和 $a^{[l+2]}$ 的<strong>维度相同</strong>；但如果 Residual blocks 中 $a^{[l]}$ 和 $a^{[l+2]}$ 的<strong>维度不同</strong>，通常可以引入矩阵$W_s$，与 $a^{[l]}$ 相乘，使得 $W_s<em>a^{[l]}$ 的维度与 $a^{[l+2]}$ 一致。参数矩阵 $W_s$ 有来两种方法得到：一种是将 $W_s$ <strong>作为学习参数</strong>，通过模型训练得到；另一种是固定 $W_s$ 值（类似单位矩阵），不需要训练，$W_s$ 与 $a^{[l]}$ 的乘积仅仅使得 $a^{[l]}$ <em>*截断或者补零</em></em>。这两种方法都可行。</p><p><strong>ResNet 结构</strong><img src="assets/image-20210414163056395.png" alt="image-20210414163056395"></p><p>上图为普通的网络，输入image，多个卷积层，最后输出一个Softmax。只需要添加 skip connection，就转换为 ResNet，如下图：</p><p><img src="assets/20171212142205247" alt="这里写图片描述"></p><p>ResNets 同类型层之间，例如 CONV layers(实线)，大多使用 Same 类型，保持维度相同。如果是不同类型层之间的连接，例如 CONV layer 与 POOL layer 之间(虚线)，如果维度不同，则引入矩阵 $W_s$。</p><blockquote><p>$W^{[l+2]}$, $b^{[l+2]}$ 就相当于一个开关，只要让这两个参数 w 和 b 为 0，就可以达到增加网络深度却不影响网络性能的目的。而<strong>是否把这两个参数置为 0 就要看反向传播</strong>，网络最终能够知道到底要不要skip。</p><p>何凯明说过其实 AlexNet 是解决太深导致梯度消失，因为随着层数的增加计算出的梯度  会慢慢变小，可以映射到激活值会慢慢变小，之后他就想加一个 skip connection就可以保证无论中间多少层，最终两端激活值大体上不改变。</p><p>当网络不断加深时，就算是选用学习恒等函数的参数都很困难，所以很多层最后的表现不但没有更好，反而更糟。</p><p>这保证了深度的增加不会给模型带来负面影响，<strong>至少不会比 Plain Network 差</strong>。<strong>残差块很容易学习恒等映射</strong></p></blockquote><hr><h4 id="2-5-Network-in-network-以及-1×1-卷积"><a href="#2-5-Network-in-network-以及-1×1-卷积" class="headerlink" title="2.5 Network in network 以及 1×1 卷积"></a>2.5 Network in network 以及 1×1 卷积</h4><p>池化层可以压缩高度和宽度。1x1卷积可以压缩通道数。</p><p>1x1卷积，处理多通道的数据。即不同通道的数据加权求和，然后通过非线性函数。</p><p>对于单个 filter，1x1 的维度，意味着卷积操作等同于乘积操作。对于多个filters，1x1 Convolutions 的作用实际上<strong>类似全连接层</strong>的神经网络结构。效果等同于 Plain Network 中 $a^{[l]}$ 到 $a^{[l+1]}$ 的过程。</p><p><img src="assets/20171212144647936" alt="这里写图片描述"></p><p>1x1 Convolutions 可以用来缩减输入图片的通道数目:</p><p><img src="assets/20171212145859683" alt="这里写图片描述"></p><blockquote><p>Network in network, lin, 2013.</p></blockquote><hr><h4 id="2-6-Inception-network-motivation"><a href="#2-6-Inception-network-motivation" class="headerlink" title="2.6 Inception network motivation"></a>2.6 Inception network motivation</h4><p>创始，开端</p><p>构建卷积层时，你要决定过滤器的大小究竟是1×1，3×3 还是 5×5，或者要不要添加池化层。而Inception网络的作用就是<strong>代替你来决定</strong>，虽然网络架构因此变得更加复杂，但网络表现却非常好。<strong>代替人工来确定</strong>卷积层中的过滤器类型，或者确定是否需要创建卷积层或池化层。</p><p>Inception Network 在单层网络上可以使用多个<strong>不同尺寸</strong>的filters，进行<strong>same convolutions</strong>，把各filter下得到的输出<strong>拼接</strong>起来。除此之外，还可以将CONV layer与POOL layer<strong>混合</strong>，同时实现各种效果。但是要注意使用<strong>same pool</strong>。</p><p><img src="assets/20171212151353599" alt="这里写图片描述"></p><p>Inception Network在提升性能的同时，会带来计算量大的问题。例如：</p><p><img src="assets/20171212172342457" alt="这里写图片描述"></p><p>对于输出中的每个数字来说，都需要执行 <code>5×5×192</code> 次乘法运算，所以乘法运算的总次数为每个输出值所需要执行的乘法运算次数 <code>5×5×192</code> 乘以输出值个数 <code>28×28×32</code>，把这些数相乘结果等于 120 M。如果输出为 <code>28x28</code>，则使用一个 <code>5x5x192</code> 的卷积核，对原始输入做乘积计算即可，要做 <code>28x28</code> 次。</p><p>为此，我们可以引入1x1 Convolutions来减少其计算量，结构如下：</p><p><img src="assets/20171212175549666" alt="这里写图片描述"></p><p>通常我们把该1x1 Convolution称为“瓶颈层”（bottleneck layer）。引入bottleneck layer之后，总共需要的计算量为：<code>1x1X192 x 28x28x16</code> 和 <code>5x5x16 x 28x28x32</code> 相加为12.4 M。多引入了1x1 Convolution层，总共的计算量减少了近90%。由此可见，1x1 Convolutions 还可以有效减少 CONV layer 的计算量。</p><p>那么仅仅大幅<strong>缩小表示层规模</strong>会不会<strong>影响神经网络的性能</strong>？事实证明，只要<strong>合理构建瓶颈层</strong>，你既可以显著缩小表示层规模，又不会降低网络性能，从而节省了计算。这就是<strong>Inception</strong>模块的主要思想。</p><blockquote><p>Going deeper with convolutions. Szegedy et al. 2014.</p></blockquote><hr><h4 id="2-7-Inception-网络"><a href="#2-7-Inception-网络" class="headerlink" title="2.7 Inception 网络"></a>2.7 Inception 网络</h4><p>盗梦空间</p><p>引入1x1 Convolution 后的 <strong>Inception module</strong> 如下图所示：</p><p><img src="assets/20171213204922094" alt="这里写图片描述"></p><p><strong>多个</strong> Inception modules <strong>组成</strong> Inception Network，效果如下图所示：</p><p><img src="assets/20171213211346970" alt="这里写图片描述"></p><p><strong>个别的module中间添加了最大池化层来修改高和宽的维度</strong>，上述 Inception Network 除了由许多 Inception modules 组成之外，值得一提的是网络中间隐藏层也可以作为输出层Softmax，有利于防止发生过拟合。</p><hr><h4 id="2-8-MobileNet"><a href="#2-8-MobileNet" class="headerlink" title="2.8 MobileNet"></a>2.8 MobileNet</h4><p>可以在低计算环境下能够构建和部署正常工作的新网络。</p><p><strong>正常卷积</strong></p><p><img src="assets/image-20210416002203682.png" alt="image-20210416002203682"></p><p>计算代价 =  滤波器参数   x   输出像素size   x   滤波器个数</p><p>   2160     =   3 x 3 x 3      x          4 x 4          x        5  </p><p><strong>深度可分离卷积</strong> Depthwise-separable convolutions </p><p><img src="assets/image-20210416000353405.png" alt="image-20210416000353405"></p><p>Depthwise convolution</p><p><img src="assets/image-20210416002825829.png" alt="image-20210416002825829"></p><p>​          $n_{out} \times n_{out}\times n_{c}$                             $3 \times 3\times n_{c}$                               $n_{out} \times n_{out} \times n_{c}$</p><p>输出的 channel 与输入 channel 和滤波器的 channel 一样，滤波器的每个 channel，对应输出的每个 channel，即<strong>每个输入的 channel 只与滤波器的一个 channel 计算</strong>。</p><p>计算代价 =  滤波器参数   x   输出像素size   x   滤波器个数</p><p>​     432     =        3 x 3       x          4 x 4          x        3  </p><p>Pointwise convolution<img src="assets/image-20210416002713830.png" alt="image-20210416002713830"></p><p>   $n_{out} \times n_{out}\times n_{c}$                          $n^{\prime} \times  1 \times 1\times n_{c}$                            $n_{out} \times n_{out} \times n^{\prime}$</p><p>$n^{\prime}$ 为滤波器的个数</p><p>计算代价 =  滤波器参数   x   输出像素size   x   滤波器个数</p><p>​     240     =    1 x 1 x 3     x          4 x 4          x        5  </p><p>深度可分离卷积与正常卷积的成本比率为：</p><script type="math/tex; mode=display">\frac{1}{n^{\prime}}+\frac{1}{f^2}</script><p>$n^{\prime}$ 为滤波器的个数，一般很大为64，128，256，512等</p><p>$f$ 为卷积核的尺寸，一般为 3</p><p>上例子中结果为 $\frac{1}{n^{\prime}}+\frac{1}{f^2}=\frac{1}{5}+\frac{1}{9}=\frac{432+240}{2160}$</p><p><strong>常规卷积</strong></p><p><img src="assets/v2-617b082492f5c1c31bde1c6e2d994bc0_720w.jpg" alt="img"></p><p><strong>深度可分离卷积</strong></p><ul><li>逐通道卷积</li></ul><p><img src="assets/v2-a20824492e3e8778a959ca3731dfeea3_720w.jpg" alt="img"></p><p><strong>无法扩展</strong> Feature map。而且这种运算对输入层的每个通道独立进行卷积运算，没有有效的利用<strong>不同通道在相同空间位置</strong>上的feature信息。</p><ul><li>逐点卷积</li></ul><p><img src="assets/v2-2cdae9b3ad2f1d07e2c738331dac6d8b_720w.jpg" alt="img"></p><p>将上一步的map在<strong>深度方向上进行加权组合</strong>，利用<strong>不同通道在相同空间位置</strong>上的feature信息，生成新的Feature map。</p><p>因此，在参数量相同的前提下，采用Separable Convolution的神经网络层数可以做的更深。</p><p><img src="assets/1503464-20191201220832846-1142021236.png" alt="img"></p><blockquote><p>MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications. Howard et al. 2017.</p></blockquote><hr><h4 id="2-9-MobileNet-架构"><a href="#2-9-MobileNet-架构" class="headerlink" title="2.9 MobileNet 架构"></a>2.9 MobileNet 架构</h4><p><img src="assets/1618544228267.png" alt="1618544228267"></p><p>13 个 mobile block（浅蓝色虚线块）</p><p><img src="assets/1618544247529.png" alt="1618544247529"></p><ul><li>通过扩展操作 ，增加了 bottleneck中的表示形式，允许网络学习更丰富的功能。（<strong>解决了v1中无法扩大通道的问题</strong>） </li><li>通过depthwise和projection可以把输出的尺寸减小，减少存储这些值所需的内存量，以便传递到下一个块。</li><li>残差连接</li></ul><p>17 个 new mobile block（红色实线瓶颈块）</p><p><img src="assets/1618548406500.png" alt="1618548406500"></p><p>n x n x 3 → n x n x 18 → n x n x 18 → n x n x 3</p><p>expansion： 18个 1x1x3    一般为<strong>原始通道的6倍</strong>作为下一层的通道数</p><p>depthwise：18个 3x3x18   用padding保持原始尺寸大小</p><p>pointwise/projection：3个 1x1x18</p><p>如果做分类就最后池化层，全连接层，softmax 输出概率</p><blockquote><p>MobileNetV2: Inverted Residuals and Linear Bottlenecks. Sandler et al. 2019</p></blockquote><p>刚好与resnet的block相反</p><hr><h4 id="2-10-EfficientNet"><a href="#2-10-EfficientNet" class="headerlink" title="2.10 EfficientNet"></a>2.10 EfficientNet</h4><p>MobileNet V1 和 V2 提供了一种实现神经网络的方法，在计算上更有效。但是有没有办法调整 MobileNet 或其他架构到特定的设备。也许正在针对不同品牌的手机，不同数量的计算资源，或不同的边缘设备实施计算机视觉算法。</p><p>如果有更多的计算资源，则希望神经网络大，以便获得更高的准确性；如果在计算上受到更多限制，也许想要一个运行速度更快的神经网络，以一点点准确性为代价。如何为特定设备<strong>自动放大或缩小</strong>神经网络？</p><p><img src="assets/1618550446381.png" alt="1618550446381"></p><p>EfficientNet，为您提供了一种方法。假设您有一个基准神经网络架构，输入的图像具有一定的分辨率 resolution，而您的新网络具有一定的深度 depth，并且各层具有一定的宽度 width。</p><p>三个变量</p><ul><li>可以按比例放大或缩小图片，可以使用高分辨率图像。新的图像分辨率为 r。蓝色发光表示高分辨率的图像。</li></ul><p><img src="assets/1618550796805.png" alt="1618550796805"></p><ul><li>可以改变神经网络的深度 d，使该网络更深。</li></ul><p><img src="assets/1618550842070.png" alt="1618550842070"></p><ul><li>可以更改这些层的宽度 w，使层更宽。</li></ul><p><img src="assets/1618550852515.png" alt="1618550852515"></p><p>问题是，给定特定的计算资源，r，d 和 w 之间的<strong>最佳权衡</strong>是什么，以获得<strong>最佳性能</strong>在您的计算资源之内？分辨率提高10％，深度增加50％，和宽度增加20％？</p><p><img src="assets/1618550954791.png" alt="1618550954791"></p><p>如果想针对特定设备调整神经网络架构，EfficientNet 可以解决这一问题。</p><p>使用MobileNet，已经学会了如何构建计算效率更高的层，而使用EfficientNet，还可以找到一种方法，可以扩大或缩小这些神经网络</p><blockquote><p>EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. Tan and Le, 2019.</p></blockquote><hr><h4 id="2-11-使用开源的实现方案"><a href="#2-11-使用开源的实现方案" class="headerlink" title="2.11 使用开源的实现方案"></a>2.11 使用开源的实现方案</h4><p>网络通常都需要很长的时间来训练，而或许有人已经使用多个<strong>GPU</strong>，通过庞大的数据集<strong>预先训练</strong>了这些网络，这样一来你就可以使用这些网络进行<strong>迁移学习</strong></p><hr><h4 id="2-12-迁移学习"><a href="#2-12-迁移学习" class="headerlink" title="2.12 迁移学习"></a>2.12 迁移学习</h4><p>你可以下载花费了别人好几周甚至几个月而做出来的开源的<strong>权重参数</strong>，把它当作一个<strong>很好的初始化</strong>用在你自己的神经网络上。用迁移学习把公共的数据集的知识迁移到你自己的问题上</p><p>假如说你要建立一个猫咪检测器，用来检测你自己的宠物猫。假如你的两只猫叫 Tigger 和 Misty，还有一种情况是，两者都不是。所以你现在有一个<strong>三分类问题</strong>。现在你可能没有Tigger 或者 Misty 的大量的图片，所以你的<strong>训练集会很小</strong>，你该怎么办呢？</p><p>建议你从网上下载一些神经网络开源的实现，把权重下载下来。有许多训练好的网络，你都可以下载。举个例子，<strong>ImageNet</strong>数据集，它有1000个不同的类别，因此这个网络会有一个<strong>Softmax</strong>单元，它可以输出1000个可能类别之一。</p><p>你可以去掉这个Softmax层，创建你<strong>自己的</strong>Softmax单元，用来输出 Tigger、Misty 和neither 三个类别。建议把<strong>所有的层看作是冻结的</strong>，<strong>冻结</strong>网络中所有层的<strong>参数</strong>，<strong>只需要训练和你的Softmax层有关的参数</strong>。这个<strong>Softmax</strong>层有三种可能的输出，Tigger<strong>、</strong>Misty或者都不是。</p><p>大多数深度学习框架也许会有<code>trainableParameter=0</code> 这样的参数，对于这些前面的层，你可能会设置这个参数。有时也会有<code>freeze=1</code> 这样的参数。在这个例子中，你<strong>只需要训练softmax层的权重，把前面这些层的权重都冻结</strong>。</p><p>另一个技巧，由于前面的层都冻结了，相当于一个<strong>固定的函数</strong>。取输入图像，然后把它映射到这层（<strong>softmax</strong>的前一层）的激活函数。所以这个能加速训练的技巧就是，如果我们先计算这一层，计算特征或者激活值，然后把它们存到硬盘里。对你的计算有用的一步就是对你的训练集中所有样本的这一层的激活值进行<strong>预计算</strong>，然后存储到硬盘里，然后在此之上训练<strong>softmax</strong>分类器。</p><p>因此如果你的任务只有一个很小的数据集，你可以这样做。要有一个<strong>更大的训练集</strong>怎么办呢？也许你有大量的 Tigger 和 Misty 的照片，还有两者都不是的，这种情况，你应该<strong>冻结更少的层</strong>。取后面几层的权重，用作<strong>初始化</strong>，然后从这里开始梯度下降。或者你可以<strong>直接去掉</strong>这几层，换成你自己的隐藏单元和你自己的<strong>softmax</strong>输出层但是有一个规律，</p><p>如果你有越来越多的数据，你需要冻结的层数越少，你能够训练的层数就越多。</p><p>最后，如果你有大量数据，你应该做的就是用开源的网络和它的权重，把所有的权重当作<strong>初始化</strong>，然后<strong>训练整个网络</strong>。再次注意，如果这是一个1000节点的<strong>softmax</strong>，而你只有三个输出，你需要你自己的<strong>softmax</strong>输出层来输出你要的标签。</p><p>如果你有越多的标定的数据，或者越多的<strong>Tigger</strong>、<strong>Misty</strong>或者两者都不是的图片，你可以训练<strong>更多的层</strong>。极端情况下，你可以用下载的权重只作为初始化，用它们来代替随机初始化，接着你可以用梯度下降训练，更新网络所有层的所有权重。</p><p>这就是卷积网络训练中的迁移学习，事实上，网上的公开数据集非常庞大，并且你下载的其他人已经训练好几周的权重，已经从数据中学习了很多了，你会发现，<strong>对于很多计算机视觉的应用，如果你下载其他人的开源的权重，并用作你问题的初始化，你会做的更好</strong>。总之，迁移学习是非常值得你考虑的，除非你有一个极其大的数据集和非常大的计算量预算来从头训练你的网络。</p><hr><h4 id="2-13-数据增强"><a href="#2-13-数据增强" class="headerlink" title="2.13 数据增强"></a>2.13 数据增强</h4><p>提高性能</p><p>无论是使用迁移学习用别人的预训练模型开始，或者从源代码开始训练模型，数据扩充会有帮助。</p><p>常用的Data Augmentation方法是对已有的样本集进行Mirroring和Random Cropping。垂直镜像对称，随机裁剪。</p><p>旋转，剪切（<strong>shearing</strong>：此处并非裁剪的含义，图像仅水平或垂直坐标发生变化）图像，扭曲变形等等。这些方法并没有坏处，太复杂所以使用很少。</p><p><img src="assets/20171214102716526" alt="这里写图片描述"></p><p>另一种Data Augmentation的方法是color shifting。color shifting就是对图片的RGB通道数值进行随意增加或者减少，改变图片<strong>色调</strong>。对<strong>R</strong>、<strong>G</strong> 和 <strong>B</strong> 的值是根据某种概率分布来决定的</p><p><img src="assets/20171214104357412" alt="这里写图片描述"></p><p>针对性地对图片的RGB通道进行PCA color augmentation，也就是对图片颜色进行主成分分析，<strong>对主要的通道颜色进行增加或减少</strong>，可以采用<strong>高斯扰动</strong>。这样也能增加有效的样本数量。可以查阅AlexNet的相关论文。<strong>算法对照片的颜色更改更具鲁棒性。</strong></p><hr><h4 id="2-14-计算机视觉现状"><a href="#2-14-计算机视觉现状" class="headerlink" title="2.14 计算机视觉现状"></a>2.14 计算机视觉现状</h4><p><strong>Benchmark</strong> 基准测试，<strong>Benchmark</strong>是一个评价方式，在整个计算机领域有着长期的应用。Benchmark在计算机领域应用最成功的就是性能测试，主要测试负载的执行时间、传输速度、吞吐量、资源占用率等。</p><blockquote><p>Wiki ：“As computer architecture advanced, it became more difficult to compare the performance of various computer systems simply by looking at their specifications.Therefore, tests were developed that allowed comparison of different architectures.”</p></blockquote><ul><li><p>集成</p><p>可以独立训练几个神经网络，并平均它们的输出。比如说随机初始化三个、五个或者七个神经网络，然后训练所有这些网络，然后平均它们的输出。</p></li><li><p><strong>Multi-crop at test time</strong></p><p>将数据扩充应用到你的测试图像。<strong>10-crop</strong></p><p><img src="assets/6027faa79b81f9940281ea36ca901504.png" alt="img"></p></li><li><p>灵活使用开源代码：</p><p>Use <strong>archittectures of networks</strong> published in the literature</p><p>Use open source <strong>implementations</strong> if possible</p><p>Use <strong>pretrained models</strong> and <strong>fine-tune</strong> on your dataset</p></li></ul><hr><h3 id="第三周-目标检测"><a href="#第三周-目标检测" class="headerlink" title="第三周 目标检测"></a>第三周 目标检测</h3><h4 id="3-1-目标定位"><a href="#3-1-目标定位" class="headerlink" title="3.1 目标定位"></a>3.1 目标定位</h4><p>boudingbox 参数表示bx, by, bh, bw</p><p><img src="assets/20180110222709201" alt="这里写图片描述"></p><p>输出的label可表示为：</p><script type="math/tex; mode=display">\left [  \begin{matrix}Pc \\bx \\by \\bh \\bw \\c1 \\c2 \\c3\end{matrix}  \right ]</script><p>Pc=1，表示有目标，即 $y_1=1$：</p><script type="math/tex; mode=display">L(\hat y,y)=(\hat y_1-y_1)^2+(\hat y_2-y_2)^2+\cdots+(\hat y_8-y_8)^2</script><p>Pc=0，表示无目标，其余7个参数没有意义，即 $y_1=0$：</p><script type="math/tex; mode=display">L(\hat y,y)=(\hat y_1-y_1)^2</script><p>当然，除了使用平方误差之外，还可以逻辑回归损失函数，类标签 $c_1,c_2,c_3$ 也可以通过softmax输出。平方误差已经能够取得比较好的效果。</p><hr><h4 id="3-2-特征点检测"><a href="#3-2-特征点检测" class="headerlink" title="3.2 特征点检测"></a>3.2 特征点检测</h4><p>landmark</p><p>人脸识别/骨架提取/姿态提取。输出特征点坐标。<strong>训练集标签里也要有特征点的准确位置</strong>。</p><p><img src="assets/20180111160539785" alt="这里写图片描述"></p><p><img src="assets/20180111162053588" alt="这里写图片描述"></p><hr><h4 id="3-3-目标检测"><a href="#3-3-目标检测" class="headerlink" title="3.3 目标检测"></a>3.3 目标检测</h4><p>滑动窗口法。首先在训练样本集上搜集相应的各种目标图片和非目标图片。注意<strong>训练集图片尺寸较小，尽量仅包含相应目标</strong>，如下图所示：</p><p><img src="assets/20180111164540407" alt="这里写图片描述"></p><p>然后，使用这些训练集构建CNN模型，使得模型有较高的识别率。</p><p>最后，在测试图片上，选择<strong>大小适宜的窗口</strong>、<strong>合适的步进长度</strong>，进行从左到右、从上倒下的滑动。每个窗口区域都送入之前构建好的 CNN 模型进行识别判断。若判断有目标，则此窗口即为目标区域；若判断没有目标，则此窗口为非目标区域。</p><p><img src="assets/20180111165958113" alt="这里写图片描述"></p><p>滑动窗口：窗口大，精度低，计算成本低；窗口小，精度高，计算成本高。</p><hr><h4 id="3-4-卷积的滑动窗口实现"><a href="#3-4-卷积的滑动窗口实现" class="headerlink" title="3.4 卷积的滑动窗口实现"></a>3.4 卷积的滑动窗口实现</h4><p>Convolutional implementation of sliding windows</p><p>滑动窗算法可以使用卷积方式实现，以提高运行速度，节约重复运算成本。滑动窗口算法卷积实现的第一步就是<strong>将全连接层转变成为卷积层</strong>，如下图所示：</p><p><img src="assets/20180111195724054" alt="这里写图片描述"></p><p>全连接层转变成卷积层的操作很简单，只需要使用与上层尺寸一致的滤波算子进行卷积运算即可。最终得到的输出层维度是1 x 1 x 4，代表4类输出值。</p><p>单个窗口区域卷积网络结构建立完毕之后，对于待检测图片，即可使用该网络参数和结构进行运算。例如16 x 16 x 3的图片，<strong>步进长度为2</strong>（因为用到了一次 2*2 的 max pool，所以滑动窗口的步长也是 2），CNN网络得到的输出层为2 x 2 x 4。其中，2 x 2表示共有4个窗口结果。对于更复杂的28 x 28 x3的图片，CNN网络得到的输出层为8 x 8 x 4，共64个窗口结果。</p><p><img src="assets/20180111203920946" alt="这里写图片描述"></p><p>滑动窗算法需要反复进行CNN正向计算，例如16 x 16 x 3的图片需进行4次，28 x 28 x3的图片需进行64次。而利用卷积操作代替滑动窗算法，则不管原始图片有多大，只需要进行一次CNN正向计算，因为其中<strong>共享了很多重复计算部分</strong>，这大大节约了运算成本。<strong>窗口步进长度与选择的MAX POOL大小有关</strong>。如果需要步进长度为4，只需设置MAX POOL为4 x 4即可。</p><blockquote><p>OverFeat: Integrated recognition, localization and detection using convolutional networks. Sermanet et al, 2014.</p></blockquote><hr><h4 id="3-5-Bounding-Box-预测"><a href="#3-5-Bounding-Box-预测" class="headerlink" title="3.5 Bounding Box 预测"></a>3.5 Bounding Box 预测</h4><p>相当于小节 3.5 = 3.1+ 3.4</p><p>上一小节，提高了速度，但是不能输出最精准的bounding box。YOLO（You Only Look Once）算法可以解决这类问题，生成更加准确的目标区域（如上图红色窗口）。</p><p>YOLO算法首先将原始图片分割成n x n网格，每个网格代表一块区域。为简化说明，下图中将图片分成3 x 3网格。</p><p><img src="assets/20180111214333011" alt="这里写图片描述"></p><p>然后，利用上一节卷积形式实现滑动窗口算法的思想，对该原始图片构建CNN网络，得到的输出层维度为 3 x 3 x 8。其中，3 x 3 对应9个网格，每个网格的输出包含8个元素：</p><script type="math/tex; mode=display">y=\left [\begin{matrix}Pc \\bx \\by \\bh \\bw \\c1 \\c2 \\c3\end{matrix}\right ]</script><p>如果目标中心坐标 $(b_x,b_y)$ 不在当前网格内，则当前网格 $P_c=0$；相反，则当前网格 $P_c=1$（即只看中心坐标是否在当前网格内）。判断有目标的网格中，$b_x,b_y,b_h,b_w$ 限定了目标区域。值得注意的是，当前网格左上角坐标设定为 $(0, 0)$，右下角坐标设定为 $(1, 1)$，$(b_x,b_y)$ 范围限定在 $[0,1]$ 之间，但是 $b_h,b_w$ 可以大于1。因为目标可能超出该网格，横跨多个区域。目标占几个网格没有关系，目标中心坐标必然在一个网格之内。</p><p><img src="assets/v2-edbde717a2b81750e550f2ddb04ad81e_1440w.jpg" alt="anchor boxes 如何起作用"></p><p>划分的网格可以更密一些。网格越小，则多个目标的中心坐标被划分到一个网格内的概率就越小，这恰恰是我们希望看到的。</p><blockquote><p>You Only Look Once: Unified real-time object detection. Redmon et al, 2015.</p></blockquote><hr><h4 id="3-6-交并比"><a href="#3-6-交并比" class="headerlink" title="3.6 交并比"></a>3.6 交并比</h4><p><strong>Intersection over union</strong></p><p>判断目标检测算法性能IoU，计算两个边界框合并集之比，一般大于0.5 即可通过。</p><p>IOU衡量了两个边界框重叠的相对大小，判断两个边界框是否相似。</p><p><img src="assets/20180112155405994" alt="这里写图片描述"></p><p>如上图所示，红色方框为真实目标区域，蓝色方框为检测目标区域。两块区域的交集为绿色部分，并集为紫色部分。蓝色方框与红色方框的接近程度可以用 IoU 比值来定义：</p><script type="math/tex; mode=display">IoU = \frac{I}{U}</script><p>IoU 可以表示任意两块区域的接近程度。IoU 值介于 0～1 之间，且越接近 1 表示两块区域越接近。</p><hr><h4 id="3-7-非极大值抑制"><a href="#3-7-非极大值抑制" class="headerlink" title="3.7 非极大值抑制"></a>3.7 非极大值抑制</h4><p>Non-max suppression：解决一个物体，多次被检测。输出概率最大的结果。 </p><p>YOLO算法中，可能会出现多个网格都检测出到同一目标的情况，例如几个相邻网格都判断出同一目标的中心坐标在其内。</p><p><img src="assets/20180112162956443" alt="这里写图片描述"></p><p>上图中，三个绿色网格和三个红色网格分别检测的都是同一目标。那如何判断哪个网格最为准确呢？方法是使用非最大值抑制算法。</p><p>图示中每个网格的 $P_c$ 值可以求出，$P_c$ 值反映了该网格包含目标中心坐标的可信度。首先选取  $P_c$  最大值对应的网格和区域，然后计算该区域与所有其它区域的IoU，剔除掉IoU大于阈值（例如0.5）的所有网格及区域。这样就能保证同一目标只有一个网格与之对应，且该网格Pc最大，最可信。接着，再从剩下的网格中选取 $P_c$ 最大的网格，重复上一步的操作。最后，就能使得每个目标都仅由一个网格和区域对应。如下图所示：</p><p><img src="assets/20180112164507109" alt="这里写图片描述"></p><p>总结一下非最大值抑制算法的流程：</p><ul><li><strong>1. 剔除Pc值小于某阈值（例如0.6）的所有网格；</strong></li><li><strong>2. 选取Pc值最大的网格，利用网格中的bounding box信息计算IoU，摒弃与该网格交叠较大的网格；</strong></li><li><strong>3. 对剩下的网格，重复步骤2。</strong></li></ul><p>删掉其余框有两个条件：Pc较低并且IoU相对高</p><p>上边的例子Pc是概率表示仅表示目标是车的概率，如果尝试同时检测三个对象，比如说行人、汽车、摩托，那么输出向量就会有三个额外的分量。事实证明，正确的做法是独立进行三次非极大值抑制，对每个输出类别都做一次</p><hr><h4 id="3-8-Anchor-Boxes"><a href="#3-8-Anchor-Boxes" class="headerlink" title="3.8 Anchor Boxes"></a>3.8 Anchor Boxes</h4><p>每个格子只能检测出一个目标。对于多个目标重叠的情况，应使用不同形状的Anchor Boxes。</p><p>如下图所示，同一网格出现了两个目标：人和车。为了同时检测两个目标，我们可以设置两个Anchor Boxes，Anchor box 1检测人，Anchor box 2检测车。也就是说，每个网格多加了一层输出。原来的输出维度是 3 x 3 x 8，现在是3 x 3 x 2 x 8（也可以写成3 x 3 x 16的形式）。这里的2表示有两个Anchor Boxes，用来在一个网格中同时检测多个目标。每个Anchor box都有一个Pc值，若两个Pc值均大于某阈值，则检测到了两个目标。<br><img src="assets/image-20210419202712681.png" alt="image-20210419202712681"></p><p>现在<strong>每个对象都和之前一样分配到同一个格子中</strong>，即对象中心所在的格子。同时也需要<strong>分配到和目标形状 IoU 最高的 Anchor Box</strong>。例如有两个 Anchor Box 而单元格中只剩一个对象，则选取IoU高的，另一个的输出 $P_c$ 则为0。与第一个box的IoU高，则把信息填在向量前半部分：</p><script type="math/tex; mode=display">y=\left [\begin{matrix}P_c \quadb_x \quadb_y \quadb_h \quadb_w \quadc_1 \quadc_2 \quadc_3 \quadP_c \quadb_x \quadb_y \quadb_h \quadb_w \quadc_1 \quadc_2 \quadc_3\end{matrix}\right ]^T</script><p>使用YOLO算法时，只需对每个Anchor box使用上一节的非最大值抑制即可。Anchor Boxes之间并行实现。</p><p>目前anchor box的选择主要有三种方式：</p><ul><li>人为经验选取</li><li>k-means聚类</li><li>作为超参数进行学习</li></ul><p><strong>为什么不直接将bounding box参数加入loss进行训练？</strong></p><p>首先注意 yolo v1 就是这样做的，即 anchor-free，直接预测具体的boundng box参数。至于yolo v2/v3使用anchor-box的原因如下：</p><ul><li><p>误差对大的box和小的box有一样的权重，但是对于大的box和小的box是不能按一样的速度进行更新的，较小的误差对于大的box就没有对小的box那么重要。</p></li><li><p><strong>降低学习难度。</strong>anchor给出了目标宽高的初始值，需要回归的是目标真实<strong>宽高</strong>与初始宽高的<strong>偏移量</strong>，而不使用anchor的做法需要回归宽高的<strong>绝对量</strong>。</p></li></ul><hr><h4 id="3-9-YOLO-算法"><a href="#3-9-YOLO-算法" class="headerlink" title="3.9 YOLO 算法"></a>3.9 YOLO 算法</h4><p><img src="assets/20180112174544272" alt="这里写图片描述"></p><p>输入图片，通过网络预测，得到一个张量。得到所有 $p_c$ 不为 0 的bounding box。如下图：</p><p><img src="assets/image-20210419214233973.png" alt="image-20210419214233973"></p><p>通过非极大值抑制。</p><ul><li><strong>1. 剔除Pc值小于某阈值（例如0.6）的所有网格；</strong>（下图左→下图中）</li><li><strong>2. 选取Pc值最大的网格，利用网格中的bounding box信息计算IoU，摒弃与该网格交叠较大的网格；</strong>（下图中→下图右，就是把概率最大的邻居bounding box删除掉）</li><li><strong>3. 对剩下的网格，重复步骤2。</strong></li></ul><p><img src="assets/image-20210419214403342.png" alt="image-20210419214403342"></p><hr><h4 id="3-10-R-CNN"><a href="#3-10-R-CNN" class="headerlink" title="3.10 R-CNN"></a>3.10 R-CNN</h4><p>之前的算法在显然没有任何目标的区域仍进行计算。因此提出 Region proposals 候选区域。具体做法是先对原始图片进行<strong>分割</strong>算法处理，然后对分割后的图片中的块进行目标检测。</p><p><img src="assets/20180112203741567" alt="这里写图片描述"></p><p>R-CNN（Regions with Convolutional Neural Network Features）。Region Proposals 共有三种方法：</p><ul><li>R-CNN:  求候选区域，然后运行分类网络。输入区域-输出标签和bounding box（anchor-free）。</li><li>Fast R-CNN: 利用卷积实现滑动窗算法，类似3.4小节。</li><li>Faster R-CNN: 利用<strong>卷积</strong>对图片进行<strong>分割</strong>（segmentation）RPN，进一步提高运行速度。</li></ul><p>比较而言，Faster R-CNN的运行速度还是比YOLO慢一些。首先得到候选区域，然后再分类。</p><p>候选区域/框 + 深度学习分类：通过提取候选区域，并对相应区域进行以深度学习方法为主的分类的方案：</p><p>R-CNN（Selective Search + CNN + SVM）</p><p>Fast R-CNN（Selective Search + CNN + ROI）</p><p>Faster R-CNN（RPN + CNN + ROI）</p><p>基于深度学习的回归方法：YOLO/SSD/DenseBox 等方法</p><blockquote><p>Selective Search &gt; 根据颜色，边缘，纹理找可能存在的目标候选框。</p><p>ROI Pooling &gt; 将proposal抠出来的过程，然后resize到统一的大小。</p><p>RPN &gt; Region Proposal Network</p><p>SPPNet &gt; 空间金字塔池化实现任意大小图像输入。</p><p>Rich feature hierarchies for accurate object detection and semantic segmentation. Girshik et al, 2013.</p><p>Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition. Kaiming He.</p></blockquote><hr><h4 id="3-11-语义分割U-Net"><a href="#3-11-语义分割U-Net" class="headerlink" title="3.11 语义分割U-Net"></a>3.11 语义分割U-Net</h4><p>语义分割，目的是绘制在检测到的物体周围绘制详细的轮廓，以便您确切地知道哪个像素属于目标，哪些像素不属于目标。</p><p>什么是语义分割？</p><p>如果您想让学习算法找出这张图片中的每个像素是什么，那么您可以使用语义分割算法其目标是输出最右图。</p><p><img src="assets/image-20210419231140171.png" alt="image-20210419231140171"></p><p>通过语义分割，算法尝试标记道路的每个像素，都以深绿色表示。自动驾驶团队使用它来准确找出哪些像素可以安全行驶。</p><p>让我们看看其他一些应用程序。在左图的胸部 X 光检查图像中，使用不同的颜色分割出肺部，心脏和锁骨。右图脑MRI扫描自动分割出肿瘤。</p><p><img src="assets/image-20210419231437782.png" alt="image-20210419231437782"></p><p>为了简单起见，让我们使用以下示例从某些背景中细分出一辆汽车。在此图像中 1 代表汽车，2 代表建筑物，3 代表道路。</p><p><img src="assets/image-20210419231923288.png" alt="image-20210419231923288"></p><p>传统分类问题</p><p><img src="assets/image-20210419233112899.png" alt="image-20210419233112899"></p><p>转变为语义分割问题</p><p><img src="assets/image-20210419233152297.png" alt="image-20210419233152297"></p><p>语义分割的一个关键步骤是将<strong>越来越小</strong>的图像尺寸<strong>逐渐放大</strong>回完整的输入图像尺寸。</p><p><img src="assets/image-20210419233239505.png" alt="image-20210419233239505"></p><p>随着深度增加，变小的 size 将变大，而增大的通道数将减少，最终得到了猫的分割图。</p><hr><h4 id="3-12-转置卷积"><a href="#3-12-转置卷积" class="headerlink" title="3.12 转置卷积"></a>3.12 转置卷积</h4><p>transpose convolution</p><p>从信息论的角度看，卷积是<strong>不可逆的</strong>。所以这里说的并不是从 output 矩阵和 kernel 矩阵计算出原始的 input 矩阵。而是计算出一个<strong>保持了位置性关系</strong>的矩阵。</p><p><img src="assets/854641-20180816102917864-126549672.png" alt="img"></p><p>重叠的部分相加。转置卷积，它所进行的操作本质上就是先对输入进行 padding，然后再进行卷积得到输出。</p><p>input 为 2x2，filter 为 3x3，result 为 5x5。padding = 1，stride = 2</p><p><img src="assets/20180109202649694" alt="img"></p><p>转换为矩阵的形式是由卷积的结果得到的，矩阵形式本身是不能直接获得的。要注意这个因果关系，转换为矩阵形式是为了便于理解，以及推导转置卷积。</p><p>kernel_size = 2, stride = 1, padding = 0</p><p><img src="assets/1908255-20201029213626867-500143807.png" alt="img"></p><p>kernel_size = 2, stride = 1, padding = 1</p><p><img src="assets/1908255-20201029222848628-1109349561.png" alt="img"></p><p>与上一张图的主要不同之处在于转置卷积将卷积结果的最外层去掉，这是因为padding=1，也正符合与卷积相反的操作。也就是说，padding越大，转置卷积就会去掉越多的外层，输出就会越小。</p><p>kernel_size = 3, stride = 1, padding = 1</p><p><img src="assets/1908255-20201029223524056-20868724.png" alt="img"></p><p>kernel_size = 2, stride = 2, padding = 1</p><p><img src="assets/1908255-20201029224539185-1232935316.png" alt="img"></p><blockquote><p>直接理解转置卷积（Transposed convolution）的各种情况 <a href="https://www.cnblogs.com/qizhou/p/13895967.html">https://www.cnblogs.com/qizhou/p/13895967.html</a></p></blockquote><hr><h4 id="3-13-U-Net架构直觉"><a href="#3-13-U-Net架构直觉" class="headerlink" title="3.13 U-Net架构直觉"></a>3.13 U-Net架构直觉</h4><p>正卷积用于网络的前半部分，对图像进行压缩。图片尺寸变小，深度很大，丢失了很多空间信息。后半部分使用转置卷积放大到原始输入图像的 size（低分辨率和高水平的特征信息）。因此通过skip-connection使神经网络获取（高分辨率和低水平的特征信息)</p><hr><h4 id="3-14-U-Net架构"><a href="#3-14-U-Net架构" class="headerlink" title="3.14 U-Net架构"></a>3.14 U-Net架构</h4><p><img src="assets/image-20210420010905023.png" alt="image-20210420010905023"></p><p>输入为 h x w x 3，conv 增加 channel，maxpool 减小size。trans conv 增加 size，减少 channel （浅蓝色为转置卷积输出）。注意每次转置卷积后，与 skip-connection 拼接后<strong>要过几次正向卷积</strong>。输出为 h x w x nc（nc为分类数目）。采用argmax，将每个像素分类为其中一个类别。</p><p><strong>损失函数</strong>用了 pixel-wise softmax，就是每个像素对应的输出单独做 softmax，也就是做了 h * w 个 softmax。其中，x 可以看作是某一个像素点， $l(x)$ 表示 x 这个点对应的类别 label，$p_k(x)$ 表示在 x 这个点的输出在类别 k 的 softmax 的值，$p_{l(x)}(x)$ 代表点 x 在对应的 label 给出的那个类别的输出的值。</p><p><img src="assets/edc4cabd5b84b3f4928743ce2673ab5d.webp" alt="img"></p><blockquote><p>Ｕ-Net: Convolutional Networks for Biomedical Image Segmentation. Ronneberger et al, 2015.</p></blockquote><hr><h3 id="第四周-特殊应用：人脸识别和神经风格转换"><a href="#第四周-特殊应用：人脸识别和神经风格转换" class="headerlink" title="第四周 特殊应用：人脸识别和神经风格转换"></a>第四周 特殊应用：人脸识别和神经风格转换</h3><h4 id="4-1-什么是人脸识别？"><a href="#4-1-什么是人脸识别？" class="headerlink" title="4.1 什么是人脸识别？"></a>4.1 什么是人脸识别？</h4><p>介绍一下人脸验证（face verification）和人脸识别（face recognition）的区别。</p><ul><li>人脸验证：输入一张人脸图片，验证输出与模板是否为同一人，即一对一问题。</li><li>人脸识别：输入一张人脸图片，验证输出是否为 K 个模板中的某一个，即一对多问题。</li></ul><p>一般地，人脸识别比人脸验证更难一些。因为假设人脸验证系统的错误率是1%，那么在人脸识别中，输出分别与K 个模板都进行比较，则相应的错误率就会增加，约 K %。模板个数越多，错误率越大一些。</p><hr><h4 id="4-2-One-Shot-学习"><a href="#4-2-One-Shot-学习" class="headerlink" title="4.2 One-Shot 学习"></a>4.2 One-Shot 学习</h4><p>One-shot learning 就是说数据库中每个人的训练样本只包含一张照片，然后训练一个 CNN 模型来进行人脸识别。若数据库有 K 个人，则CNN模型输出 softmax 层就是 K 维的。但是 One-shot learning 的性能并不好，其包含了两个缺点：</p><p>每个人只有一张图片，训练样本少，构建的 CNN 网络不够健壮。</p><p>若数据库增加另一个人，输出层 softmax 的维度就要发生变化，相当于要重新构建 CNN 网络，使模型计算量大大增加，不够灵活。</p><p>为了解决 One-shot learning 的问题，我们先来介绍相似函数（similarity function）。相似函数表示两张图片的相似程度，用 $d(img1,img2)$ 来表示。若 $d(img1,img2)$ 较小，则表示两张图片相似；若 $d(img1,img2)$ 较大，则表示两张图片不是同一个人。相似函数可以在人脸验证中使用：</p><ul><li>$d(img1,img2)\leq \tau$ : 一样</li><li>$d(img1,img2)&gt; \tau$ : 不一样</li></ul><p>对于人脸识别问题，则只需计算测试图片与数据库中 K 个目标的相似函数，取其中  $d(img1,img2)$  最小的目标为匹配对象。若所有的  $d(img1,img2)$  都很大，则表示数据库没有这个人。</p><p><img src="assets/20180114153250005" alt="这里写图片描述"></p><hr><h4 id="4-3-Siamese-网络"><a href="#4-3-Siamese-网络" class="headerlink" title="4.3 Siamese 网络"></a>4.3 Siamese 网络</h4><p>若一张图片经过一般的 CNN 网络（包括 CONV 层、POOL 层、FC 层），最终得到全连接层 FC，该 FC 层可以看成是原始图片的编码 encoding，表征了原始图片的关键特征。这个网络结构我们称之为 Siamese network。也就是说每张图片经过 Siamese network 后，由 FC 层每个神经元来表征。</p><p><img src="assets/20180114155747719" alt="这里写图片描述"></p><p>建立Siamese network后，两张图片 $x^{(1)}$ 和 $x^{(2)}$ 的相似度函数可由各自FC层 $f(x^{(1)})$ 与 $f(x^{(2)})$ 之差的范数来表示：</p><script type="math/tex; mode=display">d(x^{(1)},x^{(2)})=||f(x^{(1)})-f(x^{(2)})||^2</script><p>值得一提的是，不同图片的 CNN 网络所有结构和参数都是一样的。我们的目标就是利用梯度下降算法，不断调整网络参数，使得属于同一人的图片之间 $d(x^{(1)},x^{(2)})$ 很小，而不同人的图片之间 $d(x^{(1)},x^{(2)})$ 很大。</p><p>若 $x^{(i)},x^{(j)}$ 是同一个人，则 $||f(x^{(i)})-f(x^{(j)})||^2$ 较小</p><p>若 $x^{(i)},x^{(j)}$ 不是同一个人，则 $||f(x^{(i)})-f(x^{(j)})||^2$ 较大</p><blockquote><p>DeepFace closing the gap to human level performance. Taigman et al, 2014.</p></blockquote><hr><h4 id="4-4-Triplet-损失"><a href="#4-4-Triplet-损失" class="headerlink" title="4.4 Triplet 损失"></a>4.4 Triplet 损失</h4><p>margin  软间隔</p><p>Triplet Loss 需要每个样本包含三张图片：靶目标（Anchor）、正例（Positive）、反例（Negative），这就是triplet 名称的由来。顾名思义，靶目标和正例是同一人，靶目标和反例不是同一人。Anchor 和 Positive 组成一类样本，Anchor 和 Negative 组成另外一类样本。</p><p><img src="assets/20180114174246276" alt="这里写图片描述"></p><p>我们希望上一小节构建的CNN网络输出编码 $f(A)$ 接近  $f(P)$ ，即 $||f(A)-f(P)||^2$ 尽可能小，而 $||f(A)-f(N)||^2$ 尽可能大，数学上满足：</p><script type="math/tex; mode=display">||f(A)-f(P)||^2\leq ||f(A)-F(N)||^2\\||f(A)-f(P)||^2-||f(A)-F(N)||^2\leq 0</script><p>根据上面的不等式，如果所有的图片都是零向量，即 $f(A)=0,f(P)=0,f(N)=0$，那么上述不等式也满足。但是这对我们进行人脸识别没有任何作用，是不希望看到的。我们希望得到 $||f(A)-f(P)||^2$ 远小于$||f(A)-f(N)||^2$ 。所以，我们添加一个超参数 $α$，且 $α&gt;0$，对上述不等式做出如下修改：</p><script type="math/tex; mode=display">||f(A)-f(P)||^2-||f(A)-F(N)||^2\leq -\alpha\\||f(A)-f(P)||^2-||f(A)-F(N)||^2+\alpha \leq 0</script><p>这里的 $α$ 也被称为边界 margin，类似与支持向量机中的 margin。接下来，我们根据A，P，N三张图片，就可以定义Loss function为：</p><script type="math/tex; mode=display">L(A,P,N)=max(||f(A)-f(P)||^2-||f(A)-F(N)||^2+\alpha,\ 0)</script><p>相应地，对于m组训练样本，cost function为：</p><script type="math/tex; mode=display">J=\sum_{i=1}^mL(A^{(i)},P^{(i)},N^{(i)})</script><p>关于训练样本，必须保证同一人包含多张照片，否则无法使用这种方法。例如 10k 张照片包含 1k 个不同的人脸，则平均一个人包含 10 张照片。这个训练样本是满足要求的。然后，就可以使用梯度下降算法，不断训练优化 CNN 网络参数，让 $J$ 不断减小接近0。</p><p>同一组训练样本，A，P，N 的选择尽可能不要使用随机选取方法。因为随机选择的 A 与 P 一般比较接近，A 与 N 相差也较大，毕竟是两个不同人脸。这样的话，也许模型不需要经过复杂训练就能实现这种明显识别，但是抓不住关键区别。所以，最好的做法是人为选择 <strong>A 与 P 相差较大</strong>（例如换发型，留胡须等），<strong>A 与 N 相差较小</strong>（例如发型一致，肤色一致等）。这种人为地<strong>增加难度和混淆度</strong>会让模型本身去寻找学习不同人脸之间关键的差异，“尽力”让 $d(A,P)$ 更小，让 $d(A,N)$ 更大，即<strong>让模型性能更好</strong>。</p><p><img src="assets/20180114215601633" alt="这里写图片描述"></p><blockquote><p>FaceNet: A unified embedding for face recognition and clustering. Schroff et al, 2015.</p></blockquote><hr><h4 id="4-5-面部验证与二分类"><a href="#4-5-面部验证与二分类" class="headerlink" title="4.5 面部验证与二分类"></a>4.5 面部验证与二分类</h4><p>除了构造 triplet loss 来解决人脸识别问题之外，还可以使用二分类结构。做法是将两个 siamese 网络组合在一起，将各自的编码层输出经过一个逻辑输出单元，该神经元使用 sigmoid 函数，输出 1 则表示识别为同一人，输出 0 则表示识别为不同人。结构如下：</p><p><img src="assets/20180115084732270" alt="这里写图片描述"></p><p>每组训练样本包含两张图片，每个 siamese 网络结构和参数完全相同。这样就把人脸识别问题转化成了一个二分类问题。引入逻辑输出层参数 w 和 b，输出 $\hat{y}$ 表达式为：</p><script type="math/tex; mode=display">\hat y=\sigma(\sum_{k=1}^Kw_k|f(x^{(i)})_k-f(x^{(j)})_k|+b)</script><p>其中参数 $w_k$ 和 $b$ 都是通过梯度下降算法迭代训练得到。$\hat{y}$ 的另外一种表达式为：</p><script type="math/tex; mode=display">\hat y=\sigma(\sum_{k=1}^Kw_k\frac{(f(x^{(i)})_k-f(x^{(j)})_k)^2}{f(x^{(i)})_k+f(x^{(j)})_k}+b)</script><p>上式被称为 $χ$ 方公式，也叫 $χ$ 方相似度。</p><p>在训练好网络之后，进行人脸识别的常规方法是测试图片与模板分别进行网络计算，编码层输出比较，计算逻辑输出单元。</p><p>为了<strong>减少计算量</strong>，可以使用<strong>预计算</strong>的方式在训练时就将数据库每个模板的<strong>编码层输出</strong> $f(x)$ <strong>保存</strong>下来。因为编码层输出 $f(x)$ 比原始图片数据量少很多，所以无须保存模板图片，只要保存每个模板的 $f(x)$ 即可，节约存储空间。而且，测试过程中，无须计算模板的 siamese 网络，只要计算测试图片的 siamese 网络，得到的 $f(x^{(i)})$ 直接与存储的模板 $f(x^{(j)})$ 进行下一步的逻辑输出单元计算即可，计算时间减小了接近一半。这种方法也可以应用在上一节的 triplet loss 网络中。</p><hr><h4 id="4-6-什么是神经风格转换？"><a href="#4-6-什么是神经风格转换？" class="headerlink" title="4.6 什么是神经风格转换？"></a>4.6 什么是神经风格转换？</h4><p>它可以实现将一张图片的风格“迁移”到另外一张图片中，生成具有其特色的图片。</p><p><img src="assets/20180115102626472" alt="这里写图片描述"></p><p>一般用 C 表示内容图片，S 表示风格图片，G 表示生成的图片。</p><hr><h4 id="4-7-深度卷积网络在学什么？"><a href="#4-7-深度卷积网络在学什么？" class="headerlink" title="4.7 深度卷积网络在学什么？"></a>4.7 深度卷积网络在学什么？<span id ="4.7"></span></h4><p>典型的CNN网络如下所示：</p><p><img src="assets/20180115133731838" alt="这里写图片描述"></p><p>首先来看第一层隐藏层，<strong>遍历所有训练样本</strong>，<strong>针对每个卷据核</strong>，都找出让该层<strong>激活函数输出最大的9块图像区域</strong>；得到9 x 9的图像如下所示，其中每个3 x 3区域表示一个运算单元。左上角红框是通过第一个隐藏单元，并激活后输出最大的 9 副图像。第一层一共 9 个隐藏单元，另外 8 个如下。</p><p><img src="assets/20180115141321684" alt="这里写图片描述"></p><p>可以看出，第一层隐藏层一般检测的是原始图像的<strong>边缘和颜色阴影</strong>等简单信息。继续看CNN的更深隐藏层，随着层数的增加，捕捉的区域更大，特征更加复杂，从边缘到纹理再到具体物体。</p><p><img src="assets/1424e99481bed31de3f1c78a8bb544fbc81.png" alt="img"></p><p>层1展示了物体边缘、颜色等图像中底层的特征</p><p>层2展示了物体的边缘和轮廓，以及与颜色的组合；</p><p>层3拥有了更复杂的不变性，展示了相似的纹理，网格；花纹；</p><p>层4开始体现类与类之间的差异，其中不同组别的重构特征之间存在重大差异性；狗脸，鸟腿</p><p>层5展示了存在重大差异的一类物体；键盘，狗。</p><p>本文通过反卷积可视化</p><p><img src="assets/eb60d01ca0925ee8445ee2d60e90ceda8b2.png" alt="img"></p><p>从右边卷积的过程开始，首先用卷积核 F 对上一层池化出来的 Pooled Maps 进行卷积，得到 Feature Maps，然后在逐步进行 Relu 归一化 (Rectified Linear) 和最大值池化（Max Pooling）。</p><p>而反卷积过程则是从反最大值池化开始（Max unpooling），逐步得到unpooled、rectified unpooled和reconstruction map。</p><p><strong>反卷积神经网络主要组成部分：</strong></p><ul><li>反池化：</li></ul><p>对于最大值池化来说，它是不可逆的过程，因此作者的技巧就是在池化的时<strong>候记录下每个最大值的位置</strong>。这样的话，在反池化的时候只要把池化过程中最大激活值所在的位置激活，<strong>其它位置的值赋0</strong>。</p><ul><li>反激活：</li></ul><p>对于 Relu 激活函数来，激活值均为非负值。因此对于反向过程，同样需要保证每层的特征值为非负值，因此Reluctant <strong>反激活过程和激活过程相同</strong>。</p><ul><li>反卷积：</li></ul><p>卷积网络就是网络利用学习到的卷积核对上一层的特征进行卷积得到本层的 feature map。而反卷积就是这个过程的逆过程，用本层的 feature map 与<strong>转置后的卷积核</strong>进行卷积，得到上一层的特征。就是转置卷积。</p><p><strong>可视化网络如何提升网络性能？</strong></p><p>作者可视化了原版 AlexNet 各特征层，发现了对于 AlexNet 来说，第一层（图b）的卷积核大部分是高频和低频的特征，而对中频段图像特征整提取得不好。同时，第二层特征的可视化的结果（图d）显示出了由于第一层卷积步长 4 太大导致的 “混叠伪影”(aliasing artifacts)。因此作者对 AlexNet 的改善包括：将第一层的卷积核从 11x11 减小为 7x7（图c)；将卷积步长减小为 2 (图e）。经过作者改善后的模型在第一层和第二层特征中保留了更多的信息，提高了分类性能。</p><p><img src="assets/1618900252405.png" alt="1618900252405"></p><blockquote><p>Visualizing and understanding convolutional networks. Zeiler and Fergus., 2013.</p></blockquote><hr><h4 id="4-8-代价函数"><a href="#4-8-代价函数" class="headerlink" title="4.8 代价函数"></a>4.8 代价函数</h4><p>神经风格迁移生成图片 $G$ 的cost function由两部分组成：$C$ 与 $G$ 的相似程度和 $S$ 与 $G$ 的相似程度。</p><script type="math/tex; mode=display">J(G)=\alpha \cdot J_{content}(C,G)+\beta \cdot J_{style}(S,G)</script><p>其中，$α, β$ 是超参数，用来调整 $J_{content}(C,G)$ 与 $J_{style}(S,G)$ 的相对比重。</p><p><img src="assets/20180115151648087" alt="这里写图片描述"></p><p>神经风格迁移的基本算法流程是：</p><p>首先令 $G：100\times 100\times 3$ 为随机像素点，</p><p>然后使用梯度下降算法 $G = G - \frac{\part}{\part G}J(G)$，不断修正 $G$ 的所有像素点，使得 $J(G)$ 不断减小，从而使 $G$ 逐渐有 $C$ 的内容和 $G$ 的风格，如下图所示。</p><p><img src="assets/20180115153352106" alt="这里写图片描述"></p><blockquote><p>A neural algorithm of artistic style. Gatys et al, 2015. </p><p>Image on slide generated by Justin Johnson.</p></blockquote><hr><h4 id="4-9-content-代价函数"><a href="#4-9-content-代价函数" class="headerlink" title="4.9 content 代价函数"></a>4.9 content 代价函数</h4><p>我们先来看 $J(G)$ 的第一部分 $J_{content}(C,G)$，它表示内容图片 $C$ 与生成图片 $G$ 之间的相似度。</p><script type="math/tex; mode=display">J(G)=\alpha \cdot J_{content}(C,G)+\beta \cdot J_{style}(S,G)</script><p>使用预训练好的的 CNN 网络（AlexNet，VGG等）。$C，S，G$ <strong>共用相同模型和参数</strong>。首先，需要选择合适的层数 $l$ 来计算 $J_{content}(C,G)$。根据小节 4.7 的内容，CNN 的每个隐藏层分别提取原始图片的不同深度特征，由简单到复杂。如果 $l$ 太小，则 $G$ 与 $C$ 在像素上会非常接近，没有迁移效果；如果 $l$ 太深，则 $G$ 上某个区域将直接会出现 $C$ 中的物体。因此，$l$ 既不能太浅也不能太深，一般选择网络中间层。</p><p>然后比较 $C$ 和 $G$ 在 $l$ 层的激活函数输出 $a^{<a href="C">l</a>}$ 与 $a^{<a href="G">l</a>}$。相应的 $J_{content}(C,G)$ 的表达式为(L2范数)：</p><script type="math/tex; mode=display">J_{content}(C,G)=\frac12||a^{[l](C)}-a^{[l](G)}||^2</script><p> $a^{<a href="C">l</a>}$ 与 $a^{<a href="G">l</a>}$越相似，则说明两个图片的内容相似，则 $J_{content}(C,G)$ 越小。$\frac{1}{2}$ 为归一化操作，可以通过总 cost 函数的超参数 $\alpha$ 进行学习。</p><p>方法就是使用梯度下降算法，不断迭代修正 $G$ 的像素值，使 $J_{content}(C,G)$ 不断减小。</p><hr><h4 id="4-10-style-损失函数"><a href="#4-10-style-损失函数" class="headerlink" title="4.10 style 损失函数"></a>4.10 style 损失函数</h4><p>我们来看 $J(G)$ 的第二部分 $J_{style}(S,G)$，它表示内容图片 $S$ 与生成图片 $G$ 之间的相似度。</p><script type="math/tex; mode=display">J(G)=\alpha \cdot J_{content}(C,G)+\beta \cdot J_{style}(S,G)</script><p>什么是图片的风格？利用CNN网络模型，图片的风格可以定义成第 $l$ 层隐藏层不同通道间激活函数的乘积（相关性）。</p><p><img src="assets/20180115174238740" alt="这里写图片描述"></p><p>例如我们选取第 $l$ 层隐藏层，其各通道使用不同颜色标注，如下图所示。因为每个通道提取图片的特征不同，比如 1 通道（红色）提取的是图片的垂直纹理特征，2 通道（黄色）提取的是图片的橙色背景特征。那么计算这两个通道的相关性大小，相关性越大，表示原始图片及既包含了垂直纹理也包含了该橙色背景；相关性越小，表示原始图片并没有同时包含这两个特征。也就是说，计算不同通道的相关性，反映了原始图片特征间的相互关系，从某种程度上刻画了图片的“风格”。</p><p><img src="assets/20180115175808478" alt="这里写图片描述"></p><p>接下来我们就可以定义图片的风格矩阵（style matrix）为：</p><script type="math/tex; mode=display">G_{kk'}^{[l]}=\sum_{i=1}^{n_H^{[l]}}\sum_{j=1}^{n_W^{[l]}}a_{ijk}^{[l]}a_{ijk'}^{[l]}</script><p>其中，$a$ 表示 $k$ 通道上 $[i,j]$ 位置的激活值。$[l]$ 表示第 $l$ 层隐藏层，$k，k’$ 分别表示不同通道，总共通道数为 $n_C^{[l]}$。$i，j$ 分别表示该隐藏层的高度和宽度。如果两个 $a$ 都大，相乘也大，对应的 $G$ 也大，相关性高。</p><p>风格矩阵 $G_{kk’}^{[l]}$ 计算第 $l$ 层隐藏层不同通道对应的所有激活函数输出和。$G_{kk’}^{[l]}$ 的维度为 $n_c^{[l]} \times n_c^{[l]}$。若<strong>两个通道之间相似性高</strong>，则对应的 $G_{kk’}^{[l]}$ <strong>较大</strong>；若<strong>两个通道之间相似性低</strong>，则对应的  $G_{kk’}^{[l]}$  <strong>较小</strong>。</p><p>风格矩阵 $G_{kk’}^{<a href="S">l</a>}$ 表征了风格图片 $S$ 第 $l$ 层隐藏层的“风格”。相应地，生成图片 $G$ 也有 $G_{kk’}^{<a href="G">l</a>}$。那么，$G_{kk’}^{<a href="S">l</a>}$ 与 $G_{kk’}^{<a href="G">l</a>}$ 越相近，则表示 $G$ 的风格越接近 $S$。这样，我们就可以定义出的 $J^{[l]}_{style}(S,G)$ 表达式：</p><script type="math/tex; mode=display">J^{[l]}_{style}(S,G)=\frac{1}{(2n_H^{[l]}n_W^{[l]}n_C^{[l]})}\sum_{k=1}^{n_C^{[l]}}\sum_{k'=1}^{n_C^{[l]}}||G_{kk'}^{[l][S]}-G_{kk'}^{[l][G]}||_F^2</script><p>其中 $\frac{1}{(2n_H^{[l]}n_W^{[l]}n_C^{[l]})}$ 为归一化常数，定义完 $J^{[l]}_{style}(S,G)$ 之后，我们的目标就是使用梯度下降算法，不断迭代修正 $G$ 的像素值，使$J^{[l]}_{style}(S,G)$ 不断减小。<strong>Frobenius</strong>范数，实际上是计算两个矩阵对应元素相减的平方的和。</p><p>以上我们只比较计算了一层隐藏层 $l$ 。为了提取的“风格”更多，使用多层隐藏层，然后相加：</p><script type="math/tex; mode=display">J_{style}(S,G)=\sum_l\lambda^{[l]}\cdot J^{[l]}_{style}(S,G)</script><p>其中，$λ^{[l]}$ 表示累加过程中各层 $J^{[l]}_{style}(S,G)$ 的权重系数，为超参数。根据以上两小节的推导，最终的 cost function 为：</p><script type="math/tex; mode=display">J(G)=\alpha \cdot J_{content}(C,G)+\beta \cdot J_{style}(S,G)</script><p>使用梯度下降算法进行迭代优化。</p><p>即先对<strong>风格图</strong>和<strong>生成图</strong>的每一层滤波 feature map 分别求 gram 矩阵，再求其距离的平方和，再将 5 层的结果加权求和。</p><p><img src="assets/v2-27dcd5a25b5625cb92d97e02c12919c2_720w.jpg" alt="img"></p><p><strong>什么是 gram 矩阵，为啥要用 gram 矩阵？</strong></p><p>Gram 矩阵就是每一层滤波后的 feature map, 后将其转置并相乘得到的矩阵，如下图所示。其实就是<strong>不同滤波器滤波结果 feature map 两两之间的相关性</strong>。譬如说，（如下图）某一层中有一个滤波器专门检测尖尖的塔顶这样的东西，另一个滤波器专门检测黑色。又有一个滤波器负责检测圆圆的东西，又有一个滤波器用来检测金黄色。</p><p><img src="assets/899363-20171225164406634-1290119748.png" alt="img"></p><p><img src="assets/899363-20171225164426900-422413788.png" alt="img"></p><p>对梵高的原图做Gram矩阵，谁的相关性会比较大呢？如上图所示，“尖尖的”和“黑色”总是一起出现的，它们的相关性比较高。而“圆圆的”和“金黄色”都是一起出现的，他们的相关性比较高。因此在风格转移的时候，其实也在风景图里去寻找这种“匹配”，<strong>将尖尖的渲染为黑色</strong>，<strong>将圆圆的渲染为金黄色</strong>。如果我们承认“<strong>图像的艺术风格就是其基本形状与色彩的组合方式</strong>” ，这样一个假设，那么Gram矩阵能够表征艺术风格就是理所当然的事情了。</p><p><strong>为什么G大相关性就大？</strong><span id = "二维向量点积"></span></p><p>从向量点乘角度有助于理解格拉姆矩阵。向量点乘可以看作衡量两个向量的相似程度，对于二维向量来说，两个单位向量，方向一致，点乘为1，相互垂直，点乘为0，方向相反，点乘为-1.因为在单位向量的情况下，结果由两个向量夹角cos的值决定。而对于多维向量，向量点乘就是对应位置乘积之后相加，得到的结果仍然是标量，含义和二维向量一样。</p><p>向量内积又可以体现两个向量之间的相似性</p><p>非对角线上的值代表第 $i$ 个特征和第 $j$ 个特征的相关性，比如<strong>共同出现</strong>，<strong>此消彼长</strong>等等</p><p>协方差的本质是内积。标准差的本质是模长。相关系数的本质是夹角余弦。</p><p>点积本身的性质，在二维空间，点积可以想象成一条直线在另一条直线上的投影。点击为零表示相互垂直。</p><p><strong>Gram 矩阵与协方差矩阵和相关系数矩阵差别</strong></p><p>Gram 矩阵和协方差矩阵的差别在于，Gram 矩阵<strong>没有白化</strong>，也就是没有<strong>减去均值</strong>，直接使用两向量做内积。</p><p>Gram 矩阵和相关系数矩阵的差别在于，Gram 矩阵既<strong>没有白化</strong>，也没有标准化（也就是除以两个向量的标准差）。</p><p>Gram 所表达的意义和协方差矩阵相差不大，只是显得比较粗糙。两个向量的协方差表示两向量之间的相似程度，协方差越大越相似。对角线的元素的值越大，表示其所代表的向量或者说特征越重要。</p><blockquote><p>A neural algorithm of artistic style. Gatys et al, 2015.</p></blockquote><hr><h4 id="4-11-一维到三维推广"><a href="#4-11-一维到三维推广" class="headerlink" title="4.11 一维到三维推广"></a>4.11 一维到三维推广</h4><p>我们之前介绍的CNN网络处理的都是2D图片，举例来介绍2D卷积的规则：</p><p><img src="assets/20180115210830278" alt="这里写图片描述"></p><p>输入图片维度：14 x 14 x 3</p><p>滤波器尺寸：5 x 5 x 3，滤波器个数：16</p><p>输出图片维度：10 x 10 x 16</p><p>将2D卷积推广到1D卷积，举例<strong>EKG</strong>心跳信号来介绍1D卷积的规则：</p><p><img src="assets/20180115210923590" alt="这里写图片描述"></p><p>输入时间序列维度：14 x 1</p><p>滤波器尺寸：5 x 1，滤波器个数：16</p><p>输出时间序列维度：10 x 16</p><p>对于3D卷积，举例来介绍其规则：</p><p><img src="assets/20180115211442581" alt="这里写图片描述"></p><p>输入3D图片维度：14 x 14 x 14 x 1</p><p>滤波器尺寸：5 x 5 x 5 x 1，滤波器个数：16</p><p>输出3D图片维度：10 x 10 x 10 x 16</p><hr><h1 id="深度学习工程师-1"><a href="#深度学习工程师-1" class="headerlink" title="深度学习工程师"></a>深度学习工程师</h1><p>由 deeplearning.ai 出品，网易引进的正版授权中文版深度学习工程师微专业课程，让你在了解丰富的人工智能应用案例的同时，学会在实践中搭建出最先进的神经网络模型，训练出属于你自己的 AI。</p><p>deeplearning.ai</p><p><a href="https://www.coursera.org/learn/neural-networks-deep-learning?action=enroll">https://www.coursera.org/learn/neural-networks-deep-learning?action=enroll</a></p><p><a href="https://study.163.com/my#/smarts">https://study.163.com/my#/smarts</a></p><p><a href="https://www.bilibili.com/video/av66647398">https://www.bilibili.com/video/av66647398</a></p><p><strong>note</strong></p><p><a href="https://redstonewill.blog.csdn.net/article/details/79446105">https://redstonewill.blog.csdn.net/article/details/79446105</a></p><p><a href="http://www.ai-start.com/dl2017/">http://www.ai-start.com/dl2017/</a></p><p><strong>课后作业</strong></p><p><a href="https://blog.csdn.net/u013733326/article/details/79827273">https://blog.csdn.net/u013733326/article/details/79827273</a></p><p><a href="https://www.heywhale.com/mw/project/5e20243e2823a10036b542da">https://www.heywhale.com/mw/project/5e20243e2823a10036b542da</a></p><h2 id="Question-1"><a href="#Question-1" class="headerlink" title="Question"></a>Question</h2><ul><li>[ ] 特殊应用：人脸识别和神经风格转换-<a href="#4.7">4.7 CNN可视化解释</a>，伪影</li></ul><h2 id="序列模型"><a href="#序列模型" class="headerlink" title="序列模型"></a>序列模型</h2><h3 id="第一周-循环序列模型"><a href="#第一周-循环序列模型" class="headerlink" title="第一周 循环序列模型"></a>第一周 循环序列模型</h3><h4 id="1-1-为什么选择序列模型"><a href="#1-1-为什么选择序列模型" class="headerlink" title="1.1 为什么选择序列模型"></a>1.1 为什么选择序列模型</h4><p><img src="assets/20180305154333482" alt="这里写图片描述"></p><ul><li><strong>语音识别</strong>：给定输入音频片段 X，输出一段文字 Y。输入输出都是序列模型，因为 X 是一个按时序播放的音频片段，Y 是一系列单词。</li><li><strong>音乐发生器</strong>：输入数据 X 可以是空集，也可以是单一的整数（表示音乐风格），也可能是生成的前几个音符。输出音乐序列 Y。</li><li><strong>情感分类</strong>：输入 X 是文字序列，输出评价指标。</li><li><strong>DNA序列分析</strong>：输入<strong>DNA</strong>序列 A、C、G、T 组成，输出各部分匹配的某种蛋白质。</li><li><strong>机器翻译</strong>：输入句子，输出另一种语言的翻译结果。</li><li><strong>视频动作识别</strong>：输入视频帧，输出识别其中的行为。</li><li><strong>命名实体识别</strong>：输入句子，暑促识别出句中的人名。</li></ul><p>这些序列模型基本都属于监督式学习，输入 X 和输出 Y 不一定都是序列模型。如果都是序列模型的话，模型长度不一定完全一致。</p><hr><h4 id="1-2-数学符号"><a href="#1-2-数学符号" class="headerlink" title="1.2 数学符号"></a>1.2 数学符号</h4><p>下面以命名实体识别为例，介绍序列模型的命名规则。示例语句为：</p><p><strong>Harry Potter and Hermione Granger invented a new spell.</strong></p><p>输入 x 包含 9 个单词，输出 y 即为 1 x 9 向量，每位表征对应单词是否为人名的一部分，1 表示是，0 表示否。很明显，该句话中“Harry”，“Potter”，“Hermione”，“Granger”均是人名成分，所以，对应的输出y可表示为：</p><script type="math/tex; mode=display">y=[1\quad 1\quad  0\quad  1\quad  1\quad  0\quad  0\quad  0\quad  0]</script><p>一般约定使用 $y^{<t>}$ 表示序列对应位置的输出，使用 $T_y$ 表示输出序列长度，则 $1≤t≤T_y$。</p><p>对于输入 x，表示为：</p><script type="math/tex; mode=display">[x^{<1>}\quad x^{<2>}\quad x^{<3>}\quad x^{<4>}\quad x^{<5>}\quad x^{<6>}\quad x^{<7>}\quad x^{<8>}\quad x^{<9>}]</script><p>同样， $x^{<t>}$ 表示序列对应位置的输入，$T_x$ 表示输入序列长度。注意，此例中，$T_x=T_y=9$，但是也存在 $T_x≠T_y$ 的情况。</p><p>如何来表示每个 $x^{<t>}$ 呢？方法是首先建立一个词汇库 vocabulary，尽可能包含更多的词汇。例如一个包含 10000 个词汇的词汇库为：</p><script type="math/tex; mode=display">\left[\begin{matrix}a \\and \\\cdot \\\cdot \\\cdot \\harry \\\cdot \\\cdot \\\cdot \\potter \\\cdot \\\cdot \\\cdot \\zulu\end{matrix}\right]</script><p>该词汇库可看成是 10000 x 1 的向量。值得注意的是自然语言处理 NLP 实际应用中的词汇库可达百万级别的词汇量。</p><p>然后，使用 one-hot 编码，例句中的每个单词 $x^{<t>}$ 都可以表示成10000 x 1的向量，词汇表中与 $x^{<t>}$ 对应的位置为 1，其它位置为 0。该 $x^{<t>}$ 为one-hot向量。值得一提的是如果出现词汇表之外的单词，可以使用 <strong>UNK</strong> （<strong>Unknow Word</strong>）或其他字符串来表示。</p><p>对于多样本，以上序列模型对应的命名规则可表示为：$x^{(i)<t>}$，$y^{(i)<t>}$，$T_x^{(i)}$，$T_y^{(i)}$。其中，$i$ 表示第 $i$ 个样本。不同样本的 $T_x^{(i)}$ 或 $T_y^{(i)}$ 都有可能不同。</p><hr><h4 id="1-3-循环神经网络模型"><a href="#1-3-循环神经网络模型" class="headerlink" title="1.3 循环神经网络模型"></a>1.3 循环神经网络模型</h4><p>对于序列模型，如果使用标准的神经网络，其模型结构如下：</p><p><img src="assets/20180305180556590" alt="这里写图片描述"></p><p>使用标准的神经网络模型存在两个问题：</p><p>第一个问题，<strong>不同样本的输入序列长度或输出序列长度不同</strong>，即 $T_x^{(i)}\neq T_x^{(j)}$，$T_y^{(i)}\neq T_y^{(j)}$，造成模型难以统一。解决办法之一是设定一个最大序列长度，对每个输入和输出序列<strong>补零</strong>并统一到最大长度。但是这种做法实际效果并不理想。</p><p>第二个问题，也是主要问题，这种标准神经网络结构并<strong>不共享</strong>从文本的不同位置上<strong>学到的特征</strong>。例如，如果 $x^{<1>}$ 是“Harry”是人名成分，我们希望当句子其它位置 $x^{<5>}$ 出现了 “Harry”，可以用到位置 1 已经学到的特征将它识别出来，这是<strong>共享特征</strong>的结果，如同 CNN 网络特点一样（将部分图片里学到的内容快速推广到图片的其他部分）。但是，上图所示的网络不具备共享特征的能力。值得一提的是，共享特征还有助于减少神经网络中的参数数量，一定程度上减小了模型的计算复杂度。例如上图所示的标准神经网络，假设每个 $x^{<t>}$ 扩展到最大序列长度为 100，且词汇表长度为 10000，则输入层就已经包含了 100 x 10000 个神经元了，权重参数很多，运算量将是庞大的。</p><p>标准的神经网络不适合解决序列模型问题，而循环神经网络（RNN）是专门用来解决序列模型问题的。RNN 模型结构如下：</p><p><img src="assets/20180305203908747" alt="这里写图片描述"></p><p>序列模型从左到右，依次传递，此例中， $T_x= T_y$。 $x^{<t>}$ 到 $y^{<t>}$ 之间是隐藏神经元。$a^{<t>}$ 会传入到第 $t+1$ 个元素中，作为输入。其中，$a^{<0>}$ 一般为零向量。</p><blockquote><p>如果从左到右的顺序读这个句子，将第一个词 $x^{<1>}$ 输入一个神经网络层，可以让神经网络尝试预测输出 $\hat y^{<1>}$，判断这是否是人名的一部分。当读到句中的第二个单词 $x^{<2>}$ 时，它不是仅用 $x^{<2>}$ 就预测出 $\hat y^{<2>}$，它也会输入一些来自时间步 1 的信息。具体而言，时间步 1 的激活值就会传递到时间步 2。然后，在下一个时间步，循环神经网络输入了单词 $x^{<3>}$ ，然后它尝试预测输出了预测结果 $\hat y^{<3>}$，等等，一直到最后一个时间步，输入 $x^{<T_x>}$ ，然后输出 $\hat y^{<T_y>}$。</p><p>如果 $T_x$ 和 $T_y$ 不相同，结构会需要作出一些改变。所以<strong>在每一个时间步中，循环神经网络传递一个激活值到下一个时间步中用于计算</strong>。</p></blockquote><p>RNN模型包含三类权重系数，分别是 $W_{ax}$，$W_{aa}$，$W_{ya}$。且不同元素之间同一位置共享同一权重系数。$W_ax$ 来表示管理着从 $x^{<1>}$ 到隐藏层的连接的一系列参数，每个时间步使用的都是<strong>相同的参数</strong> $W_ax$。而激活值也就是水平联系是由参数 $W_{aa}$ 决定的，同时每一个时间步都使用<strong>相同的参数</strong> $W_{aa}$，同样的输出结果由 $W_{ya}$ 决定 。</p><p><img src="assets/20180305212325555" alt="这里写图片描述"></p><p>RNN的正向传播（Forward Propagation）过程为：</p><script type="math/tex; mode=display">a^{<t>}=g(W_{aa}\cdot a^{<t-1>}+W_{ax}\cdot x^{<t>}+ba)\\\hat y^{<t>}=g(W_{ya}\cdot a^{<t>}+b_y)</script><p>其中，$g(⋅)$ 表示激活函数，不同的问题需要使用不同的激活函数。</p><p>为了简化表达式，可以对 $a^{<t>}$ 项进行整合：</p><script type="math/tex; mode=display">W_{aa}\cdot a^{<t-1>}+W_{ax}\cdot x^{<t>}=[W_{aa}\ \ W_{ax}]\left[\begin{matrix}a^{<t-1>} \\x^{<t>}\end{matrix}\right]\rightarrow W_a[a^{<t-1>},x^{<t>}]</script><p>则正向传播可表示为：</p><script type="math/tex; mode=display">a^{<t>}=g(W_a[a^{<t-1>},x^{<t>}]+b_a)\\\hat y^{<t>}=g(W_{y}\cdot a^{<t>}+b_y)</script><p>值得一提的是，以上所述的RNN为单向RNN，即按照从左到右顺序，单向进行，$\hat y^{<t>}$ 只与左边的元素有关。但是，有时候 $\hat y^{<t>}$ 也可能与右边元素有关。例如下面两个句子中，单凭前三个单词，无法确定 “Teddy” 是否为人名，必须根据右边单词进行判断。</p><p>He said, “Teddy Roosevelt was a great President.”</p><p>He said, “Teddy bears are on sale!”</p><p>因此，有另外一种RNN结构是双向RNN，简称为BRNN。$\hat y^{<t>}$ 与左右元素均有关系，我们之后再详细介绍。</p><hr><h4 id="1-4-通过时间的反向传播"><a href="#1-4-通过时间的反向传播" class="headerlink" title="1.4 通过时间的反向传播"></a>1.4 通过时间的反向传播</h4><p></p><p></p><h4 id="1-5-不同类型的循环神经网络"><a href="#1-5-不同类型的循环神经网络" class="headerlink" title="1.5 不同类型的循环神经网络"></a>1.5 不同类型的循环神经网络</h4><p></p><p></p><h4 id="1-6-语言模型和序列生成"><a href="#1-6-语言模型和序列生成" class="headerlink" title="1.6 语言模型和序列生成"></a>1.6 语言模型和序列生成</h4><p></p><p></p><h4 id="1-7-对新序列采样"><a href="#1-7-对新序列采样" class="headerlink" title="1.7 对新序列采样"></a>1.7 对新序列采样</h4><p></p><p></p><h4 id="1-8-带有神经网络的梯度消失"><a href="#1-8-带有神经网络的梯度消失" class="headerlink" title="1.8 带有神经网络的梯度消失"></a>1.8 带有神经网络的梯度消失</h4><p></p><p></p><h4 id="1-9-GRU-单元"><a href="#1-9-GRU-单元" class="headerlink" title="1.9 GRU 单元"></a>1.9 GRU 单元</h4><p></p><p></p><h4 id="1-10-长短期记忆（LSTM）"><a href="#1-10-长短期记忆（LSTM）" class="headerlink" title="1.10 长短期记忆（LSTM）"></a>1.10 长短期记忆（LSTM）</h4><p></p><p></p><h4 id="1-11-双向神经网络"><a href="#1-11-双向神经网络" class="headerlink" title="1.11 双向神经网络"></a>1.11 双向神经网络</h4><p></p><p></p><h4 id="1-12-深层循环神经网络"><a href="#1-12-深层循环神经网络" class="headerlink" title="1.12 深层循环神经网络"></a>1.12 深层循环神经网络</h4><p></p><p></p><h3 id="第二周-自然语言处理与词嵌入"><a href="#第二周-自然语言处理与词嵌入" class="headerlink" title="第二周 自然语言处理与词嵌入"></a>第二周 自然语言处理与词嵌入</h3><h4 id="2-1-词汇表征"><a href="#2-1-词汇表征" class="headerlink" title="2.1 词汇表征"></a>2.1 词汇表征</h4><p></p><h4 id="2-2-使用词嵌入"><a href="#2-2-使用词嵌入" class="headerlink" title="2.2 使用词嵌入"></a>2.2 使用词嵌入</h4><p></p><h4 id="2-3-词嵌入的特性"><a href="#2-3-词嵌入的特性" class="headerlink" title="2.3 词嵌入的特性"></a>2.3 词嵌入的特性</h4><p></p><h4 id="2-4-嵌入矩阵"><a href="#2-4-嵌入矩阵" class="headerlink" title="2.4 嵌入矩阵"></a>2.4 嵌入矩阵</h4><p></p><h4 id="2-5-学习词嵌入"><a href="#2-5-学习词嵌入" class="headerlink" title="2.5 学习词嵌入"></a>2.5 学习词嵌入</h4><p></p><h4 id="2-6-Word2Vec"><a href="#2-6-Word2Vec" class="headerlink" title="2.6 Word2Vec"></a>2.6 Word2Vec</h4><p></p><h4 id="2-7-负采样"><a href="#2-7-负采样" class="headerlink" title="2.7 负采样"></a>2.7 负采样</h4><p></p><h4 id="2-8-GloVe-词向量"><a href="#2-8-GloVe-词向量" class="headerlink" title="2.8 GloVe 词向量"></a>2.8 GloVe 词向量</h4><p></p><h4 id="2-9-情绪分类"><a href="#2-9-情绪分类" class="headerlink" title="2.9 情绪分类"></a>2.9 情绪分类</h4><p></p><h4 id="2-10-词嵌入除偏"><a href="#2-10-词嵌入除偏" class="headerlink" title="2.10 词嵌入除偏"></a>2.10 词嵌入除偏</h4><p></p><p></p><h3 id="第三周-序列模型和注意力机制"><a href="#第三周-序列模型和注意力机制" class="headerlink" title="第三周 序列模型和注意力机制"></a>第三周 序列模型和注意力机制</h3><h4 id="3-1-基础模型"><a href="#3-1-基础模型" class="headerlink" title="3.1 基础模型"></a>3.1 基础模型</h4><p></p><p></p><h4 id="3-2-选择最可能的句子"><a href="#3-2-选择最可能的句子" class="headerlink" title="3.2 选择最可能的句子"></a>3.2 选择最可能的句子</h4><p></p><p></p><h4 id="3-3-定向搜索"><a href="#3-3-定向搜索" class="headerlink" title="3.3 定向搜索"></a>3.3 定向搜索</h4><p></p><p></p><h4 id="3-4-改进定向搜索"><a href="#3-4-改进定向搜索" class="headerlink" title="3.4 改进定向搜索"></a>3.4 改进定向搜索</h4><p></p><p></p><h4 id="3-5-定向搜索的误差分析"><a href="#3-5-定向搜索的误差分析" class="headerlink" title="3.5 定向搜索的误差分析"></a>3.5 定向搜索的误差分析</h4><p></p><p></p><h4 id="3-6-Bleu-得分（选修）"><a href="#3-6-Bleu-得分（选修）" class="headerlink" title="3.6 Bleu 得分（选修）"></a>3.6 Bleu 得分（选修）</h4><p></p><p></p><h4 id="3-7-注意力模型直观理解"><a href="#3-7-注意力模型直观理解" class="headerlink" title="3.7 注意力模型直观理解"></a>3.7 注意力模型直观理解</h4><p></p><p></p><h4 id="3-8-注意力模型"><a href="#3-8-注意力模型" class="headerlink" title="3.8 注意力模型"></a>3.8 注意力模型</h4><p></p><p></p><h4 id="3-9-语音辨识"><a href="#3-9-语音辨识" class="headerlink" title="3.9 语音辨识"></a>3.9 语音辨识</h4><p></p><p></p><h4 id="3-10-触发字检测"><a href="#3-10-触发字检测" class="headerlink" title="3.10 触发字检测"></a>3.10 触发字检测</h4><p></p><p></p><h4 id="3-11-结论和致谢"><a href="#3-11-结论和致谢" class="headerlink" title="3.11 结论和致谢"></a>3.11 结论和致谢</h4><p></p><p></p>]]></content>
      
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C_DL_W3</title>
      <link href="/2022/03/28/C-DL-W3/"/>
      <url>/2022/03/28/C-DL-W3/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习工程师"><a href="#深度学习工程师" class="headerlink" title="深度学习工程师"></a>深度学习工程师</h1><p>由 deeplearning.ai 出品，网易引进的正版授权中文版深度学习工程师微专业课程，让你在了解丰富的人工智能应用案例的同时，学会在实践中搭建出最先进的神经网络模型，训练出属于你自己的 AI。<br><span id="more"></span></p><p>deeplearning.ai</p><p><a href="https://www.coursera.org/learn/neural-networks-deep-learning?action=enroll">https://www.coursera.org/learn/neural-networks-deep-learning?action=enroll</a></p><p><a href="https://study.163.com/my#/smarts">https://study.163.com/my#/smarts</a></p><p><a href="https://www.bilibili.com/video/av66644404">https://www.bilibili.com/video/av66644404</a></p><p><strong>note</strong></p><p><a href="https://redstonewill.blog.csdn.net/article/details/78519599">https://redstonewill.blog.csdn.net/article/details/78519599</a></p><p><a href="https://redstonewill.blog.csdn.net/article/details/78600255">https://redstonewill.blog.csdn.net/article/details/78600255</a></p><p><a href="https://www.zhihu.com/column/DeepLearningNotebook">https://www.zhihu.com/column/DeepLearningNotebook</a></p><p><a href="http://www.ai-start.com/dl2017/">http://www.ai-start.com/dl2017/</a></p><p><strong>课后作业</strong></p><p><a href="https://blog.csdn.net/u013733326/article/details/79827273">https://blog.csdn.net/u013733326/article/details/79827273</a></p><p><a href="https://www.heywhale.com/mw/project/5e20243e2823a10036b542da">https://www.heywhale.com/mw/project/5e20243e2823a10036b542da</a></p><h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><ul><li>[x] no question</li></ul><hr><h2 id="结构化机器学习项目"><a href="#结构化机器学习项目" class="headerlink" title="结构化机器学习项目"></a>结构化机器学习项目</h2><h3 id="第一周-机器学习（ML）策略（1）"><a href="#第一周-机器学习（ML）策略（1）" class="headerlink" title="第一周 机器学习（ML）策略（1）"></a>第一周 机器学习（ML）策略（1）</h3><h4 id="1-1-为什么是-ML-策略"><a href="#1-1-为什么是-ML-策略" class="headerlink" title="1.1 为什么是 ML 策略"></a>1.1 为什么是 ML 策略</h4><p>改善模型性能的方法：</p><ul><li>收集更多的数据</li><li>收集多样的训练集</li><li>用梯度下降训练更久</li><li>试用更好的优化方法adam等</li><li>尝试更大/更小的网络</li><li>尝试 dropout</li><li>尝试添加 L2 正则化项</li><li>改变网络的架构</li></ul><hr><h4 id="1-2-正交化"><a href="#1-2-正交化" class="headerlink" title="1.2 正交化"></a>1.2 正交化</h4><p>orthogonalization</p><p>正交意味着互成 90 度，即每一个维度只控制其所能控制的变量，不会影响以另一维度为自变量的因变量。</p><ol><li>系统在训练集上表现的不错（训练更大的网络，切换更好的优化算法）</li><li>紧接着希望在验证集上表现的不错（正则化，更大的数据集）</li><li>然后在测试集上表现得不错（更大的验证集）</li><li>最后在真实世界里表现良好（改变验证集或 cost 函数）</li></ol><p>而这些调节方法（旋钮）只会对应一个“功能”，是正交的。</p><p>一般不用 early stopping。因为同时影响两个测试和验证，不具有独立性、正交性。</p><hr><h4 id="1-3-单一数字评估指标"><a href="#1-3-单一数字评估指标" class="headerlink" title="1.3 单一数字评估指标"></a>1.3 单一数字评估指标</h4><p><img src="assets/1617684670783.png" alt="1617684670783"></p><p>precision 查准率：在模型识别出的所有猫里，有多少确实是猫</p><p>recall 查全率（召回率）：对于所有的猫，模型识别出了多少只</p><p><img src="assets/1617684662336.png" alt="1617684662336"></p><p><img src="assets/1617684684991.png" alt="1617684684991"></p><p>F1 score 为查准率和查全率的平均值，即单实数评估指标。</p><script type="math/tex; mode=display">\begin{equation} F_{1}=\frac{2}{\frac{1}{P}+\frac{1}{R}} = \frac{2 \cdot P \cdot R}{P+R} \end{equation}</script><p>harmonic mean of P and R，调和平均</p><p>除了F1 Score之外，我们还可以使用平均值作为单实数评价指标来对模型进行评估。</p><p><img src="assets/20171113163112581" alt="这里写图片描述"></p><p>验证集 +单一数字评估指标加速迭代过程</p><hr><h4 id="1-4-满足和优化指标"><a href="#1-4-满足和优化指标" class="headerlink" title="1.4 满足和优化指标"></a>1.4 满足和优化指标</h4><p>Satisficing and Optimizing metrics</p><p>如果你要考虑 N 个指标，有时候选择其中 1 个指标做为优化指标是合理的。所以你想尽量优化那个指标；然后剩下 N-1 个指标都是满足指标，意味着只要它们达到一定阈值，例如运行时间快于100毫秒，但只要达到一定的阈值，你不在乎它超过那个门槛之后的表现，但它们必须达到这个门槛。</p><p><strong>N metric:</strong> 1 <u>optimizing</u>, N-1 <u>satisficing</u></p><p><img src="assets/1617685956590.png" alt="1617685956590"></p><p>e.g. <strong>maximize accuracy</strong> subject to <strong>running time &lt; 100 ms</strong></p><hr><h4 id="1-5-训练-验证-测试集划分"><a href="#1-5-训练-验证-测试集划分" class="headerlink" title="1.5 训练 / 验证 / 测试集划分"></a>1.5 训练 / 验证 / 测试集划分</h4><p>让验证集和测试集服从相同的分布 ← 随机地混排到验证/测试中 </p><p>选择一个验证集和测试集，以反映您期望在未来获得的数据，并考虑做好这些数据的重要性</p><hr><h4 id="1-6-验证集-测试集的大小"><a href="#1-6-验证集-测试集的大小" class="headerlink" title="1.6 验证集/测试集的大小"></a>1.6 验证集/测试集的大小</h4><p>当样本数量不多（小于一万）的时候，通常将Train/dev/test sets的比例设为60%/20%/20%，在没有dev sets的情况下，Train/test sets的比例设为70%/30%。</p><p><img src="assets/1617856413391.png" alt="1617856413391"></p><p><img src="assets/1617856422625.png" alt="1617856422625"></p><p>当样本数量很大（百万级别）的时候，通常将相应的比例设为98%/1%/1%或者99%/1%。</p><p><img src="assets/1617856434070.png" alt="1617856434070"></p><p>对于dev sets数量的设置，应该遵循的准则是通过dev sets能够检测不同算法或模型的<strong>区别</strong>，以便选择出更好的模型。</p><p>对于test sets数量的设置，应该遵循的准则是通过test sets能够反映出模型在<strong>实际中的表现</strong>。</p><p>实际应用中，可能只有train/dev sets，而没有test sets。这种情况也是允许的，只要算法模型没有对dev sets<strong>过拟合</strong>。但是，条件允许的话，最好是有test sets，实现无偏估计。</p><hr><h4 id="1-7-什么时候该改变验证-测试集和指标"><a href="#1-7-什么时候该改变验证-测试集和指标" class="headerlink" title="1.7 什么时候该改变验证/ 测试集和指标"></a>1.7 什么时候该改变验证/ 测试集和指标</h4><p>Metric + Dev: prefers A <em>(misprediction)</em><br>You / Users: prefers B</p><p>当评估指标，无法正确衡量算法之间的优劣排序时，就需要指标了。比如加权重项，分类错误的惩罚权重加大10倍。</p><p><img src="assets/equation-1617850769804.svg" alt="[公式]"></p><ol><li><strong>Place the target:</strong> 定义衡量指标以评估分类器</li><li><strong>Shoot at target:</strong> 单度考虑如何在此指标上做得好，并不断动态修改调整。</li></ol><p>如果在metric + dev / test set上效果好，但在实际应用上效果不好相对应，则更改metric and/or dev / test set。需要动态改变评价标准的情况是 dev/test sets 与实际应用的样本分布不一致。</p><hr><h4 id="1-8-Why-human-level-performance"><a href="#1-8-Why-human-level-performance" class="headerlink" title="1.8 Why human-level performance"></a>1.8 Why human-level performance</h4><p><img src="assets/1617856385977.png" alt="1617856385977"></p><p>横坐标是训练时间，纵坐标是准确性。机器学习模型经过训练会不断接近human-level performance甚至超过它。但是，超过human-level performance之后，准确性会上升得比较缓慢，最终不断接近理想的最优情况，我们称之为bayes optimal error。理论上任何模型都不能超过它，bayes optimal error代表了最佳表现。</p><p>实际上，human-level performance在某些方面有不俗的表现。例如图像识别、语音识别等领域，人类是很擅长的。所以，让机器学习模型性能不断接近 human-level performance 非常必要也做出很多努力：</p><ul><li>Get labeled data from humans. 从人类获取带标签的数据</li><li>Gain insight from manual 手动 error analysis: Why did a person get this right?</li><li>Better analysis of bias/variance.偏差/方差</li></ul><hr><h4 id="1-9-可避免偏差"><a href="#1-9-可避免偏差" class="headerlink" title="1.9 可避免偏差"></a>1.9 可避免偏差</h4><p><img src="https://pic2.zhimg.com/v2-61a14d6d632447896afebe4680a2e16d_b.jpg" alt="img"></p><p>第一个例子中，这 8 - 1 = 7% 衡量了可避免偏差大小，而10 - 8 = 2%衡量了方差大小。所以在左边这个例子里，专注减少可避免偏差可能潜力更大。</p><p>第二个例子可避免偏差可能在 8 - 7.5 = 0.5% 左右，或者 0.5% 是可避免偏差的指标。而这个10 - 8 = 2%是方差的指标，所以要减少这个 2% 比减少这个 0.5% 空间要大得多。</p><p>如果算法在训练集上的表现和人类水平的表现有很大差距的话，说明算法对训练集的拟合并不好。所以从减少偏差和方差的角度看，在这种情况下，我会把重点放在减少偏差上。你需要做的是，比如说训练更大的神经网络，或者跑久一点梯度下降，就试试能不能在训练集上做得更好。如果算法与人类水平还比较接近，就可以注重减少方差，将验证集的 performance 接近于训练集。</p><p>我们希望提高训练集的 performance，直到接近 bayes optimal error，但实际上也不希望做到比 bayes optimal error 更好，因为理论上是不可能超过 bayes optimal error 的，除非过拟合。</p><p>把 training error 与 human-level error 之间的差值称为<strong>bias</strong>，也称作 avoidable bias；把 dev error 与 training error 之间的差值称为<strong>variance</strong>。根据 bias 和 variance 值的相对大小，可以知道算法模型是否发生了欠拟合或者过拟合。</p><blockquote><p> 其中 human-level error 近似于 bayes optimal error</p></blockquote><hr><h4 id="1-10-理解人的表现"><a href="#1-10-理解人的表现" class="headerlink" title="1.10 理解人的表现"></a>1.10 理解人的表现</h4><p><strong>human-level error</strong> as a proxy for <strong>Bayes error</strong></p><p>不同人群的错误率不同。一般来说，将表现最好的那一组，即Team of experienced doctors作为human-level performance</p><p>training error 到 bayes optimal error 的差距，告诉你 avoidable bias 问题有多大，avoidable bias 问题有多严重，而 training error 与  dev error 之间的差值告诉你方差上的问题有多大，你的算法是否能够从训练集泛化推广到开发集。</p><hr><h4 id="1-11-Surpassing-human-level-performance"><a href="#1-11-Surpassing-human-level-performance" class="headerlink" title="1.11 Surpassing human- level performance"></a>1.11 Surpassing human- level performance</h4><p>对于自然感知类问题，例如视觉、听觉等，机器学习的表现不及人类。但是在很多其它方面，机器学习模型的表现已经超过人类了，通常输入为结构化数据：</p><ul><li><strong>Online advertising</strong></li><li><strong>Product recommendations</strong></li><li><strong>Logistics(predicting transit time)</strong></li><li><strong>Loan approvals</strong></li></ul><p>机器学习模型超过human-level performance是比较困难的。但是只要提供足够多的样本数据，训练复杂的神经网络，模型预测准确性会大大提高，很有可能接近甚至超过human-level performance。当算法模型的表现超过human-level performance时，很难再通过人的直觉来解决如何继续提高算法模型性能的问题。</p><hr><h4 id="1-12-改善模型表现"><a href="#1-12-改善模型表现" class="headerlink" title="1.12 改善模型表现"></a>1.12 改善模型表现</h4><p>想要让一个监督学习算法达到<strong>应用</strong>，基本上希望或者假设你可以完成两件事情。首先，你的算法对训练集的拟合很好，这可以看成是你能做到<strong>可避免偏差很低</strong>。还有第二件事你可以做好的是，在训练集中做得很好，然后推广到开发集和测试集也很好，这就是说<strong>方差不大</strong>。解决方法如下：</p><p><img src="assets/1617856248776.png" alt="1617856248776"></p><hr><h3 id="第二周-机器学习（ML）策略（2）"><a href="#第二周-机器学习（ML）策略（2）" class="headerlink" title="第二周 机器学习（ML）策略（2）"></a>第二周 机器学习（ML）策略（2）</h3><h4 id="2-1-进行误差分析"><a href="#2-1-进行误差分析" class="headerlink" title="2.1 进行误差分析"></a>2.1 进行误差分析</h4><p>建立一个表格，表格的第一列对应你要评估的想法，比如狗的问题，猫科动物的问题，模糊图像的问题。扫过每一列，最后统计各列有多少百分比图像打了勾。</p><p>通常来说，<strong>比例越大</strong>，影响越大，越应该花费时间和精力着重解决这一问题。这种 error analysis 让我们改进模型更加有针对性，从而提高效率。有人手时，可以不同小组处理不同问题。</p><hr><h4 id="2-2-清楚标注错误的数据"><a href="#2-2-清楚标注错误的数据" class="headerlink" title="2.2 清楚标注错误的数据"></a>2.2 清楚标注错误的数据</h4><p>深度学习算法对训练集的<strong>随机误差</strong>很健壮，但对<strong>系统性的错误</strong>就没那么健壮了。即可以有个别错误。 </p><p><strong>针对验证集，则看整体验证集的错误率</strong></p><p>​    Overall dev set error: 10%</p><p>​    Errors due incorrect labels: 0.6%</p><p>​    Errors due to other causes: 9.4%</p><p>上面数据表明 Errors due incorrect labels 所占的比例仅为 0.6%，占 dev set error 的6%，而其它类型错误占 dev set error 的 94%。因此，这种情况下，可以忽略incorrectly labeled data，而去修复其他原因，造成的结果。</p><p><strong>如果优化DL算法后，出现下面这种情况：</strong></p><p>Overall dev set error: 2%</p><p>Errors due incorrect labels: 0.6%</p><p>Errors due to other causes: 1.4%</p><p>上面数据表明 Errors due incorrect labels 所占的比例依然为0.6%，但是却占 dev set error的 30%，而其它类型错误占 dev set error 的70%。因此，这种情况下，incorrectly labeled data 不可忽略，需要手动修正。</p><p>我们知道，<strong>dev set 的主要作用是在不同算法之间进行比较，选择错误率最小的算法模型</strong>。但是，如果有 incorrectly labeled data 的存在，当不同算法<strong>错误率比较接近</strong>的时候，我们无法仅仅根据 Overall dev set error 准确指出哪个算法模型更好，<strong>必须修正</strong> incorrectly labeled data。</p><p>关于修正 incorrect dev/test set data，有几条建议：</p><ul><li>对验证和测试集应用相同的过程，以确保它们继续服从同一分布。</li><li>考虑研究算法正确和错误的示例</li><li>训练和验证/测试数据现在可能服从略有不同的分布</li></ul><hr><h4 id="2-3-快速搭建你的第一个系统，并进行迭代"><a href="#2-3-快速搭建你的第一个系统，并进行迭代" class="headerlink" title="2.3 快速搭建你的第一个系统，并进行迭代"></a>2.3 快速搭建你的第一个系统，并进行迭代</h4><ul><li><p><strong>快速</strong>设置验证/测试集和指标，错了可以改</p></li><li><p><strong>快速</strong>构建初始系统，并找到训练集，训练看效果，理解算法表现，及在验证集测试集上的评估指标上的表现。快速和粗糙的实现（<strong>quick and dirty implementation</strong>），</p></li><li>使用偏差/方差分析和错误分析来<strong>优先</strong>确定后续步骤</li></ul><hr><h4 id="2-4-使用来自不同分布的数据，进行训练和测试Training-and-testing-on-different-distributions"><a href="#2-4-使用来自不同分布的数据，进行训练和测试Training-and-testing-on-different-distributions" class="headerlink" title="2.4 使用来自不同分布的数据，进行训练和测试Training and testing on different distributions"></a>2.4 使用来自不同分布的数据，进行训练和测试Training and testing on different distributions</h4><p>以猫类识别为例，train set 来自于网络下载（webpages），图片比较清晰；dev/test set 来自用户手机拍摄（mobile app），图片比较模糊。假如 train set 的大小为200000，而 dev/test set 的大小为10000，显然 train set 要远远大于 dev/test set。</p><p><img src="assets/20171122223431927" alt="这里写图片描述"></p><p>虽然 dev/test set 质量不高，但是<strong>模型最终主要应用在对这些模糊的照片的处理上</strong>。面对train set 与 dev/test set 分布不同的情况，有两种解决方法。</p><p>× <strong>第一种方法</strong>是将train set和dev/test set<strong>完全混合</strong>，然后在<strong>随机选择</strong>一部分作为train set，另一部分作为dev/test set。例如，混合210000例样本，然后随机选择205000例样本作为train set，2500例作为dev set，2500例作为test set。这种做法的优点是实现train set和dev/test set<strong>分布一致</strong>，<strong>缺点</strong>是dev/test set中webpages图片所占的<strong>比重</strong>比mobile app图片大得多。例如dev set包含2500例样本，大约有2381例来自webpages，只有119例来自mobile app。这样，dev set的算法模型对比验证，仍然主要由webpages决定，实际应用的mobile app图片所占比重很小，<strong>达不到验证效果</strong>。因此，这种方法并不是很好。</p><p>√ <strong>第二种方法</strong>是将原来的train set和一部分dev/test set组合当成train set，剩下的dev/test set分别作为dev set和test set。例如，200000例webpages图片和5000例mobile app图片组合成train set，剩下的2500例mobile app图片作为dev set，2500例mobile app图片作为test set。其关键在于dev/test set全部来自于mobile app。这样<strong>保证了验证集最接近实际应用场合</strong>。这种方法较为常用，而且性能表现比较好。</p><hr><h4 id="2-5-数据分布不匹配时，偏差与方差的分析Bias-and-Variance-with-mismatched-data-distributions"><a href="#2-5-数据分布不匹配时，偏差与方差的分析Bias-and-Variance-with-mismatched-data-distributions" class="headerlink" title="2.5 数据分布不匹配时，偏差与方差的分析Bias and Variance with mismatched data distributions"></a>2.5 数据分布不匹配时，偏差与方差的分析Bias and Variance with mismatched data distributions</h4><p><strong>随机打散训练集</strong>，然后<strong>分出一部分训练集</strong>作为<strong>训练-验证集</strong>（training-dev），这是一个新的数据子集。就像验证集和测试集来自同一分布，训练集、训练-验证集也来自同一分布。但不同的地方是，现在只在<strong>训练集</strong>训练你的神经网络，<strong>不会让神经网络在训练-验证集上跑后向传播</strong>。</p><p>有一个样本，训练集误差是1%，训练-验证集误差是9%，验证集误差是10%，和以前一样。算法<strong>存在方差</strong>问题，因为训练-验证集的错误率是在和训练集来自<strong>同一分布</strong>的数据中测得的。</p><p>有一个样本，训练集误差为1%，训练-验证误差为1.5%，验证集误差为10%。算法<strong>方差问题很小</strong>，转到验证集时，错误率就大大上升了，所以这是<strong>数据不匹配</strong>的问题。因为你的学习算法没有直接在训练-验证集或者验证集训练过，但是这<strong>两个数据集来自不同的分布</strong>。</p><p>有一个样本，训练集误差是10%，训练-验证误差是11%，验证集误差为12%，人类水平对贝叶斯错误率的估计大概是0%。则算法<strong>存在偏差问题</strong>。存在<strong>可避免偏差</strong>问题。</p><p>有一个样本，训练集误差是10%，训练-验证误差为11%，验证集误差为20%，有两个问题。第一，<strong>可避免偏差</strong>相当<strong>高</strong>，因为你在训练集上都没有做得很好，而人类能做到接近0%错误率，但你的算法在训练集上错误率为10%。这里方差似乎很小，但存在<strong>数据不匹配问题</strong>。</p><p><img src="assets/equation-error.svg" alt=""></p><hr><h4 id="2-6-定位数据不匹配"><a href="#2-6-定位数据不匹配" class="headerlink" title="2.6 定位数据不匹配"></a>2.6 定位数据不匹配</h4><p>训练集来自和验证测试集不同的分布，会出现数据不匹配的问题，解决方法：</p><ul><li>进行人工错误分析，了解培训验证/测试集之间的差异</li><li>使培训数据更加相似；收集更多类似于验证/测试集的数据</li></ul><p>利用一种技术是人工合成数据（<strong>artificial data synthesis</strong>）</p><p><img src="assets/e8e1e932abb7a0bb44cab6403657321d.png" alt="img"></p><p>通过人工数据合成，你可以快速制造更多的训练数据，就像真的在车里录的那样，那就不需要花时间实际出去收集数据。</p><p>人工数据合成有一个潜在问题，如果加入的汽车噪声是相同的，算法对加入的汽车噪音过拟合，丢失对其他的汽车噪声处理。即学习算法可能会对合成的这一个小子集过拟合。</p><hr><h4 id="2-7-迁移学习"><a href="#2-7-迁移学习" class="headerlink" title="2.7 迁移学习"></a>2.7 迁移学习</h4><p>transfer learning</p><p>我们有手写数字的大数据集，并通过其训练了识别网络。现在需要识别医学图像，只需要把最后一层更换，重新学习参数即可。因为<strong>网络一部分的目的就是学习低层次特征</strong>，点/边缘/曲线/对象等。</p><p>如果有医学图像的小数据集，可以只训练输出层前的最后一/两层的网络参数。</p><p><img src="assets/20171123160012172" alt="这里写图片描述"></p><p>如果有医学图像的大数据集，也可以训练整个网络的参数。（也可以加入一些新的隐藏层）</p><p><img src="assets/20171124141447596" alt="这里写图片描述"></p><p>这个过程中，数字识别的模型称为预训练模型(pre-training)，重新学习网络中的某些参数，为微调（fine-tuning）</p><p>迁移学习适合的场景：</p><ul><li>任务A和B的输入x相同（都是图片/语音）</li><li>任务A的数据比任务B多得多</li><li>任务A的低级特征可能有助于学习B</li></ul><hr><h4 id="2-8-多任务学习"><a href="#2-8-多任务学习" class="headerlink" title="2.8 多任务学习"></a>2.8 多任务学习</h4><p>迁移学习是串行的，而多任务学习，是同时开始学习的。让单个神经网络同时做几件事情，然后希望这里每个任务都能帮到其他所有任务。</p><p>例如汽车自动驾驶中，需要实现的多任务为行人、车辆、交通标志和信号灯。如果检测出汽车和交通标志，则y为：</p><script type="math/tex; mode=display">y=\left[ \begin{matrix}   0\\   1\\   1\\   0  \end{matrix}  \right]</script><p>多任务学习模型的cost function为：</p><script type="math/tex; mode=display">\frac1m\sum_{i=1}^m\sum_{j=1}^cL(\hat y_j^{(i)},y_j^{(i)})</script><p>其中，j 表示任务下标，总有 c 个任务。对应的loss function为：</p><script type="math/tex; mode=display">L(\hat y_j^{(i)},y_j^{(i)})=-y_j^{(i)}log\ \hat y_j^{(i)}-(1-y_j^{(i)})log\ (1-\hat y_j^{(i)})</script><p>值得一提的是，Multi-task learning 与 Softmax regression 的区别在于 Softmax regression 是 <strong>single label</strong> 的，即输出向量 y <strong>只有一个元素为1</strong>；而 Multi-task learning 是 multiple labels 的，即输出向量 y 可以<strong>有多个元素为1</strong>。</p><p>多任务学习是使用单个神经网络模型来实现多个任务。实际上，也可以分别构建多个神经网络来实现。但是，如果各个任务之间是相似问题（例如都是图片类别检测），则可以使用多任务学习模型。另外，多任务学习中，可能存在训练样本Y某些label空白的情况，这并不影响多任务模型的训练。总体来说，多任务学习的应用场合主要包括三点：</p><ul><li>训练一组任务，这些任务可以从共享的低级特征中受益。</li><li><p>每个任务的数据量非常相似。</p></li><li><p>可以训练<strong>足够大</strong>的神经网络来很好地完成所有任务。比单独训练神经网络来单独完成各个任务性能要更好。</p></li></ul><p>迁移学习和多任务学习在实际应用中，迁移学习使用得更多一些。</p><hr><h4 id="2-9-什么是端到端的深度学习"><a href="#2-9-什么是端到端的深度学习" class="headerlink" title="2.9 什么是端到端的深度学习"></a>2.9 什么是端到端的深度学习</h4><p>端到端（end-to-end）深度学习就是将所有不同阶段的数据处理系统或学习系统模块组合在一起，用一个<strong>单一</strong>的神经网络模型来实现所有的功能。它将所有<strong>模块混合</strong>在一起，只关心输入和输出。以语音识别为例，传统的算法流程和end-to-end模型的区别如下：</p><p><img src="assets/20171127134439086" alt="这里写图片描述"></p><p>如果训练样本足够大，神经网络模型足够复杂，那么 end-to-end 模型性能比传统机器学习分块模型更好。实际上，end-to-end 让神经网络模型内部去自我训练模型特征，自我调节，增加了模型整体契合度。<strong>关键问题是：是否有足够的数据来学习从 X 映射到 Y 所需的复杂度函数？</strong></p><p>人脸识别系统，先检测人脸，再对比身份更好。</p><p>两步法好有两个原因。一是，你解决的两个问题，每个问题实际上要简单得多。第二，两个子任务的训练数据都很多。具体来说，有很多数据可以用于人脸识别训练，对于这里的任务1来说，任务就是观察一张图，找出人脸所在的位置，把人脸图像框出来，所以有很多数据，有很多标签数据，其中是图片，是表示人脸的位置，你可以建立一个神经网络，可以很好地处理任务1。然后任务2，也有很多数据可用，输入一张裁剪得很紧凑的照片，判断照片里人的身份。</p><p><strong>一步到位</strong>的数据就少得多，其中是门禁系统拍摄的图像，是那人的身份，因为你<strong>没有足够多的数据</strong>去解决这个端到端学习问题，但你却<strong>有足够多的数据</strong>来解决子问题 1 和子问题 2。</p><hr><h4 id="2-10-是否要使用端到端的深度学习"><a href="#2-10-是否要使用端到端的深度学习" class="headerlink" title="2.10 是否要使用端到端的深度学习"></a>2.10 是否要使用端到端的深度学习</h4><p><strong>优点</strong></p><ul><li>让数据说话</li><li>减少所需组件的手工设计</li></ul><p><strong>缺点</strong></p><ul><li>可能需要大量数据</li><li>丢失了<strong>可能</strong>有用的手工设计组件</li></ul><p>例如，在语音识别领域，早期的识别系统有这个音位概念，就是基本的声音单元，如cat单词的“cat”的Cu-、Ah-和Tu-，我觉得这个音位是人类语言学家生造出来的，我实际上认为音位其实是语音学家的幻想，用音位描述语言也还算合理。但是<strong>不要强迫你的学习算法以音位为单位思考</strong>，这点有时没那么明显。如果你<strong>让你的学习算法学习它想学习的任意表示方式</strong>，而不是强迫你的学习算法使用音位作为表示方式，那么其整体表现可能会更好。</p><p>精心设计的人工组件<strong>可能</strong>非常有用，但它们也有可能真的伤害到你的算法表现。例如，强制你的算法以音位为单位思考，也许让算法自己找到更好的表示方法更好。所以这是一把<strong>双刃剑</strong>，可能有坏处，可能有好处，但往往好处更多，手工设计的组件往往在训练集更小的时候帮助更大。</p><hr><h3 id="第三周-人工智能行业大师访谈"><a href="#第三周-人工智能行业大师访谈" class="headerlink" title="第三周 人工智能行业大师访谈"></a>第三周 人工智能行业大师访谈</h3><h4 id="3-1-吴恩达采访-Andrej-Karpathy"><a href="#3-1-吴恩达采访-Andrej-Karpathy" class="headerlink" title="3.1. 吴恩达采访 Andrej Karpathy"></a>3.1. 吴恩达采访 Andrej Karpathy</h4><p>imageNet创始人</p><p>cs231n</p><p>openAI</p><p>接触底层</p><hr><h4 id="3-2-采访-Ruslan-Salakhutdinov"><a href="#3-2-采访-Ruslan-Salakhutdinov" class="headerlink" title="3.2. 采访 Ruslan Salakhutdinov"></a>3.2. 采访 Ruslan Salakhutdinov</h4><p>Apple</p><p>CMU</p><p>尝试不同的事情，不要害怕尝试创新</p><p>了解底层</p><p>学术界 时间</p><p>工业界 钱</p><hr>]]></content>
      
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C_DL_W2</title>
      <link href="/2022/03/28/C-DL-W2/"/>
      <url>/2022/03/28/C-DL-W2/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习工程师"><a href="#深度学习工程师" class="headerlink" title="深度学习工程师"></a>深度学习工程师</h1><p>由 deeplearning.ai 出品，网易引进的正版授权中文版深度学习工程师微专业课程，让你在了解丰富的人工智能应用案例的同时，学会在实践中搭建出最先进的神经网络模型，训练出属于你自己的 AI。<br><span id="more"></span></p><p>deeplearning.ai</p><p><a href="https://www.coursera.org/learn/neural-networks-deep-learning?action=enroll">https://www.coursera.org/learn/neural-networks-deep-learning?action=enroll</a></p><p><a href="https://study.163.com/my#/smarts">https://study.163.com/my#/smarts</a></p><p><a href="https://www.bilibili.com/video/av66524657">https://www.bilibili.com/video/av66524657</a></p><p><strong>note</strong></p><p><a href="https://blog.csdn.net/red_stone1/article/details/78403416">https://blog.csdn.net/red_stone1/article/details/78403416</a></p><p><a href="https://www.zhihu.com/column/DeepLearningNotebook">https://www.zhihu.com/column/DeepLearningNotebook</a></p><p><a href="http://www.ai-start.com/dl2017/">http://www.ai-start.com/dl2017/</a></p><p><strong>课后作业</strong></p><p><a href="https://blog.csdn.net/u013733326/article/details/79827273">https://blog.csdn.net/u013733326/article/details/79827273</a></p><p><a href="https://www.heywhale.com/mw/project/5e20243e2823a10036b542da">https://www.heywhale.com/mw/project/5e20243e2823a10036b542da</a></p><h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><ul><li>[ ] 改善深层神经网络-<a href="#winit">1.11 权重初始化</a>，有这个概念，但没在主流模型的代码中见过。</li><li>[ ] 改善深层神经网络-<a href="#BN-test">3.7 测试时的 Batch Norm</a>，指数加权平均过程很模糊 </li><li>[ ] 改善深层神经网络-<a href="#dadz">3.9 训练一个 Softmax 分类器</a>，激活函数对 z 求导，<a href="https://www.cnblogs.com/lizhiqing/p/10684795.html">https://www.cnblogs.com/lizhiqing/p/10684795.html</a></li></ul><hr><h2 id="改善深层神经网络：超参数调试、正则化以及优化"><a href="#改善深层神经网络：超参数调试、正则化以及优化" class="headerlink" title="改善深层神经网络：超参数调试、正则化以及优化"></a>改善深层神经网络：超参数调试、正则化以及优化</h2><h3 id="第一周-深度学习的实用层面"><a href="#第一周-深度学习的实用层面" class="headerlink" title="第一周 深度学习的实用层面"></a>第一周 深度学习的实用层面</h3><hr><h4 id="1-1-训练-验证-测试集"><a href="#1-1-训练-验证-测试集" class="headerlink" title="1.1 训练 / 验证 / 测试集"></a>1.1 训练 / 验证 / 测试集</h4><p>层数、隐藏单元、学习率、激活函数</p><p>这些参数都是需要大迭代更新学习的。</p><p>一组数据 = 训练集+ 验证集\交叉验证集 + 测试集    普通量级 70 + 0 + 30     60 + 20 +20  数据量级越大 后两者占比越小 百万级别 98 + 1 + 1</p><p><img src="assets/7be8de26db579238f7e72a5a45087595.png" alt="img"></p><p><strong>训练集</strong> 加入训练</p><p>作用：估计模型，用于训练模型以及确定模型权重</p><p>学习样本数据集，通过匹配一些参数来建立一个分类器。建立一种分类的方式，主要是用来训练模型的。</p><p><strong>验证集</strong> 加入训练</p><p>作用：确定网络结构或者控制模型复杂程度的参数，</p><p>对学习出来的模型，调整分类器的参数，如在神经网络中选择隐藏单元数。验证集还用来确定网络结构或者控制模型复杂程度的参数。</p><p><strong>测试集 </strong> 不加入训练</p><p>作用：检验最终选择最优的模型的性能如何，泛化能力</p><p>主要是测试训练好的模型的分辨能力（识别率等）</p><p><strong>不要</strong>在训练集和测试集<strong>分布不同</strong>的情况下训练网络，要确保训练集和测试集使用<strong>同一分布</strong></p><p><strong>测试集</strong>的目的是让最终所选定的神经网络系统做出<strong>无偏估计</strong>。如果不需要做无偏估计，就不需要测试集。（但比较bug的一点是，这时的验证集又可以被看做是测试集）</p><hr><h4 id="1-2-偏差-方差"><a href="#1-2-偏差-方差" class="headerlink" title="1.2 偏差 / 方差"></a>1.2 偏差 / 方差</h4><p><img src="assets/image-20210330210829773.png" alt="image-20210330210829773"></p><p>高偏差 欠拟合</p><p>高方差 过拟合</p><p>如果人的误差为 0%</p><div class="table-container"><table><thead><tr><th style="text-align:center">训练集误差</th><th style="text-align:center">1%</th><th style="text-align:center">15%</th><th style="text-align:center">15%</th><th style="text-align:center">0.5%</th></tr></thead><tbody><tr><td style="text-align:center">验证集误差</td><td style="text-align:center">11%</td><td style="text-align:center">16%</td><td style="text-align:center">30%</td><td style="text-align:center">1%</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">高方差</td><td style="text-align:center">高偏差</td><td style="text-align:center">高偏差+高方差</td><td style="text-align:center">低偏差+低方差</td></tr></tbody></table></div><p>太线性 高偏差</p><p>太非线性 高方差</p><p>方差度量随机变量和其数学期望（即均值）之间的偏离程度</p><p>方差越大，数据的波动越大，数据分布比较分散</p><p>方差越小，数据的波动越小，数据分布比较集中</p><hr><h4 id="1-3-机器学习基础"><a href="#1-3-机器学习基础" class="headerlink" title="1.3 机器学习基础"></a>1.3 机器学习基础</h4><p>检查偏差，评估训练集性能，如果偏差高（训练集误差大），甚至无法拟合训练集，需要更换一个新的网络（更多层，更多隐藏单元，加大训练时间）</p><p> 一旦偏差降到可接受范围，就需要检查方差，评估验证集性能，如果方差高（验证集误差大），正则化/更换网络架构/需要采用更多的数据来训练。</p><p>直到找到一个低偏差、低方差的网络。</p><p>bias variance trade off 权衡</p><hr><h4 id="1-4-正则化"><a href="#1-4-正则化" class="headerlink" title="1.4 正则化"></a>1.4 正则化</h4><p><strong>正则化</strong>：多任务学习、增加噪声，集成学习，早停止，稀疏表示，dropout，正切传播，参数绑定，权值共享，范数惩罚，数据增强</p><p>如果网络过拟合，即存在高方差的问题。<strong>正则化</strong>可以处理！ </p><p><strong>L1范数</strong></p><p>向量参数 w 的 L1 范数如下: </p><script type="math/tex; mode=display">\begin{equation}\|w\|_{1} =\sum_{i=1}^{n_{y}}|w|\end{equation}</script><p>如果用L1正则化，w最终会是稀疏的。</p><p><strong>L2范数</strong></p><p>向量参数 w 的 L2 范数，用到了欧几里得法线</p><script type="math/tex; mode=display">\begin{equation}\|\omega\|_{2}^{2}=\sum_{j=1}^{n_{x}} \omega_{j}^{2}=\omega^{\top} \omega\end{equation}</script><p>如果用L2正则化，w的值会比较小，避免过拟合</p><p><strong>实例</strong></p><p>普通的 logistics 回归任务 $\min _{w, b} J(w, b)$</p><script type="math/tex; mode=display">\begin{equation}J(\omega, b)=\frac{1}{m} \sum_{i=1}^{m} \mathcal{L}\left(\hat{y}^{(i)}, y^{(i)}\right)+\frac{\lambda}{2 m}\|\omega\|_{2}^{2}\end{equation}</script><p>其中 w 和 b 是logistics 的两个参数，$w\in \mathbb{R^{nx}}$， $b\in\mathbb{R}$ </p><p>不加 b 的L2范数是因为，w 通常为高维，可以独立表达高偏差问题，b 对模型影响不大，加上也可以。其中 $\lambda$ 是一个需要调整的超参数</p><script type="math/tex; mode=display">J\left(\omega^{[1)}, b^{[1]}, \ldots, \omega^{[L]}, b^{[L]}\right)=\sum_{i=1}^{m} L\left(\hat{y}^{(i)} ,y^{(i)}\right)+\frac{\lambda}{2 m} \sum_{l=1}^{L}\left\|\omega^{[l] }\right\|^{2}_{F}</script><p>其中</p><script type="math/tex; mode=display">\| \omega^{[l]}||^{2}=\sum_{i=1}^{n^{[l-1]}} \sum_{j=1}^{n^{[l]}}\left(\omega_{i j}^{[l]}\right)^{2}_{F}</script><p>矩阵范式，被定义为矩阵中所有元素的平方求和，其中 w 的 size 为 $(n^{[l]},n^{[l-1]})$ </p><p>被称为 frobenius 范数/F范数    弗罗贝尼乌斯</p><p>参数更新公式为</p><script type="math/tex; mode=display">\begin{split}w^{[l]}&=w^{[l]}-\alpha(backward)\end{split}</script><p>如果加上这个正则项，就相当于对梯度 $dW^{[l]}$ 加上了 $\frac{\lambda}{m}w^{[l]}$</p><script type="math/tex; mode=display">\begin{split}w^{[l]}&=w^{[l]}-\alpha\left[backward+\frac{\lambda}{m} w^{[l]}\right]\\&=w^{[l]}-\frac{\alpha\lambda}{m}w^{[l]}-\alpha(backward)\end{split}</script><p>w 的系数是 $(1-\frac{\alpha\lambda}{m})$   <strong>权重衰减</strong>，不论w是什么值，都打算让他变得更小</p><hr><h4 id="1-5-为什么正则化可以减少过拟合？"><a href="#1-5-为什么正则化可以减少过拟合？" class="headerlink" title="1.5 为什么正则化可以减少过拟合？"></a>1.5 为什么正则化可以减少过拟合？</h4><script type="math/tex; mode=display">J\left(\omega^{[1)}, b^{[1]}, \ldots, \omega^{[L]}, b^{[L]}\right)=\sum_{i=1}^{m} L\left(\hat{y}^{(i)} ,y^{(i)}\right)+\frac{\lambda}{2 m} \sum_{l=1}^{L}\left\|\omega^{[l] }\right\|^{2}_{F}</script><p>如果将 $\lambda$ 设置足够大，则 w 足够小，许多隐藏单元减少产生的影响，即减少非线性。（考虑极端，如果其他隐藏单元都不产生影响，只有一个有影响，那就是变成线性回归了）</p><p><img src="assets/image-20210330221922620.png" alt="image-20210330221922620"></p><hr><h4 id="1-6-Dropout-正则化"><a href="#1-6-Dropout-正则化" class="headerlink" title="1.6 Dropout 正则化"></a>1.6 Dropout 正则化</h4><p>随机失活，设定节点保留和消除的概率</p><p><img src="assets/1617160374854.png" alt="1617160374854"></p><p><strong>inverted dropout 反向随机失活</strong></p><p>根据阈值，生成一个 bool 类型矩阵，与参数 w 矩阵相乘，得到随机失活后的参数矩阵 w。 </p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">d = np.random.rand(a.shape[<span class="number">0</span>], a.shape[<span class="number">1</span>]) &lt; keep_prob</span><br><span class="line">a = np.multiply(a, d)</span><br><span class="line">a = a / keep_prob</span><br></pre></td></tr></table></figure><p>下一层的计算如下</p><script type="math/tex; mode=display">z = w * a + b</script><p>假设<code>keep_prob = 0.8</code> ，那么有 20% 的数变成了 0，<code>a</code> 的期望变成了原来的 80%， <code>z</code> 的期望也变成了原来的80%。</p><p>为了不影响 <code>z</code> 的期望值，需要给 <code>a</code> 除以 0.8 ，修正弥补。</p><p><strong>训练测试</strong></p><p>不同的训练样本，失活的隐藏单元也不同。每次训练数据的梯度不同，则随机对不同隐藏单元归零。每个 epoch 将不同的隐藏单元归零。  </p><p><strong>测试阶段不使用 dropout 函数。也不用除以 <code>keep_prob</code></strong></p><hr><h4 id="1-7-理解-Dropout"><a href="#1-7-理解-Dropout" class="headerlink" title="1.7 理解 Dropout"></a>1.7 理解 Dropout</h4><p>使用正则化就像是采用一个较小的神经网络。</p><p>不愿意吧权重全部放在其中一个特征（输入），因为有可能失活被删除。</p><p>实施dropout会减小权重，类似L2正则，预防过拟合。但L2对不同参数的衰减程度不同，</p><p>可以针对不同层设置不同的 <code>keep_prob</code></p><p>除非算法过拟合（数据不够），否则一般不用dropout</p><p>dropout 缺点是损失函数不确定了 。</p><p>先关闭 drop 确定损失函数单调递减之后再打开 dropout</p><hr><h4 id="1-8-其他正则化方法"><a href="#1-8-其他正则化方法" class="headerlink" title="1.8 其他正则化方法"></a>1.8 其他正则化方法</h4><p><strong>数据增强</strong></p><p>扩增数据，即加大数据量</p><p><img src="assets/1617162083581.png" alt="1617162083581"></p><p>水平<strong>翻转</strong>图片，训练集可以大一倍。还处于同一分布。</p><p>或<strong>裁剪</strong>图片，但要确保猫还在图片中。</p><p><img src="assets/1617162158684.png" alt="1617162158684"></p><p>特殊的数据还可以随意轻微的<strong>旋转</strong>或<strong>扭曲</strong>。</p><p><strong>early stopping</strong></p><p>绘制训练误差和验证误差。验证集误差通常是先变小后变大。在最小值就可以提前停止训练了。</p><p>训练神经网络之前，w 很小，在迭代过程中 w 会越来越大。</p><p>但是提前停止训练，不能独立的处理代价函数 J 和验证集误差。了解即可，不建议用。</p><p><strong>解决办法就是给J加上正则化项，并不使用early stopping</strong>，这会使超参数搜索空间更容易分解，更容易搜索。缺点就是需要调整正则化参数 $\lambda$</p><hr><h4 id="1-9-归一化输入"><a href="#1-9-归一化输入" class="headerlink" title="1.9 归一化输入"></a>1.9 归一化输入</h4><p>normalizing </p><p><img src="assets/1617165180456.png" alt="1617165180456"></p><p><strong>第一步 零均值化</strong></p><p><img src="assets/1617165195446.png" alt="1617165195446"></p><script type="math/tex; mode=display">\begin{equation}  \mu=\frac{1}{m} \sum_{i=1}^{m} x^{(i)} \\ x = x -\mu\end{equation}</script><p>相当于移动数据集。</p><p><strong>第二步 归一化方差</strong></p><p><img src="assets/1617167345080.png" alt="1617167345080"></p><script type="math/tex; mode=display">\begin{equation} \sigma^{2}=\frac{1}{m} \sum_{i=1}^{M} x^{(i)} * * 2 \\ x = x / \sigma\end{equation}</script><p><code>**2</code> 表示每个元素都平方 element-wise</p><p>$\sigma^2$ 是一个向量，它的每个特征都有方差，因为均值已经为 0，所以 x 的平方直接就是方差。</p><p><strong>注意</strong></p><p>也应该用<strong>从训练集计算得到的参数</strong>处理<strong>测试集</strong>。</p><p><img src="assets/1617167554679.png" alt="1617167554679"></p><p><img src="assets/1617167574641.png" alt="1617167574641"></p><p>比较狭长。梯度下降可能拐来拐去，才能到最优值。</p><p><img src="assets/1617167588247.png" alt="1617167588247"></p><p><img src="assets/1617167613864.png" alt="1617167613864"></p><p>比较均匀。梯度下降法直接指向最小值，能用较大步长。</p><hr><h4 id="1-10-梯度消失与梯度爆炸"><a href="#1-10-梯度消失与梯度爆炸" class="headerlink" title="1.10 梯度消失与梯度爆炸"></a>1.10 梯度消失与梯度爆炸</h4><p><img src="assets/1617167911663.png" alt="1617167911663"></p><p>参数比1大，随层数 L 指数增长。参数比1小，随层数 L 指数递减</p><hr><h4 id="1-11-神经网络的权重初始化"><a href="#1-11-神经网络的权重初始化" class="headerlink" title="1.11 神经网络的权重初始化"></a>1.11 神经网络的权重初始化<span id="winit"></span></h4><p><img src="assets/1617245938449.png" alt="1617245938449"></p><p>其中有n个特征</p><script type="math/tex; mode=display">\begin{equation} z=\omega_{1} x_{1}+\omega_{2} x_{2}+\cdots \cdot + \omega_{n} x_{n} \end{equation}</script><p>因为 z 是求和，所以 n 越大，z 越大</p><p>合理的方法是设置</p><script type="math/tex; mode=display">W=\frac{1}{n}W</script><p>即令其<strong>方差</strong>为 $\frac{1}{n}$，即上一层的特征数量的平方根</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">w[l] = np.random.randn(n[l],n[l-<span class="number">1</span>]) * np.sqrt(<span class="number">1</span>/n[l-<span class="number">1</span>]) </span><br></pre></td></tr></table></figure><p>如果是 <code>ReLu</code> 函数，令其<strong>方差</strong>为 $\frac{2}{n}$，</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">w[l] = np.random.randn(n[l],n[l-<span class="number">1</span>])  * np.sqrt(<span class="number">2</span>/n[l-<span class="number">1</span>]) </span><br></pre></td></tr></table></figure><p>如果是 <code>Tanh</code> 函数，令其<strong>方差</strong>为 $\frac{1}{n}$。Xavier 初始化</p><blockquote><p>x ~ N(μ, σ²)                  kx ~ N(kμ, k²σ²)</p><p>整个大型前馈神经网络无非就是一个超级大映射，将原始样本<strong>稳定的</strong>映射成它的类别。也就是将样本空间映射到类别空间。</p><p>如果样本空间与类别空间的<strong>分布差异</strong>很<strong>大</strong>，比如说<strong>类别空间特别稠密</strong>，<strong>样本空间特别稀疏辽阔</strong>，那么在类别空间得到的用于反向传播的误差丢给样本空间后简直变得微不足道，也就是会导致模型的训练非常缓慢。同样，如果<strong>类别空间特别稀疏</strong>，<strong>样本空间特别稠密</strong>，那么在类别空间算出来的误差丢给样本空间后简直是爆炸般的存在，即导致模型发散震荡，无法收敛。</p><p>因此，我们要让样本空间与类别空间的分布差异（密度差别）不要太大，<strong>也就是要让它们的方差尽可能相等</strong>。</p></blockquote><hr><h4 id="1-12-梯度的数值逼近"><a href="#1-12-梯度的数值逼近" class="headerlink" title="1.12 梯度的数值逼近"></a>1.12 梯度的数值逼近</h4><p>在反向传播时，有一步梯度检验。对计算数值做逼近</p><p>双边误差，更逼近导数，误差量级更小，结果更准确。</p><script type="math/tex; mode=display">\begin{equation} f^{\prime}(\theta)=\lim _{\varepsilon \rightarrow 0} \frac{f(\theta+\varepsilon)-f(\theta-\varepsilon)}{2 \varepsilon} \end{equation}</script><p>逼近误差为 $O(\epsilon^2)$</p><hr><h4 id="1-13-梯度检验"><a href="#1-13-梯度检验" class="headerlink" title="1.13 梯度检验"></a>1.13 梯度检验</h4><p>计算梯度的数值逼近 $d\theta_{approx}$ 和数值解 $d\theta$，比较二者差距。使用欧几里得范数</p><script type="math/tex; mode=display">\begin{equation}\frac{\left\|d\theta_{approx}-d \theta\right\|_{2}}{\left\|d\theta_{approx}\right\|_{2} +\left\|d \theta\right\|_{2} }\end{equation}</script><p>误差平方和然后在求平方根，得到欧氏距离。分母预方向量太大或太小。分母为两个参数向量的模之和。</p><p>三角形两边之和大于第三边，确保上式落在 $[0, 1]$ 之间。</p><p>如果值小于 $1e-7$ 或更小即通过验证。</p><p>如果大于 $1e-5$ ，就需要检查有没有其中一项的误差，即两者差值特别大。</p><hr><h4 id="1-14-关于梯度检验实现的注记"><a href="#1-14-关于梯度检验实现的注记" class="headerlink" title="1.14 关于梯度检验实现的注记"></a>1.14 关于梯度检验实现的注记</h4><ol><li>不要在训练中使用梯度检验，只用于debug</li><li>如果梯度检验失败。检查每一项逼近解 $d\theta_{approx}$ 和数值解 $d\theta$ 的插值，寻找哪一项误差最大。如果发现某层的 $d\theta^{[l]}$ 特别大，但是 $dw^{[l]}$ 的各项非常接近，那么一定是在计算参数 $b$ 的导数 $db^{[l]}$ 存在bug。同理，如果发现某层的 $d\theta^{[l]}$ 特别大，但是 $db^{[l]}$ 的各项非常接近，那么一定是在计算参数 $w$ 的导数 $dw^{[l]}$ 存在bug。</li><li>注意正则化项，要包含进去</li><li>不能与dropout共同使用</li><li>如果碰到当 $w$ 和 $b$ 接近0时，检验正确；但是训练过程， $w$ 和 $b$ 逐渐变大，检验不通过。可以在一开始做一下梯度检验，训练一段时间后再进行一次梯度检验确保正确。</li></ol><hr><h3 id="第二周-优化算法"><a href="#第二周-优化算法" class="headerlink" title="第二周 优化算法"></a>第二周 优化算法</h3><h4 id="2-1-Mini-batch-梯度下降法"><a href="#2-1-Mini-batch-梯度下降法" class="headerlink" title="2.1 Mini-batch 梯度下降法"></a>2.1 Mini-batch 梯度下降法</h4><p>特征 X 的 size 为 $[x_n, m]$，标签 Y 的 size 为 $[1,m]$.</p><p>如果样本数 m 巨大如 5000000个，训练速度很慢。因为每次迭代都要对所有样本进行进行求和运算和矩阵运算。如果先让梯度下降法处理一部分，算法速度会很快。</p><p>可以把训练集<strong>分割</strong>为小一点的子训练集 如1000个一组。子集被称为 <strong>mini-batch</strong>。如下共有 5000 个 mini-batch。</p><p><img src="assets/equation.svg" alt="[公式]"></p><p><img src="assets/equation-1617340169208.svg" alt="[公式]"></p><p>一个 mini-batch 的特征 X 的 size 为 $[x_n, 1000]$，标签 Y 的 size 为 $[1, 1000]$.</p><p><img src="assets/1617370541220.png" alt="1617370541220"></p><p>把所有训练集完整的遍历完为 1 个 epoch。采用 mini-batch 方法 1 个 epoch 梯度下降 5000 次，否则 1 个 epoch 只下降一次。</p><hr><h4 id="2-2-理解-mini-batch-梯度下降法"><a href="#2-2-理解-mini-batch-梯度下降法" class="headerlink" title="2.2 理解 mini-batch 梯度下降法"></a>2.2 理解 mini-batch 梯度下降法</h4><p><img src="assets/20171026113219156" alt="这里写图片描述"></p><p>mini-batch 梯度不是每次都在下降的。但如果数据足够均匀，右图噪声就越小。</p><p>如果mini-batch size =  m （样本数 ），称为batch 梯度下降，只有一个子集就是其本身</p><p>如果mini-batch size =  1  ，称为随机梯度下降，每个样本都是一个 mini-batch</p><p>随机梯度永远不会收敛，在最小值附近波动</p><p><img src="assets/20171026135131370" alt="这里写图片描述"></p><p>蓝色的线代表 Batch gradient descent，紫色的线代表 Stachastic gradient descent。Batch gradient descent会比较<strong>平稳</strong>地接近全局最小值，但是因为使用了所有m个样本，每次前进的<strong>速度</strong>有些慢。Stachastic gradient descent每次前进<strong>速度</strong>很快，但是路线曲折，有较大的<strong>振荡</strong>，最终会在最小值附近来回波动，难以真正达到最小值处。而且在数值处理上就<strong>不能</strong>使用<strong>向量化</strong>的方法来提高运算速度。</p><p>因此要设置一个合适的 mini-batch size</p><p>一般来说，如果总体样本数量 $m$ 不太大时，例如 $m≤2000$，建议直接使用Batch gradient descent。</p><p>如果总体样本数量 $m$ 很大时，建议将样本分成许多mini-batches。推荐常用的mini-batch size为 64,128,256,512。这些都是2的幂。之所以这样设置的原因是计算机存储数据一般是2的幂，这样设置可以提高运算速度。</p><hr><h4 id="2-3-指数加权平均"><a href="#2-3-指数加权平均" class="headerlink" title="2.3 指数加权平均"></a>2.3 指数加权平均</h4><script type="math/tex; mode=display">\begin{equation} V_{t}=\beta V_{t-1}+(1-\beta) \theta_{t} \end{equation}</script><ul><li><strong>large β:</strong> 适应的慢，相对平滑</li><li><strong>small β:</strong> 噪声更大，不平滑</li></ul><p>如果参数设置为 0.9，即第 $t$ 天与第 $t-1$ 天的气温迭代关系为：</p><script type="math/tex; mode=display">\begin{equation} \begin{aligned} V_{t} &=0.9 V_{t-1}+0.1 \theta_{t} \\ &=0.9^{t} V_{0}+0.9^{t-1} \cdot 0.1 \theta_{1}+0.9^{t-2} \cdot 0.1 \theta_{2}+\cdots+0.9 \cdot 0.1 \theta_{t-1}+0.1 \theta_{t} \end{aligned} \end{equation}</script><p>$β$ 值决定了指数加权平均的天数，近似表示为：</p><script type="math/tex; mode=display">\frac{1}{1-\beta}</script><p>指数加权移动平均值</p><p>指数加权平均数 </p><hr><h4 id="2-4-理解指数加权平均"><a href="#2-4-理解指数加权平均" class="headerlink" title="2.4 理解指数加权平均"></a>2.4 理解指数加权平均</h4><p><img src="assets/1617372894803.png" alt="1617372894803"></p><script type="math/tex; mode=display">\begin{equation} \begin{aligned} V_{t}=& \beta V_{t-1}+(1-\beta) \theta_{t} \\=&(1-\beta) \theta_{t}+(1-\beta) \cdot \beta \cdot \theta_{t-1}+(1-\beta) \cdot \beta^{2} \cdot \theta_{t-2}+\cdots \\ &+(1-\beta) \cdot \beta^{t-1} \cdot \theta_{1}+\beta^{t} \cdot V_{0} \end{aligned} \end{equation}</script><p>观察上面这个式子，$ \theta_{t}, \theta_{t-1}, \theta_{t-2}, \cdots, \theta_{1} $ 是原始数据值，$ (1-\beta),(1-\beta) \beta,(1-\beta) \beta^{2}, \cdots,(1-\beta) \beta^{t-1} $ 是类似指数曲线，从右向左，呈指数下降的。$V_t$ 的值就是这两个子式的点乘，将原始数据值与衰减指数点乘，相当于做了指数衰减，离得越近，影响越大，离得越远，影响越小，衰减越厉害。</p><p><img src="assets/20171027155944527" alt="这里写图片描述"></p><p>实践中，经常vθ初始化为0</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vθ = <span class="number">0</span></span><br><span class="line">repeat:</span><br><span class="line">    get <span class="built_in">next</span> θt</span><br><span class="line">    vθ = β * vθ + (<span class="number">1</span>-β) * θt</span><br></pre></td></tr></table></figure><hr><h4 id="2-5-指数加权平均的偏差修正"><a href="#2-5-指数加权平均的偏差修正" class="headerlink" title="2.5 指数加权平均的偏差修正"></a>2.5 指数加权平均的偏差修正</h4><p>上文中提到当 $β=0.98$ 时，指数加权平均结果如下图绿色曲线所示。但是实际上，真实曲线如紫色曲线所示。</p><p><img src="assets/20171028095447301" alt="这里写图片描述"></p><p>我们注意到，紫色曲线与绿色曲线的区别是，紫色曲线开始的时候相对较低一些。这是因为开始时我们设置 $V_0=0$，所以初始值会相对小一些，直到后面受前面的影响渐渐变小，趋于正常。</p><p>修正这种问题的方法是进行偏移校正（bias correction），即在每次计算完 $V_t$ 后，对 $V_t$ 进行下式处理：</p><script type="math/tex; mode=display">\begin{equation} \frac{V_{t}}{1-\beta^{t}} \end{equation}</script><p>在刚开始的时候，$t$ 比较小，$(1−β^t)&lt;1$，这样就将 $V_t$ 修正得更大一些，效果是把紫色曲线开始部分向上提升一些，与绿色曲线接近重合。随着 $t$ 增大，$(1−β^t)≈1$ ，$V_t$ 基本不变，紫色曲线与绿色曲线依然重合。这样就实现了简单的偏移校正，得到我们希望的绿色曲线。</p><p>机器学习中，偏移校正并不是必须的。因为，在迭代一次次数后（$t$ 较大），$V_t$ 受初始值影响微乎其微，紫色曲线与绿色曲线基本重合。所以，一般可以<strong>忽略初始迭代过程</strong>，等到一定迭代之后再取值，这样就不需要进行偏移校正了。</p><hr><h4 id="2-6-动量梯度下降法"><a href="#2-6-动量梯度下降法" class="headerlink" title="2.6 动量梯度下降法"></a>2.6 动量梯度下降法</h4><blockquote><p>momentum：基本的想法是计算梯度的指数加权平均数，并利用该梯度更新你的权重</p></blockquote><p>梯度下降法，要很多计算步骤，慢慢摆动到最小值。摆动减慢了梯度下降的速度，无法使用较大的学习率。</p><p><img src="assets/20171028142838569" alt="这里写图片描述"></p><p>希望纵向学习率低一点，减少摆动。横向学习率高一点，快速靠近最小值。采用</p><script type="math/tex; mode=display">\begin{equation} v_{d W}=\beta v_{d W} +(1-\beta) d W =\beta v_{d W} +W\end{equation}</script><p>即旧的惯性加新的方向。指数加权平均，减少纵轴波动，相当于取平均且平均为 0，正负数相互抵消。而所有的微分都指向横轴方向。momentum项 $v_{dW}$ 提供速度，微分项 $dW$ 提供加速度。$\beta$ 相当于提供摩擦力，不让无限加速下去。</p><p><img src="assets/1617433470211.png" alt="1617433470211"></p><p>有两个超参数 $\alpha,\beta$，$\beta$ 常用 0.9 是很棒的鲁棒数。一般不适用偏差干扰项。且有时 $1-\beta$ 项会去掉，一般不去比较好，因为会影响 $\alpha$ 的值。</p><hr><h4 id="2-7-RMSprop"><a href="#2-7-RMSprop" class="headerlink" title="2.7 RMSprop"></a>2.7 RMSprop</h4><p> root mean square prop 均方根，因为你将微分进行平方，然后最后使用平方根。</p><script type="math/tex; mode=display"> S_{W}=\beta S_{d W}+(1-\beta) d W^{2} \\ S_{b}=\beta S_{d b}+(1-\beta) d b^{2} \\ W:=W-\alpha \frac{d W}{\sqrt{S_{W}}}\\ b:=b-\alpha \frac{d b}{\sqrt{S_{b}}}</script><p>从下图中可以看出，梯度下降（蓝色折线）在垂直方向（b）上<strong>振荡较大</strong>，在水平方向（W）上振荡较小，表示在b方向上<strong>梯度较大</strong>，即 $db$ 较大，而在 W 方向上梯度较小，即 $dW$ 较小。因此，上述表达式中 $S_b$ 较<strong>大</strong>，而 $S_W$ 较小。在更新 W 和 b 的表达式中，变化值 $ \frac{d W}{\sqrt{S W}} $ 较大，而 $ \frac{d b}{\sqrt{S_{b}}} $ 较<strong>小</strong>。也就使得 W 变化得多一些，b 变化得<strong>少</strong>一些。</p><p><img src="assets/20171028163526337" alt="这里写图片描述"></p><p>即加快了W方向的速度，减小了b方向的速度，减小振荡，实现快速梯度下降算法，其梯度下降过程如绿色折线所示。总得来说，就是如果哪个方向振荡大，就减小该方向的更新速度，从而减小振荡。</p><p>避免 RMSprop 算法中分母为零，通常可以在分母增加一个极小的常数 $ε$ ：</p><script type="math/tex; mode=display">\begin{equation} W:=W-\alpha \frac{d W}{\sqrt{S_{W}}+\varepsilon}, b:=b-\alpha \frac{d b}{\sqrt{S_{b}}+\varepsilon} \end{equation}</script><p>其中，$ε=10^{−8}$，或者其它较小值。</p><hr><h4 id="2-8-Adam-优化算法"><a href="#2-8-Adam-优化算法" class="headerlink" title="2.8 Adam 优化算法"></a>2.8 Adam 优化算法</h4><p>2015年 ICLR 提出的 A method for Stochastic Optimization, that the name is derived from adaptive moment estimation</p><p>Stochastic Optimization 随机优化</p><p>derived from 来源于</p><p>adaptive moment estimation 自适应矩估计</p><p>Init:  $V_{dW}=0, S_{dW},\space\space V_{db}=0, S_{db}=0$<br>On iteration t:<br>    Compute $dW,\space\space db$<br>    $ V_{d W}=\beta_{1} V_{d W}+\left(1-\beta_{1}\right) d W,\space\space V_{d b}=\beta_{1} V_{d b}+\left(1-\beta_{1}\right) d b $<br>    $ S_{d W}=\beta_{2} S_{d W}+\left(1-\beta_{2}\right) d W^{2},\space\space S_{d b}=\beta_{2} S_{d b}+\left(1-\beta_{2}\right) d b^{2} $<br>    Compute bias corrected 偏差修正<br>    $ V_{d W}^{\text {corrected }}=\frac{V_{d W}}{1-\beta_{1}^{t}},\space\space V_{d b}^{\text {corrected }}=\frac{V_{d b}}{1-\beta_{1}^{t}} $<br>    $ S_{d W}^{\text {corrected }}=\frac{S_{d W}}{1-\beta_{2}^{t}},\space\space S_{d b}^{\text {corrected }}=\frac{S_{d b}}{1-\beta_{2}^{t}} $<br>    $ W:=W-\alpha \frac{V_{d W}^{\text {corrected }}}{\sqrt{S_{d W}^{\text {Corrected }}}},\space\space b:=b-\alpha \frac{V_{d b}^{\text {corrected }}}{\sqrt{S_{d b}^{\text {corrected }}}} $</p><p>计算<strong>Momentum</strong>指数加权平均数，用<strong>RMSprop</strong>进行更新。其中 $dW^2$ $db^2$ 是对整个积分进行平方（element-wise）。偏差修正时的 t 表示迭代次数。</p><p>Adam算法包含了几个超参数，分别是：$α,β_1,β_2,ε$。其中，$β_1$ 通常设置为0.9，$β_2$ 通常设置为0.999，$ε$ 通常设置为 $10^{−8}$。一般只需要对 $β_1$ 和 $β_2$ 进行调试。</p><p>实际应用中，Adam算法结合了动量梯度下降和RMSprop各自的优点，使得神经网络训练速度大大提高。</p><p>adaptive moment estimation 自适应矩估计</p><p>$β_1$ 用来计算微分 $dW$，叫做第一矩</p><p>$β_2$ 用来计算平方数的指数加权平均数 $dW^2$ ，叫做第二矩。</p><p>论文中的算法</p><p><img src="assets/v2-5db14a3057bc9c9c407ede98f14eb6f6_720w.jpg" alt="img"></p><hr><h4 id="2-9-学习率衰减"><a href="#2-9-学习率衰减" class="headerlink" title="2.9 学习率衰减"></a>2.9 学习率衰减</h4><p>learning rate decay</p><p>加快深度学习训练速度的一个办法，随时间慢慢减小学习率。</p><p>如果学习率 $\alpha$ 是固定的值，且batch较小，算法不会收敛，只会在最优解附近不断徘徊。 </p><p>下图中，蓝色折线表示使用恒定的学习因子 $α$，由于每次训练 $α$ 相同，步进长度不变，在接近最优值处的振荡也大，在最优值附近较大范围内振荡，与最优值距离就比较远。绿色折线表示使用不断减小的 $α$，随着训练次数增加，$α$ 逐渐减小，步进长度减小，使得能够在最优值处较小范围内微弱振荡，不断逼近最优值。相比较恒定的 $α$ 来说，learning rate decay 更接近最优值。</p><p>1 epoch = 1 pass through datasets</p><p>遍历一次数据集</p><script type="math/tex; mode=display">\begin{equation} \alpha=\frac{1}{1+\underbrace{\text { decay-rate }}_{\text {hyperparameter }} \times \text { epoch }} \cdot \alpha_{0} \end{equation}</script><p>指数下降</p><script type="math/tex; mode=display">\begin{equation} \alpha=\lambda^{\text {epoch-number }} \cdot \alpha_{0}, \quad \lambda<1 \sim 0.95 \end{equation}</script><p>对数下降</p><script type="math/tex; mode=display">\begin{equation} \alpha=\frac{\overbrace{\gamma_{c o n s t}}^{\text {hyperparameter }}}{\sqrt{\text { epoch-number }}} \cdot \alpha_{0} \quad  or  \quad=\frac{\gamma_{\text {const }}}{\sqrt{t}} \cdot \alpha_{0} \end{equation}</script><p>离散阶梯</p><script type="math/tex; mode=display">\begin{equation} \alpha=f_{\text {discrete staircase }} \end{equation}</script><hr><h4 id="2-10-局部最优的问题"><a href="#2-10-局部最优的问题" class="headerlink" title="2.10 局部最优的问题"></a>2.10 局部最优的问题</h4><p><strong>只要选择合理的强大的神经网络，一般不太可能陷入局部最优</strong></p><p>平稳段是一块区域导数长期为0，会降低学习速度。</p><p>如果都是凸函数，就很好求解。</p><p>马鞍面，一凸一凹组成的，交点为鞍点。</p><hr><h3 id="第三周-超参数调试、Batch-正则化和程序框架"><a href="#第三周-超参数调试、Batch-正则化和程序框架" class="headerlink" title="第三周 超参数调试、Batch 正则化和程序框架"></a>第三周 超参数调试、Batch 正则化和程序框架</h3><h4 id="3-1-调试处理"><a href="#3-1-调试处理" class="headerlink" title="3.1 调试处理"></a>3.1 调试处理</h4><p>T3 学习率 最重要</p><p>T2 动量梯度下降因子 隐藏单元 mini-batch size </p><p>T1 网络层数，学习率衰减因子 </p><p>T0 Adam算法参数</p><p>参数较少时，可以全部试一遍</p><p>参数较多时，随机采样。<strong>coarse to fine</strong> 由粗糙到精细的搜索。即采样后，也许你会发现效果最好的某个点，也许这个点周围的其他一些点效果也很好，那在接下来要做的是放大这块小区域，然后在其中更密集得取值或随机取值，聚集更多的资源。</p><hr><h4 id="3-2-为超参数选择合适的范围"><a href="#3-2-为超参数选择合适的范围" class="headerlink" title="3.2 为超参数选择合适的范围"></a>3.2 为超参数选择合适的范围</h4><p>参数在不同的数量级，对变化的敏感程度不一样，取<strong>对数</strong> log10，就是在数量级上均匀取值（分布），能快速确定数量级大小</p><p>$α \in[ 10^a ~ 10^b]$</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r = np.random.uniform(a, b)</span><br><span class="line">alpha = <span class="number">10</span> ** r</span><br></pre></td></tr></table></figure><p><img src="assets/20171101094754376" alt="这里写图片描述"></p><p>$β \in[0.9 ~ 0.999] → [1-10^{b} ~ 1-10^{a}]$</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r = np.random.uniform(a, b)</span><br><span class="line">beta = <span class="number">1</span> - <span class="number">10</span> ** r</span><br></pre></td></tr></table></figure><hr><h4 id="3-3-超参数训练的实践：Pandas-VS-Caviar"><a href="#3-3-超参数训练的实践：Pandas-VS-Caviar" class="headerlink" title="3.3 超参数训练的实践：Pandas VS Caviar"></a>3.3 超参数训练的实践：Pandas VS Caviar</h4><p><strong>pandas</strong></p><p>照看一个模型，通常是有庞大的数据组，但没有许多计算资源或足够的CPU和GPU的前提下，基本而言，你只可以一次负担起试验一个模型或一小批模型。</p><p>比如，第0天，你将随机参数初始化，然后开始试验，然后你逐渐观察自己的模型评价曲线，在第1天内逐渐减少，那这一天末的时候，试着增加一点学习速率，看看它会怎样，也许结果证明它做得更好。两天后，它依旧做得不错，也许我现在可以填充下Momentum或减少变量。第三天，发现你的学习率太大了，所以你可能又回归之前的模型。</p><p>每天花时间照看此模型，即使是它在许多天或许多星期的试验过程中。所以这是一个人们照料一个模型的方法，观察它的表现，耐心地调试学习率。</p><p><strong>caviar</strong></p><p>同时试验多种模型，你设置了一些超参数，尽管让它自己运行，或者是一天甚至多天，然后会获得多条模型评价曲线。最后快速选择工作效果最好的那个。</p><hr><h4 id="3-4-归一化网络的激活函数"><a href="#3-4-归一化网络的激活函数" class="headerlink" title="3.4 归一化网络的激活函数"></a>3.4 归一化网络的激活函数</h4><p>对当前层的每个样本计算出的隐藏单元值进行归一化，共有m个样本(= mini batch_size)</p><p>已知第 l 层的隐藏单元值为：$ z^{<a href="i">l</a>}=z^{(1)}, z^{(2)}, \ldots, z^{(m)} $</p><p>归一化：</p><script type="math/tex; mode=display">\begin{equation} \begin{aligned}  \mu &=\frac{1}{m} \sum_{i=1}^{m} z^{(i)} \\  \sigma^{2} &=\frac{1}{m} \sum_{i=1}^{m}\left(z^{(i)}-\mu\right)^{2} \\  z_{\text {norm }}^{(i)} &=\frac{z^{(i)}-\mu}{\sqrt{\sigma^{2}+\varepsilon}} \end{aligned} \end{equation}</script><p>其中 $\varepsilon$ 防止分母为0，取值 $10^{-8}$。这样该隐藏层的所有输入 $z^{(i)}$ 均值为0，方差为1。</p><p>但是，大部分情况下并不希望所有的  $z^{(i)}$ 均值都为 0，方差都为 1，也不太合理。通常需要对  $z^{(i)}$  进行进一步处理：</p><script type="math/tex; mode=display">\tilde{z}^{(i)} =\gamma z_{\text {norm }}^{(i)}+\beta</script><p>其中 $\gamma,\beta$ 是需要学习的参数，可以通过梯度下降等算法求得。这里， $\gamma,\beta$ 的作用是让 $ \tilde{z}^{(i)} $ 的均值和方差为任意值，只需调整其值就可以了。特别的如果：</p><script type="math/tex; mode=display">\begin{equation} \gamma=\sqrt{\sigma^{2}+\varepsilon}, \beta=u \end{equation}</script><p>则有 $ \tilde{z}^{(i)} = z^{(i)} $。通过Batch Normalization，对隐藏层的各个$z^{<a href="i">l</a>}$ 进行归一化处理，且下一层的输入为 $ \tilde{z}^{<a href="i">l</a>} $ ，而不是 $ z^{<a href="i">l</a>} $</p><p>输入的标准化处理 Normalizing inputs 和隐藏层的标准化处理 Batch Normalization 是<strong>有区别的</strong>。Normalizing inputs 使所有输入的均值为0，方差为1。而 Batch Normalization 可使各隐藏层输入的均值和方差为任意值。</p><p><img src="assets/2d314293ae9aaa67285299267857632f.png" alt="img"></p><p>实际上，从激活函数的角度来说，如果各隐藏层的输入<strong>均值</strong>在靠近 <strong>0</strong> 的区域即处于激活函数的<strong>线性</strong>区域，这样不利于训练好的非线性神经网络，得到的模型效果也不会太好。这也解释了为什么需要用  $\gamma,\beta$  来对 $z^{<a href="i">l</a>}$ 作进一步处理。</p><hr><h4 id="3-5-将-Batch-Norm-拟合进神经网络"><a href="#3-5-将-Batch-Norm-拟合进神经网络" class="headerlink" title="3.5 将 Batch Norm 拟合进神经网络"></a>3.5 将 Batch Norm 拟合进神经网络</h4><p>batch norm 在激活函数前进行</p><p>全连接网络中共有 N <em> L </em> 2 个 BN 参数，L 表示层数，N 表示一层里隐藏单元数目。</p><p><img src="assets/equation-1617519745354.svg" alt="[公式]"></p><p>如果使用 BN，那么 bias 即 $b$ 可以去除掉，因为要先将 $z^{[L]}$ 减去均值，而 bias 会被均值减法抵消掉。其实 $\beta$ 就把 $b$ 包括进去了，二者都在调整这一特征的平均的水平</p><script type="math/tex; mode=display">\begin{equation} \begin{aligned}  z^{[l]}&=W^{[l]} a^{[l-1]} \\ z_{norm}^{[l]} &= \frac{z^{[l]}-\mu}{\sqrt{\sigma^{2}+\varepsilon}} \\ \tilde{z}^{[l]}&=\gamma^{[l]} z_{\text {norm }}^{[l]}+\beta^{[l]}  \end{aligned}\end{equation}</script><p>Parameters: $ W^{[1]} \in \mathbb{R}^{n[l] \times n^{[l-1]}}, \quad \gamma^{[l]} \in \mathbb{R}^{n^{[l]} \times 1}, \quad \beta^{[l]} \in \mathbb{R}^{n^{[l]} \times 1} $</p><p>for t = 1, 2, …, num_mini_batches<br>    forward prop on $X^{\{t\}}$<br>    in each hidden layer, use BN to replace $z^{[l]}$ with $ \tilde{z}^{[l]}$<br>    back prop to compute $dW^{[l]}, dγ^{[l]}, dβ^{[l]}$<br>    update parameters</p><script type="math/tex; mode=display">\begin{equation} W^{[l]}:=W^{[l]}-\alpha d W^{[l]} \\ \gamma^{[l]}:=\gamma^{[l]}-\alpha d\gamma^{[l]} \\ \beta^{[l]}:=\beta^{[l]}- \alpha d\beta^{[l]} \end{equation}</script><p>works with Momentum / RMSProp / Adam</p><hr><h4 id="3-6-Batch-Norm-为什么奏效？"><a href="#3-6-Batch-Norm-为什么奏效？" class="headerlink" title="3.6 Batch Norm 为什么奏效？"></a>3.6 Batch Norm 为什么奏效？</h4><blockquote><p>covariate shift：两组数据分布不一致，但条件分布一致</p></blockquote><p>BN 减少了隐藏值分布变化的数量。哪怕前一层参数变换，BN后的均值和方差都一样（分布很相同）。</p><p>限制了前层的<strong>参数更新</strong>会<strong>影响</strong>数值<strong>分布</strong>的程度。</p><p>Batch Norm 减少了各层 $W^{[l]}$、$B^{[l]}$ 之间的<strong>耦合性</strong>，让各层更加<strong>独立</strong>，实现自我训练学习的效果。</p><p>对于特别多层的网络，后面的累积<strong>分布差异</strong>跟原数据分布完全不一样。每换一个batch，分布又可能往另一种方式差异化。BN 解决了这个问题。</p><p>简单的说就是让各层之间相对<strong>独立</strong>，不会因为前面层的变动导致后面层巨大变化。</p><p>像是把一个工序相互影响很大的工厂变成流水线，当前一层只需要考虑上一层的结果和当前层的处理。上一层的结果（分布）也比较稳定，当前层做起来就比较轻松。</p><p>BN 一次只能针对一个 mini-batch，每个mini-batch都有一个均值和方差，而不是用整个数据集计算。因此会产生 noise，迫使后边网络，不过分依赖于任何一个隐藏单元，slight 正则化效果。</p><hr><h4 id="3-7-测试时的-Batch-Norm"><a href="#3-7-测试时的-Batch-Norm" class="headerlink" title="3.7 测试时的 Batch Norm"></a>3.7 测试时的 Batch Norm<span id ="BN-test"></span></h4><p>BN 将你的数据以mini-batch的形式逐一处理，但在测试时，你可能需要对每个样本逐一处理</p><p>为了将你的神经网络运用于测试，就需要单独估算 $\mu$ 和 $\sigma^2$.</p><p>可以把所有训练集放入最终的神经网络模型中，然后直接计算每层的参数。</p><p>也可以用指数加权平均。</p><hr><h4 id="3-8-Softmax-回归"><a href="#3-8-Softmax-回归" class="headerlink" title="3.8 Softmax 回归"></a>3.8 Softmax 回归</h4><p>传统logistic回归为 神经网络输出层只有一个神经元，表示预测输出 $\hat{y}$ 是正类的概率$ P(y=1 \mid x)$，$\hat{y}&gt;0.5 $ 则判断为正类，$\hat{y}&lt;0.5 $ 则判断为负类。</p><p>Softmax 处理多分类任务。神经网络中输出层就有C个神经元，即 $n^{[L]} = C$。每个神经元的输出依次对应属于该类的概率 $ P(y=C \mid x)$</p><p>最后一层输出    </p><script type="math/tex; mode=display">\begin{equation} z^{[L]}=W^{[L]} a^{[L-1]}+b^{[L]} \end{equation}</script><p>通过Softmax激活函数</p><script type="math/tex; mode=display"> t=e^{z^{[L]}}, \quad t \in \mathbb{R}^{4 \times 1} \\ a^{[L]}=\frac{e^{z^{[L]}}}{\sum_{i=1}^{4} t_{i}}, \quad a_{i}^{[L]}=\frac{t_{i}}{\sum_{i=1}^{4} t_{i}} \\ \operatorname{softmax}: a_{(c, 1)}^{[L]}=g^{[L]}\left(z_{\{c, 1\rangle}^{[L]}\right)</script><p>其中 C 表示分类数量，例子中 C = 4，a 表示对应所属类的概率，维度与 z 相同。且</p><script type="math/tex; mode=display">\begin{equation} \sum_{i=1}^{C} a_{i}^{[L]}=1 \end{equation}</script><p>Softmax 回归是 logistic 回归的一般形式。Softmax回归 = 分C类的广义逻辑回归</p><p><img src="assets/v2-11758fbc2fc5bbbc60106926625b3a4f_1440w.jpg" alt="详解softmax函数以及相关求导过程"></p><hr><h4 id="3-9-训练一个-Softmax-分类器"><a href="#3-9-训练一个-Softmax-分类器" class="headerlink" title="3.9 训练一个 Softmax 分类器"></a>3.9 训练一个 Softmax 分类器<span id ="dadz"></span></h4><p>让 $\hat{y}2$ 尽可能大，除了第二项其余项都为零</p><script type="math/tex; mode=display">\begin{equation} y=\left[\begin{array}{l}0 \\ 1 \\ 0 \\ 0\end{array}\right] \quad a^{[L]}=\hat{y}=\left[\begin{array}{c}0.3 \\ 0.2 \\ 0.1 \\ 0.4\end{array}\right] \quad C=4 \\ L(\hat{y}, y)=-\sum^{4} y_{j} \log \hat{y}_{j}=-\log \hat{y}_{2} \Rightarrow \hat{y}_{2} \uparrow \end{equation}</script><p>cost函数为</p><script type="math/tex; mode=display">\begin{equation} J\left(W^{[1]}, b^{[1]}, \ldots, W^{[L]}, b^{[L]}\right)=\frac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{(i)}, y^{(i)}\right) \end{equation}</script><p>损失函数为</p><script type="math/tex; mode=display">\begin{equation} L(\hat{y}, y)=-\sum_{j=1}^{4} y_{j} \log \hat{y}_{j} \end{equation}</script><p>其中</p><script type="math/tex; mode=display">da = \frac{\part L}{\part a}=-\frac{y}{\hat{y}}=-\frac{1}{\hat{y}}</script><p>因为 y 的值只有 0/1，0 项消掉了，只剩 1 项。</p><p>激活函数</p><script type="math/tex; mode=display">\begin{equation} t=e^{z^{[L]}}, \quad t \in \mathbb{R}^{C \times 1} \\ a^{[L]}=\frac{e^{z^{[L]}}}{\sum_{i=1}^{C} t_{i}}, \quad a_{i}^{[L]}=\frac{t_{i}}{\sum_{i=1}^{C} t_{i}} \\ \operatorname{softmax}: a_{(c, 1)}^{[L]}=g^{[L]}\left(z_{\{c, 1\rangle}^{[L]}\right) \end{equation}</script><p>其中</p><script type="math/tex; mode=display">\frac{\part a}{\part z} =  \frac{\partial}{\partial z} \cdot\left(\frac{e^{z_{i}}}{\sum_{i=1}^{C} e^{z_{i}}}\right) \\= a\cdot(1-a)</script><p>得</p><script type="math/tex; mode=display">dz=\frac{\part L}{\part z} \\= \frac{\part L}{\part a}\frac{\part a}{\part z} \\=-\frac{1}{\hat{y}}*a(1-a)\\=-\frac{1}{\hat{y}}*\hat{y}(1-\hat{y})\\=\hat{y}-1\\=\hat{y}-y</script><p>其中 a = $\hat{y}$ ，$y=1$</p><hr><h4 id="3-10-深度学习框架"><a href="#3-10-深度学习框架" class="headerlink" title="3.10 深度学习框架"></a>3.10 深度学习框架</h4><p>易于编程，运行速度快，开源</p><hr><h4 id="3-11-TensorFlow"><a href="#3-11-TensorFlow" class="headerlink" title="3.11 TensorFlow"></a>3.11 TensorFlow</h4><p>例如cost function是参数w的函数：</p><script type="math/tex; mode=display">\begin{equation} J=w^{2}-10 w+25 \end{equation}</script><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">coefficients = np.array([[<span class="number">1.</span>], [-<span class="number">10.</span>], [<span class="number">25.</span>]])</span><br><span class="line"></span><br><span class="line">w = tf.Variable(<span class="number">0</span>,dtype=tf.float32)  <span class="comment"># 定义参数w 初始化为0 </span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="number">3</span>,<span class="number">1</span>]) <span class="comment"># training data size为 3x1 稍后为x提供数值    现在x变成了控制这个二次函数系数的数据</span></span><br><span class="line">cost = x[<span class="number">0</span>][<span class="number">0</span>]*w**<span class="number">2</span> + x[<span class="number">1</span>][<span class="number">0</span>]*w + x[<span class="number">2</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># cost = tf.add(tf.add(w**2, tf.multiply(10., w)), 25) # 定义cost fucition</span></span><br><span class="line">cost = w**<span class="number">2</span> - <span class="number">10</span>*w + <span class="number">25</span> <span class="comment"># 重载了加减运算</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(cost) <span class="comment"># 优化器为梯度下降 学习率0.01 指定最小化函数为cost</span></span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initalizer() <span class="comment"># 初始化</span></span><br><span class="line">session = tf.Sessions() <span class="comment"># 开启一个tf session </span></span><br><span class="line">session.run(init) <span class="comment"># 初始化全局变量 给w赋初值</span></span><br><span class="line">session.run(w) <span class="comment"># 评估变量w</span></span><br><span class="line"></span><br><span class="line">session.run(train) <span class="comment"># 开始优化 1步</span></span><br><span class="line">session.run(train, feed_dict = &#123;x:coefficients&#125;) <span class="comment"># 开始优化 并给x赋值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>): <span class="comment"># 优化1000步</span></span><br><span class="line">    session.run(train)</span><br><span class="line">    session.run(train, feed_dict = &#123;x:coefficients&#125;) <span class="comment"># 开始优化 并给x赋值</span></span><br><span class="line">    </span><br></pre></td></tr></table></figure><p><strong>TensorFlow</strong> 中的 <strong>placeholder</strong> 是一个你之后会赋值的变量，这种方式便于把训练数据加入损失方程，把数据加入损失方程用的是这个句法，当你运行训练迭代，用 <code>feed_dict</code> 来让 <code>x=coefficients</code>。</p><p>如果你在做 <strong>mini-batch</strong> 梯度下降，在每次迭代时，你需要插入不同的 <strong>mini-batch</strong>，那么每次迭代，你就用 <code>feed_dict</code> 来喂入训练集的不同子集，把不同的 <strong>mini-batch</strong> 喂入损失函数需要数据的地方。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">session = tf.Sessions() <span class="comment"># 开启一个tf session </span></span><br><span class="line">session.run(init) <span class="comment"># 初始化全局变量 给w赋初值</span></span><br><span class="line">session.run(w) <span class="comment"># 评估变量w</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以替换为</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session()  <span class="keyword">as</span> session:</span><br><span class="line">session.run(init)</span><br><span class="line">    <span class="built_in">print</span>(session.run(w))</span><br></pre></td></tr></table></figure><p><strong>Python</strong>中的<strong>with</strong>命令更方便清理，以防在执行这个内循环时出现错误或例外</p><p>TensorFlow的最大优点就是采用数据流图（data flow graphs）来进行数值运算。图中的节点（Nodes）表示<strong>数学操作</strong>，图中的线（edges）则表示在节点间相互联系的<strong>多维数据数组</strong>，即张量（tensor）。而且它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个CPU（或GPU），服务器，移动设备等等。</p><hr><h2 id="第四周【人工智能行业大师访谈】"><a href="#第四周【人工智能行业大师访谈】" class="headerlink" title="第四周【人工智能行业大师访谈】"></a>第四周【人工智能行业大师访谈】</h2><h4 id="4-1-吴恩达采访-Yoshua-Bengio"><a href="#4-1-吴恩达采访-Yoshua-Bengio" class="headerlink" title="4.1. 吴恩达采访 Yoshua Bengio"></a>4.1. 吴恩达采访 Yoshua Bengio</h4><p>花书作者</p><p>self attention</p><p>but i dont think that we need that everything be formalized mathematically but be formalized logically, not the sense that i can convice somebody that this should be work, whether this make sense. This is the most important aspect. And then math allows us to make that stronger and tighter. </p><p>不认为一切事物都要数学化， 而是要逻辑化，并不是我可以让别人相信这样有用，可行。 然后再通过数学来强化和精练。</p><p>大多数人只停留在粗浅了解的程度，一旦出现问题，使用者很难解决，也不知道原因。所以大家要亲自实践，即便效率不高，只要知道是怎么回事就好，很有帮助，尽量亲自动手。 所以不要用那种几行代码就可以解决一切，却不知道其中原理的编程框架。尽量从基本原理入手获取知识。多阅读，多看别人的代码，多自己写代码。</p><p>不要畏惧数学，发展直觉认识，一旦在直觉经验层面得心应手，数学问题会变得更容易理解。 </p><hr><h4 id="4-2-吴恩达采访-林元庆"><a href="#4-2-吴恩达采访-林元庆" class="headerlink" title="4.2. 吴恩达采访 林元庆"></a>4.2. 吴恩达采访 林元庆</h4><p> 国家深度学习实验室</p><hr>]]></content>
      
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C_DL_W1</title>
      <link href="/2022/03/28/C-DL-W1/"/>
      <url>/2022/03/28/C-DL-W1/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习工程师"><a href="#深度学习工程师" class="headerlink" title="深度学习工程师"></a>深度学习工程师</h1><p>由 deeplearning.ai 出品，网易引进的正版授权中文版深度学习工程师微专业课程，让你在了解丰富的人工智能应用案例的同时，学会在实践中搭建出最先进的神经网络模型，训练出属于你自己的 AI。<br><span id="more"></span></p><p>deeplearning.ai</p><p><a href="https://www.coursera.org/learn/neural-networks-deep-learning?action=enroll">https://www.coursera.org/learn/neural-networks-deep-learning?action=enroll</a></p><p><a href="https://study.163.com/my#/smarts">https://study.163.com/my#/smarts</a></p><p><a href="https://www.bilibili.com/video/av66314465">https://www.bilibili.com/video/av66314465</a></p><p><strong>note</strong></p><p><a href="https://blog.csdn.net/red_stone1/article/details/78208851">https://blog.csdn.net/red_stone1/article/details/78208851</a></p><p><a href="https://www.zhihu.com/column/DeepLearningNotebook">https://www.zhihu.com/column/DeepLearningNotebook</a></p><p><a href="http://www.ai-start.com/dl2017/">http://www.ai-start.com/dl2017/</a></p><p><strong>课后作业</strong></p><p><a href="https://blog.csdn.net/u013733326/article/details/79827273">https://blog.csdn.net/u013733326/article/details/79827273</a></p><p><a href="https://www.heywhale.com/mw/project/5e20243e2823a10036b542da">https://www.heywhale.com/mw/project/5e20243e2823a10036b542da</a></p><h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><ul><li>[x] 神经网络和深度学习-<a href="#dz">3.9</a> $dZ^{[2]}$ ????????????????</li></ul><h2 id="神经网络和深度学习"><a href="#神经网络和深度学习" class="headerlink" title="神经网络和深度学习"></a>神经网络和深度学习</h2><h3 id="第一周-深度学习概论"><a href="#第一周-深度学习概论" class="headerlink" title="第一周 深度学习概论"></a>第一周 深度学习概论</h3><h4 id="1-1-欢迎来到深度学习工程微专业"><a href="#1-1-欢迎来到深度学习工程微专业" class="headerlink" title="1.1. 欢迎来到深度学习工程微专业"></a>1.1. 欢迎来到深度学习工程微专业</h4><h4 id="1-2-什么是神经网络？"><a href="#1-2-什么是神经网络？" class="headerlink" title="1.2. 什么是神经网络？"></a>1.2. 什么是神经网络？</h4><p><img src="assets/1616421771173.png" alt="1616421771173"></p><p>输入为房屋面积 , 通过一个神经元（函数运算），然后输出房价 y</p><p>ReLU （Rectified Linear Unit，railu） 修正线性单元  修正是指取不小于0的值</p><p><img src="assets/1616422154046.png" alt="1616422154046"></p><p>中间三个圈为隐藏单元，每个隐藏单元都来自自己学习到的权重，与输入加权求和。</p><hr><h4 id="1-3-用神经网络进行监督学习"><a href="#1-3-用神经网络进行监督学习" class="headerlink" title="1.3. 用神经网络进行监督学习"></a>1.3. 用神经网络进行监督学习</h4><p>监督学习的应用</p><p>实值估计，在线广告，</p><p>机智的选择输入和输出，解决特定问题，并把这部分学习过的组件嵌入到更大型的系统。</p><p>普通应用 对应 标准的神经网络NN</p><p>图像领域内，卷积神经网络 CNN</p><p>对于序列数据，循环神经网络 RNN</p><p>更复杂的应用 复杂的混合神经网络架构。</p><p>训练数据分为<strong>结构化数据</strong>和<strong>非结构化数据</strong></p><p>结构化数据       每个特征都有清晰的定义。</p><p>非结构化数据   例如音频，图像，文本</p><p>好的网络能够同时适应结构化和非结构化数据</p><hr><h4 id="1-4-为什么深度学习会兴起？"><a href="#1-4-为什么深度学习会兴起？" class="headerlink" title="1.4. 为什么深度学习会兴起？"></a>1.4. 为什么深度学习会兴起？</h4><p>普通的模型无法应用海量数据带来的益处，有时也无法处理海量数据，</p><p>而给规模足够大（有许多隐藏神经元）的神经网络输入海量数据，会增强performance</p><p>一些算法创新可以让神经网络运行效率更高，效果更好，是我们可以训练更大规模的网络。</p><p><img src="assets/1616423575240.png" alt="1616423575240"></p><p>传统sigmod函数，让负值梯度趋近于零但不是零，学习会变得非常缓慢，因为当梯度接近0时，使用梯度下降法，参数会变化得很慢，学习也变得很慢。</p><p>而relu让负值梯度直接为0，直接不学习。加速梯度下降。</p><p><img src="assets/1616423610014.png" alt="1616423610014"></p><p>很多时候，有了一个新想法，关于神经网络结构的想法，然后写代码实现想法，结果表现神经网络的效果，然后进一步赶紧神经网络结构的细节。</p><hr><h4 id="1-5-关于这门课"><a href="#1-5-关于这门课" class="headerlink" title="1.5. 关于这门课"></a>1.5. 关于这门课</h4><h4 id="1-6-课程资源"><a href="#1-6-课程资源" class="headerlink" title="1.6. 课程资源"></a>1.6. 课程资源</h4><p>coursea -&gt; disscusion </p><hr><h3 id="第二周-神经网络基础"><a href="#第二周-神经网络基础" class="headerlink" title="第二周 神经网络基础"></a>第二周 神经网络基础</h3><h4 id="2-1-二分分类"><a href="#2-1-二分分类" class="headerlink" title="2.1. 二分分类"></a>2.1. 二分分类</h4><p>m个样本的训练集，遍历这个训练集，</p><p>正向过程/传播    forward pass/propagation</p><p>反向过程/传播    backward pass/propagation</p><p>计算机存储图像，用红绿蓝三个通道的矩阵表示。</p><p><img src="assets/1616475094011.png" alt="1616475094011"></p><p>在进行网络训练时，通常要unroll或者reshape为一维向量。</p><p><img src="assets/1616475156017.png" alt="1616475156017"></p><p>（x，y） 来表示一个单独的样本，x是n_x维的特征向量 $x \in \mathbb{R}^{n_x}$，y是标签值为 0 或 1</p><p>共有m个样本 ：$(x^{(1)},y^{(1)}) , (x^{(2)},y^{(2)}), \dots, (x^{(m)},y^{(m)})$</p><p>也可以用大写 $X$ 表示训练集</p><p><img src="assets/equation-1617340213621.svg" alt="[公式]"></p><p>m列表示m个样本，n_x行表示每个样本有n_x条特征，表示为 $X \in \mathbb{R}^{n_x \times m}$ 或者 <code>X.shape=(n_x,m)</code>，有时行列相反。</p><p><img src="assets/equation-1617340240915.svg" alt="[公式]"></p><p>m列表示m个样本，1行表示每个样本有1个输出标签，表示为 $Y \in \mathbb{R}^{1\times m}$ 或者 <code>Y.shape=(1,m)</code></p><hr><h4 id="2-2-logistic-回归"><a href="#2-2-logistic-回归" class="headerlink" title="2.2. logistic 回归"></a>2.2. logistic 回归</h4><p>给输入 $x$ 希望输出 $\hat{y}$ 判断是不是一副 cat picture。一般  $\hat{y}$ 是一个概率，当输入特征x满足一定的条件时，y就是1。</p><script type="math/tex; mode=display">\hat{y} = P(y=1|x)</script><p>输入 $X \in \mathbb{R}^{n_x \times m}$ ，logistic 参数  $w \in \mathbb{R}^{n_x}$  , $b \in \mathbb{R}$ 是一个实数。</p><script type="math/tex; mode=display">\hat{y} = w^Tx+b</script><p>可能是一个上述的线性函数，但可能性不大，因为输出概率在0到1之间。</p><p>而 logistic 回归给一个 sigmoid 函数</p><script type="math/tex; mode=display">\hat{y} = \sigma (w^Tx+b)</script><p><img src="assets/1616476097923.png" alt="1616476097923"></p><p>输出为从 0 到 1 的光滑函数 $\sigma (z)$，其中在本例中 $z = w^Tx+b$</p><script type="math/tex; mode=display">\sigma (z) = \frac{1}{1-e^{-z}}</script><p>如果 z 特别大，趋近于1；z 特别小，趋近于0。</p><p>神经网络学习 w 和 b 两个参数，通常 b 对应一个 intercepter 拦截器</p><hr><h4 id="2-3-logistic-回归损失函数"><a href="#2-3-logistic-回归损失函数" class="headerlink" title="2.3. logistic 回归损失函数"></a>2.3. logistic 回归损失函数<span id="logistic"></span></h4><p>为了训练 w 和 b 两个参数，需要定义一个 loss function。给定输入$(x^{(1)},y^{(1)}) , (x^{(2)},y^{(2)}), \dots, (x^{(m)},y^{(m)})$ ，我们希望预测到的 $\hat{y}^{(i)} \approx  y^{(i)}$</p><p>我们可以定义损失函数，衡量预测值与实际值的差距，用误差平方不利于梯度下降，因为会将问题变成<strong>非凸non-convex函数</strong>（w形状，有多个局部最小值）。</p><script type="math/tex; mode=display">\begin{equation} \mathcal{L}(\hat{y}, y)=\frac{1}{2}(\hat{y}-y)^{2} \end{equation}</script><p>换一种损失函数，<strong>凸convex函数</strong>（v形状，有一个全局最小值）。</p><script type="math/tex; mode=display">\begin{equation} \mathcal{L}(\hat{y}, y)=-(y \log \hat{y}+(1-y) \log (1-\hat{y})) \end{equation}</script><p>如果 y = 1 时， $\mathcal{L}(\hat{y}, y)=- \log \hat{y}$。损失函数越小越好，即 $\log \hat{y}$ 越大越好，这时 $ \hat{y}$ 要接近 y 的值 1</p><p>如果 y = 0 时， $ \mathcal{L}(\hat{y}, y)= -\log (1-\hat{y})) $。损失函数越小越好， $\log (1-\hat{y}))$ 越大越好，这时 $ \hat{y}$ 要接近 y 的值 0</p><p>loss函数衡量了<strong>单个</strong>训练样本的表现。cost 函数衡量<strong>全体</strong>训练样本的表现。</p><script type="math/tex; mode=display">\begin{split} J(w, b)&=\frac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{(i)}, y^{(i)}\right)\\&=-\frac{1}{m} \sum_{i=1}^{m}\left[y^{(i)} \log \hat{y}^{(i)}+\left(1-y^{(i)}\right) \log \left(1-\hat{y}^{(i)}\right)\right]\end{split}</script><p>即损失函数的平均值。</p><blockquote><p>凸优化问题是指 $\chi$ 是<strong>闭合的凸集</strong>且 $f$ 是 $\chi$ 上的<strong>凸函数</strong>的最优化问题，这两个条件任一不满足则该问题即为非凸的最优化问题。</p><p><strong>为什么要求是凸函数呢？因为如果是下图这样的函数，则无法获得全局最优解。</strong></p><p><img src="assets/20140107114211578.jpeg" alt="img"></p><p><strong>为什么要求是凸集呢？因为如果可行域不是凸集，也会导致局部最优</strong></p><p><img src="assets/20140107114309671.jpeg" alt="img"></p></blockquote><hr><h4 id="2-4-梯度下降法"><a href="#2-4-梯度下降法" class="headerlink" title="2.4. 梯度下降法"></a>2.4. 梯度下降法</h4><p>gradient descent</p><p>已知待训练sigmod函数： $ \hat{y}=\sigma\left(w^{T} x+b\right), \sigma(z)=\frac{1}{1+e^{-z}} $</p><p>成本函数： </p><script type="math/tex; mode=display">\begin{split} J(w, b)&=\frac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{(i)}, y^{(i)}\right)\\&=-\frac{1}{m} \sum_{i=1}^{m}\left[y^{(i)} \log \hat{y}^{(i)}+\left(1-y^{(i)}\right) \log \left(1-\hat{y}^{(i)}\right)\right]\end{split}</script><p>找到合适的 w 和 b 让成本函数较小。</p><p><img src="assets/image-20210324213334658.png" alt="image-20210324213334658"></p><p><strong>J(w,b) 是在水平轴 w 和 b 上的曲面，找到 J(w,b) 最小值对应的参数。</strong></p><p>方法:</p><p>用某个随即参数初始化一个点，朝最陡的方向走。</p><p>重复执行$ \omega=\omega-\alpha \frac{dJ(\omega)}{d \omega} $，直到算法收敛。其中 $\alpha$ 为学习率，控制每次迭代中梯度下降的步长，$\frac{dJ(\omega)}{d \omega}$ 是参数的更新量或变化量。</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">w = w - a * dw; <span class="comment">// dw = deltaJ / deltaw;  dw是此点的导数 此点函数的斜率</span></span><br><span class="line">b = b - a * db; <span class="comment">// db = deltaJ / deltab;  pytorch自动求导</span></span><br></pre></td></tr></table></figure><hr><h4 id="2-5-导数"><a href="#2-5-导数" class="headerlink" title="2.5. 导数"></a>2.5. 导数</h4><p>derivatives</p><p>slope斜率 = 绿色极限三角形的高除以宽 = 0.003/0.001 = 3</p><p><img src="assets/1616478167609.png" alt="1616478167609"></p><p>a1 = 2             f(a1) = 6</p><p>a2 = 2.001     f(a2) = 6.003</p><p>df = f(a2) - f(a1) / (a2 - a1) = 6.003 - 6 / (2.001 - 2) = 3</p><p>这个函数任何地方的斜率都是 3。</p><hr><h4 id="2-6-更多导数的例子"><a href="#2-6-更多导数的例子" class="headerlink" title="2.6. 更多导数的例子"></a>2.6. 更多导数的例子</h4><p>也就是复杂函数求导</p><hr><h4 id="2-7-计算图"><a href="#2-7-计算图" class="headerlink" title="2.7. 计算图"></a>2.7. 计算图</h4><p>computation graph</p><p>神经网络都是按照<strong>前向</strong>或者<strong>反向传播</strong>过程来实现的。</p><p>首先计算出神经网络的输出，紧接着进行一个<strong>反向传输操作</strong>。后者用来计算出对应的梯度或者导数。</p><p>$J(a,b,c) = 3(a + b <em> c)$ 是三个变量a,b,c的函数，我们可以设定 `u = b</em>c<code>，</code>v = a + u<code>，</code>J = 3*v`，则有下图</p><p><img src="assets/image-20210324205340803.png" alt="image-20210324205340803"></p><p>通过一个从左向右的过程，可以计算出 $J$ 的值。通过从右向左可以计算出导数。</p><hr><h4 id="2-8-计算图中的导数计算"><a href="#2-8-计算图中的导数计算" class="headerlink" title="2.8. 计算图中的导数计算"></a>2.8. 计算图中的导数计算</h4><p>按照上图计算，$J$ 对 $v$ 的导数，$\frac{dJ}{dv} = 3$。a的值改变，v的值就会改变，J的值也会改变。a改变，v改变量取决于 $\frac{dv}{da}$，</p><p>链式法则 $\frac{dJ}{da} = \frac{dJ}{dv}  \frac{dv}{da}$，$\frac{dJ}{db} = \frac{dJ}{dv}  \frac{dv}{du} \frac{du}{db}$，$\frac{dJ}{dc} = \frac{dJ}{dv}  \frac{dv}{du} \frac{du}{dc}$</p><hr><h4 id="2-9-logistic回归中的梯度下降法"><a href="#2-9-logistic回归中的梯度下降法" class="headerlink" title="2.9. logistic回归中的梯度下降法"></a>2.9. logistic回归中的梯度下降法</h4><script type="math/tex; mode=display">z = w^Tx+b</script><script type="math/tex; mode=display">\hat{y} = a =\sigma (z)</script><script type="math/tex; mode=display">\mathcal{L}(\hat{y}, y)=-(y \log a+(1-y) \log (1-a))</script><p>a是 logistics 函数的输出，y 是标签真值。</p><p>如果有两个特征 $x_1$ 和 $x_2$ 则</p><script type="math/tex; mode=display">z = w_1^Tx_1+w_2^Tx_2 +b</script><p>在 logistic 回归中，我们需要做的是，<strong>变换参数</strong> w 和 b 来最小化损失函数，</p><p><img src="assets/image-20210324211215820.png" alt="image-20210324211215820"></p><p>其中</p><script type="math/tex; mode=display">\frac{dL}{da} = -\frac{y}{a} + \frac{1-y}{1-a}</script><p>其中<span id="dz"></span></p><script type="math/tex; mode=display">\begin{split}\frac{dL}{dz} &= \frac{dL}{da} \frac{da}{dz}\\&=(-\frac{y}{a} + \frac{1-y}{1-a}) * (a(1-a))\\&=a-y\end{split}</script><p>其中目标函数对三个参数的导数如下：</p><script type="math/tex; mode=display">\begin{split}\frac{dL}{dw_1} &= x_1*\frac{dL}{dz}\\\frac{dL}{dw_2} &= x_2*\frac{dL}{dz}\\\frac{dL}{db} &= \frac{dL}{dz}\end{split}</script><p>然后根据下式更新参数。</p><script type="math/tex; mode=display">\begin{split}w_1 &= w_1 - \alpha \frac{dL}{dw_1}\\w_2 &= w_2 - \alpha \frac{dL}{dw_2}\\b &= b - \alpha \frac{dL}{db}\end{split}</script><hr><h4 id="2-10-m个样本的梯度下降"><a href="#2-10-m个样本的梯度下降" class="headerlink" title="2.10. m个样本的梯度下降"></a>2.10. m个样本的梯度下降</h4><p>上一节均为单一样本的求导与参数更新。实际情况下，训练集会有很多样本。</p><script type="math/tex; mode=display">\begin{split} J(w, b)&=\frac{1}{m} \sum_{i=1}^{m} L(\hat{y}^{(i)}, y^{(i)})\\&=-\frac{1}{m} \sum_{i=1}^{m}\left[y^{(i)} \log \hat{y}^{(i)}+(1-y^{(i)}) \log (1-\hat{y}^{(i)})\right]\end{split}</script><p>其中</p><script type="math/tex; mode=display">\hat{y}^{i} = a =\sigma (z^{i})=\sigma (w^Tx^{i}+b)</script><p>直接求导</p><script type="math/tex; mode=display">\frac{\partial J(w, b)}{\partial w_1} = \frac{1}{m} \sum_{i=1}^{m}\frac{\partial L(\hat{y}^{(i)}, y^{(i)})}{\partial w_i}</script><p>计算每一个样本的梯度值，然后求平均，会得到全局梯度值，可以直接用到梯度下降法。</p><p><img src="assets/image-20210324214705487.png" alt="image-20210324214705487"></p><p>整个过程相当于一次epoch。每次将所有样本计算过一边后，梯度下降一次，更改参数。重复多次。</p><p><strong>显式的使用循环，会使算法很低效。</strong>因此向量化编程有很大的帮助。</p><hr><h4 id="2-11-向量化"><a href="#2-11-向量化" class="headerlink" title="2.11. 向量化"></a>2.11. 向量化</h4><p>消除代码中显式for循环语句的艺术。<strong>不能使用显式for循环</strong>，numpy隐式循环。</p> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time </span><br><span class="line"></span><br><span class="line"><span class="comment"># vectorization version</span></span><br><span class="line">a = np.randrom.rand(<span class="number">1000000</span>)</span><br><span class="line">b = np.randrom.rand(<span class="number">1000000</span>)</span><br><span class="line"></span><br><span class="line">tic = time.time()</span><br><span class="line">c = np.dot(a,b)</span><br><span class="line">toc = time.tiem()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Vectorized version:&quot;</span> + <span class="built_in">str</span>(<span class="number">1000</span>*(toc-tic)) + <span class="string">&quot;ms&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># for loop version</span></span><br><span class="line">c = <span class="number">0</span></span><br><span class="line">tic = time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000000</span>)</span><br><span class="line">c += a[i]*b[i]</span><br><span class="line">toc = time.time()   </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;For loop version:&quot;</span> + <span class="built_in">str</span>(<span class="number">1000</span>*(toc-tic)) + <span class="string">&quot;ms&quot;</span>)  <span class="comment"># 时间比向量化版本长</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>CPU 和 GPU 都有并行处理能力 <strong>SIMD 单指令多数据流</strong></p><hr><h4 id="2-12-向量化的更多例子"><a href="#2-12-向量化的更多例子" class="headerlink" title="2.12. 向量化的更多例子"></a>2.12. 向量化的更多例子</h4><p>计算</p><script type="math/tex; mode=display">\begin{split}u &= Av\\u_i &= \sum_i\sum_jA_{ij}v_j\end{split}</script><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">u = np.zeros((n, <span class="number">1</span>))</span><br><span class="line"><span class="keyword">for</span> i </span><br><span class="line"><span class="keyword">for</span> j</span><br><span class="line">    u[i] = A[i][j] * v[j]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或</span></span><br><span class="line">u = np.dot(A,v)       </span><br></pre></td></tr></table></figure><p>计算</p><script type="math/tex; mode=display">u_i = e^{v_i}</script><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">u = np.zeros((n, <span class="number">1</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)</span><br><span class="line">u[i] = math.exp(v[i])</span><br><span class="line"><span class="comment"># 或</span></span><br><span class="line">u = np.exp(v);</span><br><span class="line">np.log(v);</span><br><span class="line">np.<span class="built_in">abs</span>(v);</span><br><span class="line">np.maximun(v,<span class="number">0</span>) <span class="comment"># v中所有元素和0之间相比的最大值</span></span><br><span class="line">v**<span class="number">2</span><span class="comment">#v^2    </span></span><br><span class="line"><span class="number">1</span>/v     <span class="comment">#v的倒数</span></span><br></pre></td></tr></table></figure><p>Logistic 回归求导</p><p><img src="assets/1616648854396.png" alt="1616648854396"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">J = <span class="number">0</span>, dw1 = <span class="number">0</span>, dw2 = <span class="number">0</span>, db = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i = <span class="number">1</span> to n:</span><br><span class="line">    z[i] = w^T * x[i] + b</span><br><span class="line">    a[i] = sigma(z[i])  <span class="comment">#sigma  1 / (1 + e^-x)</span></span><br><span class="line">    J += -[y[i] * log(yhat[i]) + (<span class="number">1</span> - y[i]) * log(<span class="number">1</span> - yhat[i])]</span><br><span class="line">    dz = a[i] * (<span class="number">1</span> - a[i])   <span class="comment"># dz = da/dz</span></span><br><span class="line">    dw1 = x1[i] * dz[i]</span><br><span class="line">    dw2 = x2[i] * dz[i]</span><br><span class="line">    db += dz[i]</span><br><span class="line">J = J / m</span><br><span class="line">dw1 = dw1 / m</span><br><span class="line">dw2 = dw2 / m</span><br><span class="line">db = db / m</span><br></pre></td></tr></table></figure><hr><h4 id="2-13-向量化-logistics-回归"><a href="#2-13-向量化-logistics-回归" class="headerlink" title="2.13. 向量化 logistics 回归"></a>2.13. 向量化 logistics 回归</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">z = np.dot(w.t ,x) + b</span><br><span class="line">a = <span class="number">1</span> / np.exp(-z)</span><br></pre></td></tr></table></figure><p>b 是一个实数，python会自动把实数b 扩展成一个<code>1*m</code> 的行向量</p><hr><h4 id="2-14-向量化-logistics-回归的梯度输出"><a href="#2-14-向量化-logistics-回归的梯度输出" class="headerlink" title="2.14. 向量化 logistics 回归的梯度输出"></a>2.14. 向量化 logistics 回归的梯度输出</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dz = a - y;   <span class="comment"># dz = dL/dz  不是   da/dz</span></span><br><span class="line">dw = np.<span class="built_in">sum</span>(np.dot(x, dz.t)) / m</span><br><span class="line">db = np.<span class="built_in">sum</span>(dz) / m</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 总向量化编程logistics回归</span></span><br><span class="line">z = np.dot(w.t ,x) + b</span><br><span class="line">a = <span class="number">1</span> / np.exp(-z)</span><br><span class="line">dz = a - y;   <span class="comment"># dz = dL/dz  不是   da/dz</span></span><br><span class="line">dw = np.<span class="built_in">sum</span>(np.dot(x, dz.t)) / m</span><br><span class="line">db = np.<span class="built_in">sum</span>(dz) / m</span><br><span class="line"></span><br><span class="line">w = w - alpha * dw</span><br><span class="line">b = b - alpha * db</span><br></pre></td></tr></table></figure><p>仍然需要一个大 for 循环，实现每一次梯度更新，即eopch。</p><hr><h4 id="2-15-Python-中的广播"><a href="#2-15-Python-中的广播" class="headerlink" title="2.15. Python 中的广播"></a>2.15. Python 中的广播</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">A = np.array([<span class="number">56</span> , <span class="number">0</span> , <span class="number">4.4</span> , <span class="number">68</span>],</span><br><span class="line">            [<span class="number">1.2</span>, <span class="number">104</span>, <span class="number">52</span>, <span class="number">8</span>],</span><br><span class="line">            [<span class="number">1.8</span>, <span class="number">135</span>, <span class="number">99</span>, <span class="number">0.9</span>])</span><br><span class="line">cal = A.<span class="built_in">sum</span>(axis = <span class="number">0</span>) <span class="comment">#按列求和  按行求和axis = 1</span></span><br><span class="line">percentage = <span class="number">100</span> * A / cal.reshape(<span class="number">1</span>,<span class="number">4</span>)  <span class="comment">#A 3x4         cal 1x4 </span></span><br><span class="line"><span class="comment">#.reshape(1,4) 可以确保矩阵形状是我们想要的</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>广播（broadcasting）即<strong>同型复制</strong></p><p><strong>general principle</strong></p><p>size ：[m,n] +-*/ [1,n]  把 [1,n] 复制m行变成  [m,n]再和前项运算</p><p>size ：[m,n] +-*/ [m,1] 把 [m,1]复制n列变成 [m,n] 再和前项</p><hr><h4 id="2-16-关于-python-numpy-向量的说明"><a href="#2-16-关于-python-numpy-向量的说明" class="headerlink" title="2.16. 关于 python/numpy 向量的说明"></a>2.16. 关于 python/numpy 向量的说明</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 避免使用秩为 1 的矩阵</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.random.randn(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">a.shape  <span class="comment">#(5, ) 秩为1的数组 </span></span><br><span class="line">np.dot(a, a.T)   <span class="comment"># 算出来是内积 一个数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 尽量不要使用秩为1的数组 即</span></span><br><span class="line">a = np.random.randn(<span class="number">5</span>) </span><br><span class="line"><span class="comment"># 改为</span></span><br><span class="line">a = np.random.randn(<span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">a.shape  <span class="comment">#(5, 1) 秩不为1的数组 </span></span><br><span class="line">np.dot(a, a.T)   <span class="comment"># 算出来是外积 一个矩阵</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用断言加以保障 执行很快 </span></span><br><span class="line"><span class="keyword">assert</span>(a.shape == (<span class="number">5</span>,<span class="number">1</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#确保形状</span></span><br><span class="line">reshape</span><br></pre></td></tr></table></figure><hr><h4 id="2-17-Jupyter-Ipython笔记本的快速指南"><a href="#2-17-Jupyter-Ipython笔记本的快速指南" class="headerlink" title="2.17. Jupyter/Ipython笔记本的快速指南"></a>2.17. Jupyter/Ipython笔记本的快速指南</h4><p>shift + enter 执行代码段</p><p>kernel 重启内核</p><p>submit assignment 提交任务</p><hr><h4 id="2-18-logistic-损失函数的解释"><a href="#2-18-logistic-损失函数的解释" class="headerlink" title="2.18 logistic 损失函数的解释"></a>2.18 logistic 损失函数的<a href="#logistic">解释</a></h4><script type="math/tex; mode=display">\hat{y} = \sigma (w^Tx+b)</script><script type="math/tex; mode=display">\sigma (z) = \frac{1}{1-e^{-z}}</script><p>我们设定</p><script type="math/tex; mode=display">\begin{equation} \hat{y}=P(y=1 \mid x) \end{equation}</script><p>即算法的输出 $\hat{y}$ 是给定训练样本 x 条件下 y 等于 1 的概率。</p><p>换句话说，如果 y=1，那么在给定 x 得到 y=1的概率等于 $\hat{y}$ </p><p>反过来说，如果 y=0，那么在给定 x 得到 y=0 的概率等于$1-\hat{y}$</p><p>下边有验证。</p><p>简单说  $\hat{y}$ 表示 y=1的概率。</p><script type="math/tex; mode=display">\begin{equation}if \quad y=1: \quad p(y \mid x)=\hat{y} \\if \quad y=0: \quad p(y \mid x)=1-\hat{y} \end{equation}</script><p>二分类问题，y的取值只能是0或1。</p><p>0-1分布/二项分布/伯努利分布，上述两条公式可以合并成</p><script type="math/tex; mode=display">\begin{equation} p(y \mid x)=\hat{y}^{y}(1-\hat{y})^{(1-y)} \end{equation}</script><p>当 y = 1或 y = 0 代入上式可以得到上上式的结论。</p><p>两边同时取<strong>对数</strong>，方便<strong>展开</strong>/<strong>求导/优化</strong>。</p><script type="math/tex; mode=display">\begin{equation} \log p\left(\left.y\right|x\right)=\log \hat{y}^{y}(1-\hat{y})^{(1-y)}=y \log \hat{y}+(1-y) \log (1-\hat{y}) \end{equation}</script><p>概率为1时，log函数为0，概率为0时，log函数为负无穷。</p><p>假设所有样本<strong>独立同分布</strong></p><script type="math/tex; mode=display">\begin{equation}P= \prod_{i=1}^{m} p\left(y^{(i)} \mid x^{(i)}\right) \end{equation}</script><p>由于各个样本<strong>独立</strong>，因此求得<strong>全局最优</strong>的条件便是求得<strong>各样本最优</strong>，也即各个样本取得<strong>最优的概率的连乘</strong></p><p>两边同时取<strong>对数</strong>，方便<strong>展开</strong>/<strong>求导/优化</strong>。</p><script type="math/tex; mode=display">\begin{equation}\log P= \sum_{i=1}^{m} \log p\left(y^{(i)} \mid x^{(i)}\right) \end{equation}</script><p>最大似然估计，即求出一组参数，这里就是w和b，使这个式子取最大值。</p><p>也就是说这个式子最大值，$\hat{y}$ 和 $y$ 越接近，网络越好。</p><hr><h3 id="第三周-浅层神经网络"><a href="#第三周-浅层神经网络" class="headerlink" title="第三周 浅层神经网络"></a>第三周 浅层神经网络</h3><h4 id="3-1-神经网络概览"><a href="#3-1-神经网络概览" class="headerlink" title="3.1. 神经网络概览"></a>3.1. 神经网络概览</h4><p>右上角方括号内表示网络的层数</p><p>右上角圆括号表示第几个训练样本</p><p>右下角表示特征索引</p><p><img src="assets/1616728252104.png" alt="1616728252104"></p><p>这是一个简单的两层神经网络的计算过程，第一层得到的概率 $a^{[1]}$ ，又被输入到下一层，再次进行学习，第二层得到的概率为最终输出 $a^{[2]}$，并进一步计算 loss</p><hr><h4 id="3-2-神经网络表示"><a href="#3-2-神经网络表示" class="headerlink" title="3.2. 神经网络表示"></a>3.2. 神经网络表示</h4><p>下图为双层神经网络，输入层不算在内。 </p><p><img src="assets/1616728799846.png" alt="1616728799846"></p><p>左边一层称为输入层，第二层称为隐藏层，第三层只有一个节点，称为输出层。在训练时，隐藏层节点的值，不知道。</p><p>$X$ 或 $a^{[0]}$表示输入。第二层为 $a^{[1]}$ 是一个四维向量。输出为 $a^{[2]}$。</p><p>隐藏层有两个相关的参数 W 和 b，W 是（4，3）的矩阵，有三个输入，b 是（4，1）的矩阵。</p><p>输出层有两个相关的参数 W 和 b，W 是（1，4）的矩阵，有四个隐藏层单元，b 是（1，4）的矩阵。</p><hr><h4 id="3-3-计算神经网络的输出"><a href="#3-3-计算神经网络的输出" class="headerlink" title="3.3. 计算神经网络的输出"></a>3.3. 计算神经网络的输出</h4><p><img src="assets/1616729421965.png" alt="1616729421965"></p><p>这个圆圈代表了回归计算的两个步骤，首先按照步骤计算出z，然后在第二步计算激活函数。神经网络就是不断重复这个过程</p><p><img src="assets/1616729548101.png" alt="1616729548101"></p><p><strong>第一隐藏层的第一个</strong>节点先计算</p><script type="math/tex; mode=display">\begin{equation} z_{1}^{[1]}=\omega_{1}^{[1]} x+b_{1}^{[1]} \end{equation}</script><p>再计算</p><script type="math/tex; mode=display">\begin{equation} a_{1}^{[1]}=\sigma(z_{1}^{[1]}) \end{equation}</script><p>上标表示层数，下标表示节点索引（1-4）</p><p><img src="assets/1616729708292.png" alt="1616729708292"></p><p><strong>第一隐藏层的第二个</strong>节点先计算</p><script type="math/tex; mode=display">\begin{equation} z_{2}^{[1]}=\omega_{2}^{[1]} x+b_{2}^{[1]} \end{equation}</script><p>再计算</p><script type="math/tex; mode=display">\begin{equation} a_{2}^{[1]}=\sigma(z_{2}^{[1]}) \end{equation}</script><p>如下图</p><p><img src="assets/1616729799515.png" alt="1616729799515"></p><script type="math/tex; mode=display">\begin{split}z_{1}^{[1]}=\omega_{1}^{[1]T} x+b_{1}^{[1]}, a_{1}^{[1]}=\sigma(z_{1}^{[1]}) \\z_{2}^{[1]}=\omega_{2}^{[1]T} x+b_{2}^{[1]}, a_{2}^{[1]}=\sigma(z_{2}^{[1]}) \\z_{3}^{[1]}=\omega_{3}^{[1]T} x+b_{3}^{[1]}, a_{3}^{[1]}=\sigma(z_{3}^{[1]}) \\z_{4}^{[1]}=\omega_{4}^{[1]T} x+b_{4}^{[1]}, a_{4}^{[1]}=\sigma(z_{4}^{[1]}) \\\end{split}</script><p>矩阵化</p><p><img src="assets/1616731945222.png" alt="1616731945222"></p><p>上述输出为 $z^{[1]}$ 第一层的输出向量</p><p>给定输入 x</p><script type="math/tex; mode=display">\begin{split}z^{[1]}&=W^{[1]} x+b^{[1]} \\a^{[1]}&=\sigma(z^{[1]}) \\\end{split}</script><p>(4,1) = (4,3) * (3,1) + (4,1)               W 是四个不同的节点，对三个输入的权重</p><p>(4,1) = (4,1)</p><script type="math/tex; mode=display">\begin{split}z^{[2]}&=W^{[2]} a^{[1]}+b^{[2]} \\a^{[2]}&=\sigma(z^{[2]}) \end{split}</script><p>(1,1) = (1,4) * (4,1) + (1,1)</p><p>(1,1) = (1,1)</p><hr><h4 id="3-4-多个例子中的向量化"><a href="#3-4-多个例子中的向量化" class="headerlink" title="3.4. 多个例子中的向量化"></a>3.4. 多个例子中的向量化</h4><p> 样本的循环正向反向，权重是同一套。m个样本</p><p><img src="assets/1616732735832.png" alt="1616732735832"></p><p>  全部变成矩阵运算。</p><p><img src="assets/equation-1617340426834.svg" alt="[公式]"></p><p><img src="assets/equation-1617340433434.svg" alt="[公式]"></p><p><img src="assets/equation-1617340436976.svg" alt="[公式]"></p><hr><h4 id="3-5-向量化实现的解释"><a href="#3-5-向量化实现的解释" class="headerlink" title="3.5. 向量化实现的解释"></a>3.5. 向量化实现的解释</h4><p> 以样本数目直接扩展为矩阵</p><p><img src="assets/equation-1617340602054.svg" alt="[公式]"></p><p><img src="assets/equation-1617340606506.svg" alt="[公式]"></p><p><img src="assets/equation-1617340610258.svg" alt="[公式]"></p><p><img src="assets/equation-1617340684960.svg" alt="[公式]"></p><hr><h4 id="3-6-激活函数"><a href="#3-6-激活函数" class="headerlink" title="3.6. 激活函数"></a>3.6. 激活函数</h4><p><img src="assets/image-20220325173040770.png" alt="image-20220325173040770"></p><p><img src="assets/image-20220325173054231.png" alt="image-20220325173054231"></p><p>tanh 函数比 sigmoid 函数激活非线性效果好一些，因为值介于-1和1之间，激活函数的均值为 0。类似数据中心化的效果。</p><p>但是 tanh 一般<strong>不在输出层使用</strong>，因为有时输出为概率，概率在 0 - 1 之间。如果做二分类问题，可以试着用 sigmoid 函数。</p><p>tanh 和 sigmoid 在 z 很大或很小时，函数的斜率很接近 0，会拖慢梯度下降。</p><p><img src="assets/image-20220325173244818.png" alt="image-20220325173244818"></p><p>relu 在 z 为正数时，导数为 1，负数时为 0。</p><p>sigmoid 二元分类用，其余不用</p><p>tanh 可以替代sigmoid</p><p>relu  最常用</p><p>leaky relu</p><p><img src="assets/image-20220325173254167.png" alt="image-20220325173254167"></p><p>Relu 的输入值为负的时候，输出始终为0，其一阶导数也始终为0，这样会导致神经元不能更新参数，也就是神经元不学习了，这种现象叫做“Dead Neuron”。<strong>失活</strong>。为了解决 Relu 函数这个缺点，在 Relu 函数的负半区间引入一个泄露（Leaky）值。</p><p>实际选择激活函数可以在交叉验证集上做个小实验。</p><p><img src="assets/image-20220325173301855.png" alt="image-20220325173301855"></p><p><img src="assets/image-20220325173312749.png" alt="image-20220325173312749"></p><blockquote><p>激活函数（Activation Function）是一种添加到人工神经网络中的函数，旨在帮助网络学习数据中的复杂模式。类似于人类大脑中基于神经元的模型，激活函数最终决定了要发射给下一个神经元的内容。</p></blockquote><hr><h4 id="3-7-为什么需要非线性激活函数？"><a href="#3-7-为什么需要非线性激活函数？" class="headerlink" title="3.7. 为什么需要非线性激活函数？"></a>3.7. 为什么需要非线性激活函数？</h4><p>如果没有激活函数，就只是一个线性组合。</p><hr><h4 id="3-8-激活函数的导数"><a href="#3-8-激活函数的导数" class="headerlink" title="3.8. 激活函数的导数"></a>3.8. 激活函数的导数</h4><p><strong>sigmoid 函数</strong></p><p><img src="assets/image-20210327213042173.png" alt="image-20210327213042173"></p><script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}</script><p>求导</p><script type="math/tex; mode=display">g^{\prime}(z) = \frac{d}{d z} g(z) = g(z)(1-g(z))</script><p>z 特别大 g(z) = 1 梯度为0</p><p>z 特别小 g(z) = 0 梯度为0</p><p>z = 0    g(z) = 0.5  梯度为0.25</p><p><strong>tanh 函数</strong></p><p><img src="assets/image-20210327213229741.png" alt="image-20210327213229741"></p><script type="math/tex; mode=display">g(z) = \frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}</script><p>求导</p><script type="math/tex; mode=display">g^{\prime}(z) = \frac{d}{d z} g(z) = 1-g(z)^2</script><p>z 特别大 g(z) = 1  梯度为0</p><p>z 特别小 g(z) = -1 梯度为0</p><p>z = 0       g(z) = 0  梯度为1</p><p><strong>ReLU函数</strong></p><p><img src="assets/image-20210327213340105.png" alt="image-20210327213340105"></p><script type="math/tex; mode=display">g(z) = max(0, z)</script><p>求导</p><script type="math/tex; mode=display">g^{\prime}(z)=\left\{\begin{array}{ll}0 & \text { if } z<0 \\1 & \text { if } z \geqslant 0\end{array}\right.</script><p><strong>Leaky ReLU函数</strong></p><p><img src="assets/image-20210327213540069.png" alt="image-20210327213540069"></p><script type="math/tex; mode=display">g(z) = max(0.01z, z)</script><p>求导</p><script type="math/tex; mode=display">g^{\prime}(z)=\left\{\begin{array}{ll}0.01 & \text { if } z<0 \\1 & \text { if } z \geqslant 0\end{array}\right.</script><hr><h4 id="3-9-神经网络的梯度下降法"><a href="#3-9-神经网络的梯度下降法" class="headerlink" title="3.9. 神经网络的梯度下降法"></a>3.9. 神经网络的梯度下降法</h4><p>待训练参数：$w^{[1]}, b^{[1]}, w^{[2]}, b^{[2]}$，    有隐藏单元： $n^{[0]}, n^{[1]}, n^{[2]}$</p><p>矩阵 $w^{[1]}$ 维度为 $(n^{[1]}, n^{[0]})$，$b^{[1]}$ 就是一个 $(n^{[1]},1)$ 维的向量，$w^{[2]}$ 维度为 $(n^{[2]}, n^{[1]})$，$b^{[2]}$ 就是一个 $(n^{[2]},1)$ 维的向量。</p><p>cost 函数为：</p><script type="math/tex; mode=display">J\left(\omega^{[1]}, b^{(1)}, \omega^{[2]}, b^{[2]}\right)=\frac{1}{m} \sum_{i=1}^{n}\mathcal{L}(\hat{y}, y)</script><p>其中 $\hat{y}=a^{[2]}$ 是网络输出。</p><p>梯度下降过程：</p><p>​    重复：   $d\omega ^{[1]}=\frac{\partial J}{\partial \omega^{[1]}}$，$db^{[1]}=\frac{\partial J}{\partial b^{[1]}}$</p><p>​                   $\omega^{[1]}=\omega^{[1]}-\alpha d\omega^{[1]}$，$b^{[1]}=b^{[1]}-\alpha db^{[1]}$，$\omega^{[2]}=\omega^{[2]}-\alpha d\omega^{[2]}$，$b^{[2]}=b^{[2]}-\alpha db^{[2]}$</p><p><strong>正向传播</strong></p><script type="math/tex; mode=display">\begin{split}Z^{[1]}&=W^{[1]} x+b^{[1]} \\A^{[1]}&=g^{[1]}(Z^{[1]}) \\Z^{[2]}&=W^{[2]} A^{[1]}+b^{[2]} \\A^{[2]}&=g^{[2]}(Z^{[2]}) \end{split}</script><p><strong>反向传播</strong></p><script type="math/tex; mode=display">\begin{split}dZ^{[2]} &= A^{[2]} - Y_{truth}\\dW^{[2]} &= \frac{1}{m}dZ^{[2]}A^{[1]T}\\db^{[2]} &= \frac{1}{m}np.sum(dZ^{[2]}, axis=1, keepdims=True)\\dZ^{[1]} &= W^{[2]T}dZ^{[2]} * g^{[1]\prime}(Z^{[1]})\\dW^{[1]} &= \frac{1}{m}dZ^{[1]}X^{T}\\db^{[1]} &= \frac{1}{m}np.sum(dZ^{[1]}, axis=1, keepdims=True)\\\end{split}</script><p>第一行推导过程公式见<a href="#dz">dZ</a> ，这里假设使用sigmoid激活函数，直接转化为最终式子，所以没有 $g^{[2]\prime}$。</p><p>第二行直接求导结果为系数，$\frac{1}{m}$ 因为是直接对cost function求导，所以要除以m</p><p>第三行 <code>axis=1</code> 水平相加求和，<code>keepdims</code> 防止 python 输出秩为 1 的数组$(n^{[2]},)    $       $(n^{[2]},1)$</p><p>第四行 $g^{[1]\prime}$是隐藏层的激活函数的导数。*为逐个元素相乘，点乘。$W^{[2]T}dZ^{[2]}$ 的size $(n^{[1]},m)$</p><script type="math/tex; mode=display">dZ^{[1]} = \frac{\part \mathcal{L}}{\part Z^{[1]}}=\frac{\part \mathcal{L}}{\part Z^{[2]}}\frac{\part Z^{[2]}}{\part A^{[1]}} \frac{\part A^{[1]}}{\part Z^{[1]}}\\=W^{[2]T}dZ^{[2]} *g^{[1]\prime}(Z^{[1]})</script><p><del>为什么是 $dZ^{[2]}$ ???????????????????????????????????????????</del> <span id="dz"></span></p><p>答案的$W^{[2]T}dZ^{[2]}$ 与上边偏导对应的位置刚好相反</p><p>第五行 $db^{[1]}$ 的size $(n^{[1]},1)$</p><p><strong>上边的公式解释见下节</strong></p><hr><h4 id="3-10-直观理解反向传播"><a href="#3-10-直观理解反向传播" class="headerlink" title="3.10. 直观理解反向传播"></a>3.10. 直观理解反向传播</h4><p>任意变量与其导数维度相同</p><script type="math/tex; mode=display">\begin{split}dz^{[2]} &= a^{[2]} - y\\dW^{[2]} &= \frac{1}{m}dz^{[2]}a^{[1]T}\\db^{[2]} &= dz^{[2]}\\dz^{[1]} &= W^{[2]T}dz^{[2]} * g^{[1]\prime}(z^{[1]})\\dW^{[1]} &= \frac{1}{m}dz^{[1]}x^{T}\\db^{[1]} &= dz^{[1]}\\\end{split}</script><p>向量化</p><script type="math/tex; mode=display">\begin{split}dZ^{[2]} &= A^{[2]} - Y_{truth}\\dW^{[2]} &= \frac{1}{m}dZ^{[2]}A^{[1]T}\\db^{[2]} &= \frac{1}{m}np.sum(dZ^{[2]}, axis=1, keepdims=True)\\dZ^{[1]} &= W^{[2]T}dZ^{[2]} * g^{[1]\prime}(Z^{[1]})\\dW^{[1]} &= \frac{1}{m}dZ^{[1]}X^{T}\\db^{[1]} &= \frac{1}{m}np.sum(dZ^{[1]}, axis=1, keepdims=True)\\\end{split}</script><hr><h4 id="3-11-随机初始化"><a href="#3-11-随机初始化" class="headerlink" title="3.11. 随机初始化"></a>3.11. 随机初始化</h4><p>权重不能初始化为0。偏置可以初始化为0。若初始化为 0 输入不同的样本，计算过程相同，得到相同的结果和梯度。</p><p>神经元对称 symmetric</p><p><img src="assets/image-20210327232838851.png" alt="image-20210327232838851"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">W1 = np.random.randn((<span class="number">2</span>, <span class="number">2</span>)) * <span class="number">0.01</span> <span class="comment">#</span></span><br><span class="line">b1 = np.zeros((<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">W2 = np.random.randn((<span class="number">1</span>, <span class="number">2</span>)) * <span class="number">0.01</span></span><br><span class="line">b2 = np.zeros((<span class="number">2</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>w 初始化为很小的数。b 不受影响。</p><p>一般初始化为较小的值，如果初始化较大，使用tanh和sigmoid激活函数时，梯度接近 0。</p><p>如果没有tanh和sigmoid激活函数时，初始化大小无所谓</p><p>如果网络比较深选用0.01外的初始化倍数</p><hr><h3 id="第四周-深层神经网络"><a href="#第四周-深层神经网络" class="headerlink" title="第四周 深层神经网络"></a>第四周 深层神经网络</h3><h4 id="4-1-深层神经网络"><a href="#4-1-深层神经网络" class="headerlink" title="4.1 深层神经网络"></a>4.1 深层神经网络</h4><p><img src="assets/1616917392656.png" alt="1616917392656"></p><p><img src="assets/1616920793507.png" alt="1616920793507"></p><p>L 表示神经网络的层数</p><p>$n^{[L]}$ 表示L层的隐藏单元的数目</p><p>$n^{[1]} = 5$，$n^{[2]} = 5$，$n^{[3]} = 3$，输入层 $n^{[0]} = 3$</p><hr><h4 id="4-2-深层网络中的前向传播"><a href="#4-2-深层网络中的前向传播" class="headerlink" title="4.2 深层网络中的前向传播"></a>4.2 深层网络中的前向传播</h4><p>四层公式如下：</p><script type="math/tex; mode=display">\begin{split}Z^{[1]}&=W^{[1]} x+b^{[1]} \\a^{[1]}&=g^{[1]}(Z^{[1]}) \\Z^{[2]}&=W^{[2]} a^{[1]}+b^{[2]} \\a^{[2]}&=g^{[2]}(Z^{[2]}) \\Z^{[3]}&=W^{[3]} a^{[2]}+b^{[3]} \\a^{[3]}&=g^{[3]}(Z^{[3]}) \\Z^{[4]}&=W^{[4]} a^{[3]}+b^{[4]} \\a^{[4]}&=g^{[4]}(Z^{[4]}) \\\end{split}</script><p>通用公式如下：</p><script type="math/tex; mode=display">\begin{split}Z^{[L]} &= W^{[L]}a^{[L-1]}+b^{[L-1]}\\a^{[L]} &= g^{[L]}(Z^{[L]}) \\\end{split}</script><hr><h4 id="4-3-核对矩阵的维数"><a href="#4-3-核对矩阵的维数" class="headerlink" title="4.3 核对矩阵的维数"></a>4.3 核对矩阵的维数</h4><p>检查网络的bug，按照算法流程逐行检查矩阵维度。</p><p>归纳演绎法：从特殊到一般；从一个到整体；从一个实数到一组向量；从一组向量到一个矩阵。</p><p><img src="assets/1616926229300.png" alt="1616926229300"></p><p><strong>单个样本</strong>的维度变化：</p><p>$Z^{[1]}=W^{[1]} A^{[0]}+b^{[1]}$ ，$n^{[1]} = 3$，W的size为 （3，2）； $A^{[0]}=X$的size为（2，1）；b的size为（3，1）；Z的size为（3，1）</p><p>$A^{[1]} = g^{[1]}(Z^{[1]})$，Z的size为 （3，1）； A的size为（3，1）</p><p>$Z^{[2]}=W^{[2]} A^{[1]}+b^{[2]}$ ，$n^{[1]} = 3$，W的size为 （5，3）； X的size为（3，1）；b的size为（3，1）；Z的size为（5，1）</p><p>$A^{[2]} = g^{[2]}(Z^{[2]})$，Z的size为 （5，1）； A的size为（5，1）</p><p>$Z^{[3]}=W^{[3]} A^{[2]}+b^{[3]}$ ，$n^{[1]} = 3$，W的size为 （4，5）； X的size为（5，1）；b的size为（4，1）；Z的size为（4，1）</p><p>$A^{[3]} = g^{[3]}(Z^{[3]})$，Z的size为 （4，1）； A的size为（4，1）</p><p>$Z^{[4]}=W^{[4]} A^{[3]}+b^{[4]}$ ，$n^{[1]} = 3$，W的size为 （2，4）； X的size为（4，1）；b的size为（2，1）；Z的size为（2，1）</p><p>$A^{[4]} = g^{[4]}(Z^{[4]})$，Z的size为 （2，1）； A的size为（2，1）</p><p>$Z^{[5]}=W^{[5]} A^{[4]}+b^{[5]}$ ，$n^{[1]} = 3$，W的size为 （1，2）； X的size为（2，1）；b的size为（1，1）；Z的size为（1，1）</p><p>$A^{[5]} = g^{[5]}(Z^{[5]})$，Z的size为 （1，1）； A的size为（1，1）</p><p><strong>使用下边两个公式检查</strong></p><p>W/dW的size为（$n^{[L]},n^{[L-1]}$），b/db的size为（$n^{[L]},1$）</p><p>z/dz的size为（$n^{[L]},1$），x/dx的size为（$n^{[L]},1$）</p><hr><p><img src="assets/1616926229300.png" alt="1616926229300"></p><p><strong>多m个样本</strong>的维度变化，即经过向量化后：</p><p>$Z^{[1]}=W^{[1]} A^{[0]}+b^{[1]}$ ，$n^{[1]} = 3$，W的size为 （3，2）； $A^{[0]}=X$的size为（2，m）；b的size为（3，m）；Z的size为（3，m）</p><p>$A^{[1]} = g^{[1]}(Z^{[1]})$，Z的size为 （3，m）； A的size为（3，m）</p><p>$Z^{[2]}=W^{[2]} A^{[1]}+b^{[2]}$ ，$n^{[1]} = 3$，W的size为 （5，3）； X的size为（3，m）；b的size为（3，m）；Z的size为（5，m）</p><p>$A^{[2]} = g^{[2]}(Z^{[2]})$，Z的size为 （5，m）； A的size为（5，m）</p><p>$Z^{[3]}=W^{[3]} A^{[2]}+b^{[3]}$ ，$n^{[1]} = 3$，W的size为 （4，5）； X的size为（5，m）；b的size为（4，m）；Z的size为（4，m）</p><p>$A^{[3]} = g^{[3]}(Z^{[3]})$，Z的size为 （4，m）； A的size为（4，m）</p><p>$Z^{[4]}=W^{[4]} A^{[3]}+b^{[4]}$ ，$n^{[1]} = 3$，W的size为 （2，4）； X的size为（4，m）；b的size为（2，m）；Z的size为（2，m）</p><p>$A^{[4]} = g^{[4]}(Z^{[4]})$，Z的size为 （2，m）； A的size为（2，m）</p><p>$Z^{[5]}=W^{[5]} A^{[4]}+b^{[5]}$ ，$n^{[1]} = 3$，W的size为 （1，2）； X的size为（2，m）；b的size为（1，m）；Z的size为（1，m）</p><p>$A^{[5]} = g^{[5]}(Z^{[5]})$，Z的size为 （1，m）； A的size为（1，m）</p><p><strong>使用下边两个公式检查</strong></p><p>W/dW的size为（$n^{[L]},n^{[L-1]}$），b/db的size为（$n^{[L]},m$），其中b使用python广播机制，每列相等</p><p>Z/dZ的size为（$n^{[L]},m$），X/dX的size为（$n^{[L]},m$）</p><hr><h4 id="4-4-为什么使用深层表示"><a href="#4-4-为什么使用深层表示" class="headerlink" title="4.4 为什么使用深层表示"></a>4.4 为什么使用深层表示</h4><p><img src="assets/1616927679151.png" alt="1616927679151"></p><p>网络第一层，当成一个边缘检测器/特征检测器。隐藏单元就是下边的20ge小方块，第一个小方块会找垂直方向的边缘线，第19个会找水平方向的边缘线。找输入照片的各个边缘。</p><p>第二层，把被检测到的边缘组合成面部的不同部分。比如：一个神经元会去找眼睛的部分，另一个神经元会去找鼻子的部分 。然后把这许多的边缘结合在一起，就可以开始检测人脸的不同部分。</p><p>第三层，把这些部分放在一起，就可以识别或检测不同的人脸。</p><p><strong>语音识别实例：</strong></p><p>第一层，探测比较低层次的音频波形的一些特征（低频、高频、音调）</p><p>第二层，然后把特征组合成一个单元，去探测声音的基本单元（音位）</p><p>第三层，组合音位，识别单词</p><p>第四层，组合单词，识别词组/语句</p><p><strong>解释</strong></p><p>前几层，学习低层次的简单特征，可以理解为探测简单的函数，比如边缘。后几层，把简单的特征结合在一起，就能学习更多复杂的函数。</p><p><strong>circuit theory 电路理论</strong></p><p>浅层网络需要指数级的隐藏单元才能像一些函数 与或非门一样计算。</p><p>可以先用浅层做实验，然后逐步加深。</p><hr><h4 id="4-5-搭建深层神经网络块"><a href="#4-5-搭建深层神经网络块" class="headerlink" title="4.5 搭建深层神经网络块"></a>4.5 搭建深层神经网络块</h4><p><img src="assets/v2-6a0a7d63578db464b6fc539ef7e883d6_b.jpg" alt="img"></p><p>第一行是正向传播</p><p>第二行是反向传播 （需要缓存正向传播过程中 z 的值来计算梯度）</p><p><img src="assets/v2-f8839ba29ecee2ecddee04bbe0780825_b.jpg" alt="img"></p><p>根据反向传播过程中每层计算出的梯度，更新参数</p><hr><h4 id="4-6-前向和反向传播"><a href="#4-6-前向和反向传播" class="headerlink" title="4.6 前向和反向传播"></a>4.6 前向和反向传播</h4><p><strong>正向传播</strong></p><p>输入 $a^{[L-1]}$</p><p>输出 $a^{[L]}$，缓存 $cache(z^{[L]})$</p><p>循环：</p><script type="math/tex; mode=display">\begin{split}Z^{[L]}&=W^{[L]} A^{[L-1]}+b^{[L]} \\a^{[L]}&=g^{[L]}(Z^{[L]}) \end{split}</script><p><strong>反向传播</strong></p><p>输入 $da^{[L]}$</p><p>提取缓存 $cache(z^{[L]})$</p><p>输出 $da^{[L-1]}，dW^{[L-1]}，db^{[L-1]}$       </p><p>循环：</p><script type="math/tex; mode=display">\begin{split}dz^{[L]}&=da^{[L]} * g^{[L]\prime}(z^{[L]}) \\dW^{[L]}&=dz^{[L]}a^{[L-1]T    } \\db^{[L]}&=dz^{[L]} \\da^{[L-1]}&=W^{[L]T}dz^{[L]}\\dz^{[L]}&=W^{[L+1]T}dz^{[L+1]} * g^{[L]\prime}(z^{[L]}) \\\end{split}</script><p>这里的导数是损失函数 L 对参数求导，第五行是dz的另一种表示，*表示逐点相乘。</p><script type="math/tex; mode=display">\begin{split}dZ^{[L]}&=dA^{[L]} * g^{[L]\prime}(Z^{[L]}) \\dW^{[L]}&=\frac{1}{m}dZ^{[L]}A^{[L-1]T    } \\db^{[L]}&=\frac{1}{m}np.sum(dZ^{[L]},axis=1,keepdims=True) \\dA^{[L-1]}&=W^{[L]T}dz^{[L]}\end{split}</script><p>上式为<strong>向量化</strong>后，其中 $dA^{[L]}$ 是矩阵</p><hr><h4 id="4-7-参数-VS-超参数"><a href="#4-7-参数-VS-超参数" class="headerlink" title="4.7 参数 VS 超参数"></a>4.7 参数 VS 超参数</h4><p>参数：$W^{[1]},b^{[1]},W^{[2]},b^{[2]},W^{[3]},b^{[3]},\dots$</p><p>超参数： 学习率$\alpha$，迭代次数，隐藏层数$L$，隐藏单元$n^{[1]},n^{[2]},\dots$，激活函数</p><p>​              momentum，mini batch_size，正则化参数</p><p><strong>超参数确定控制了参数的值</strong>。</p><p>必须通过训练/交叉验证，试试各种参数。看那个loss下降又小又快</p><hr><h4 id="4-8-这和大脑有什么关系？"><a href="#4-8-这和大脑有什么关系？" class="headerlink" title="4.8 这和大脑有什么关系？"></a>4.8 这和大脑有什么关系？</h4><hr><h3 id="第五周-人工智能行业大师访谈"><a href="#第五周-人工智能行业大师访谈" class="headerlink" title="第五周 人工智能行业大师访谈"></a>第五周 人工智能行业大师访谈</h3><h4 id="5-1-吴恩达采访-Geoffrey-Hinton"><a href="#5-1-吴恩达采访-Geoffrey-Hinton" class="headerlink" title="5.1. 吴恩达采访 Geoffrey Hinton"></a>5.1. 吴恩达采访 Geoffrey Hinton</h4><p>Geoffrey Hinton                          推动反向传播/波尔兹曼机</p><p>Yann LeCun（Hinton的学生）     </p><p>Yoshua Bengio                            推动RNN</p><p>AlexNet</p><p>全息图 hologram</p><p>Relu 等同于许多 logistics 单元 </p><p>变分法</p><p>建模型：先记录测量， 对其应用非线性变化，直到状态向量变成表达式。这项活动变得线性。</p><p>不能假设线性，应该找一个从观察转换到<strong>潜在变量</strong>（有因果能力）的转换，线性操作。比如<strong>潜在变量</strong>的矩阵乘积，就是如此。</p><hr><h4 id="5-2-吴恩达采访-Pieter-Abbeel"><a href="#5-2-吴恩达采访-Pieter-Abbeel" class="headerlink" title="5.2. 吴恩达采访 Pieter Abbeel"></a>5.2. 吴恩达采访 Pieter Abbeel</h4><p>深度强化学习</p><p>概率图模型</p><hr><h4 id="5-3-吴恩达采访-Ian-Goodfellow"><a href="#5-3-吴恩达采访-Ian-Goodfellow" class="headerlink" title="5.3. 吴恩达采访 Ian Goodfellow"></a>5.3. 吴恩达采访 Ian Goodfellow</h4><p> GAN</p><hr>]]></content>
      
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cycle4Completion</title>
      <link href="/2022/03/03/P_C_Cycle4Completion/"/>
      <url>/2022/03/03/P_C_Cycle4Completion/</url>
      
        <content type="html"><![CDATA[<p>CVPR2021：  Unpaired Point Cloud Completion using Cycle Transformation with Missing Region Coding</p><hr><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>In this paper, we present a novel unpaired point cloud completion network, named Cycle4Completion, to infer the complete geometries from a partial 3D object.      在本文中，我们提出了一种新颖的不成对的点云完成网络，称为 <code>Cycle4Completion</code>，可以从部分3D对象推断出完整的几何形状。<br><span id="more"></span><br>Previous unpaired completion methods merely focus on the learning of geometric correspondence from incomplete shapes to complete shapes, and ignore the learning in the reverse direction, which makes them suffer from low completion accuracy due to the limited 3D shape understanding ability. 先前的不成对完成方法仅专注于<strong>从不完整形状到完整</strong>形状的几何对应关系的学习，而<strong>忽略了相反方向</strong>的学习，这使得它们由于3D形状理解能力有限而遭受较低的完成精度。</p><p>To address this problem, we propose two simultaneous <strong>cycle transformations</strong> between the latent spaces of complete shapes and incomplete ones. 为了解决这个问题，我们提出了完全形状和不完全形状的潜在空间之间的两个同时<strong>循环变换</strong>。</p><p>Specifically, the first cycle transforms shapes from incomplete domain to complete domain, and then projects them back to the incomplete domain. This process learns the geometric characteristic of complete shapes, and maintains the shape consistency between the complete prediction and the incomplete input. 具体来说，第一个循环将形状从不完整域转换为完整域，然后将其投影回不完整域。此过程了解完整形状的几何特征，并保持完整预测和不完整输入之间的形状一致性。 </p><p>Similarly, the inverse cycle transformation starts from complete domain to incomplete domain, and goes back to complete domain to learn the characteristic of incomplete shapes. 类似地，逆循环变换从完整域开始到不完整域，然后返回到完整域以学习不完整形状的特征。 </p><p>We experimentally show that our model with the learned bidirectional geometry correspondence outperforms state-of-the-art unpaired completion methods. 我们通过实验证明，具有学习到的双向几何对应关系的模型优于最新的不成对完成方法。</p><hr><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>Point clouds, as a popular 3D representation, can be easily produced by 3D scanning devices and depth cameras. However, due to the limitations of the view angles of camera/scanning devices and self-occlusion, raw point clouds are often sparse, noisy and partial, which usually require shape completion before being analyzed in further applications such as shape classification [25, 17], retrieval [14, 8, 15], semantic/instance segmentation [22, 35]. Although the recent data-driven supervised completion methods [31, 40, 37, 39, 19, 21] have achieved impressive performance, they heavily rely on the paired training data, which consists of incomplete shapes and their corresponding complete ground truth. In real-world applications, however,<br>such high quality and large-scale paired training dataset is not easy to access, which makes it hard to directly train a supervised completion network.</p><p>点云作为一种流行的3D表示形式，可以通过3D扫描设备和深度相机轻松生成。 但是，由于相机/扫描设备的视角和自闭塞的限制，原始点云通常稀疏，嘈杂且局部，通常需要在完成其他应用（例如形状分类）之前对形状进行完善[25，17 ]，检索[14、8、15]，语义/实例分割[22、35]。 尽管最近的数据驱动的监督完成方法[31、40、37、39、19、21]取得了骄人的成绩，但它们<strong>严重依赖配对的训练数据</strong>，该训练数据由不完整的形状及其相应的完整的G.T. 组成。但是，在实际应用中，如此高质量和大规模的成对训练数据集并不容易访问，这使得直接训练受监督的完成网络变得困难。</p><p>A promising but challenging solution to this problem is to learn a completion network in an unpaired way, where the common practice is to establish the shape correspondence between the incomplete shapes and complete ones from the unpaired training data without requiring the incomplete and complete correspondence. The latest work like Pcl2Pcl [3]  introduced an adversarial framework to merge the geometric gap between the complete shape distribution and incomplete one in the latent representation space. Although many efforts have been made to learn the geometric correspondence from incomplete shapes to complete ones, previous methods ignore the inverse correspondence from complete<br>shapes to incomplete ones, which leads to low completion accuracy due to the limited 3D shape understanding ability. </p><p>解决此问题的一个有希望但具有挑战性的解决方案是以不成对的方式学习补全网络，通常的做法是从不成对的训练数据中建立<strong>不完整</strong>的形状和<strong>完整</strong>的形状之间的<strong>形状对应关系</strong>，而无需不完整和完整的对应关系。像Pcl2Pcl[3] 这样的最新作品引入了一种对抗性框架，用于合并潜在表示空间中完整形状分布和不完整形状之间的几何间隙。尽管已经进行了许多努力来学习从不完整形状到完整形状的几何对应关系，但是先前的方法忽略了从完整形状到不完整形状的逆对应关系，这由于有限的3D形状理解能力而导致较低的完成精度。</p><p>To address this problem, we propose a novel unpaired point cloud completion network, named Cycle4Completion, to establish the geometric correspondence between incomplete and complete shapes in both directions. We achieve this by designing two cycle transformations, i.e. the incomplete cycle transformation (incomplete-cycle) and the complete cycle transformation (complete-cycle), as shown in Figure 1. The incomplete-cycle in Figure 1(a) learns the mapping from the incomplete domain to the complete one, which is then projected back to the incomplete domain. On the other hand, the complete-cycle in Figure 1(b) provides the completion knowledge on the inverse direction with incomplete input, which can be used to further enhance the incompletion quality for incomplete-cycle.</p><p>为了解决这个问题，我们提出了一个新的不成对的点云完成网络，称为Cycle4Completion，以建立<strong>两个方向</strong>上不完整和完整形状之间的几何对应关系。 我们通过设计两个周期转换来实现此目的，即不完整周期转换（incomplete-cycle）和完整周期转换（complete-cycle），如图1所示。图1（a）中的不完整周期从中学习映射 将不完整的域转换为完整的域，然后将其投影回不完整的域。 另一方面，图1（b）中的完整循环提供了具有不完整输入的反方向的完整知识，可用于进一步提高不完整循环的不完整质量。</p><p><img src="assets/1616750292108.png" alt="1616750292108"></p><p><strong>Fig. 1.a</strong> 循环变换的图示，它由两个逆循环组成，如（a）和（b）所示。 循环变换通过学习从互补形状生成完整或不完整的形状，从而使网络了解3D形状。</p><p><img src="assets/1616750302228.png" alt="1616750302228"></p><p><strong>Fig. 1.b</strong> 循环变换的图示，它由两个逆循环组成，如（a）和（b）所示。 循环变换通过学习从互补形状生成完整或不完整的形状，从而使网络了解3D形状。</p><p><img src="assets/1616750664685.png" alt="1616750664685"></p><p><strong>图2.a</strong> 目标混乱的问题。 基于神经网络的变换FX可以学习将多个不完整的输入（A1，A2，A3）投影到一个完整的目标（A）中，但是其逆变换FY无法学习将一个完整的输入投影到多个不完整的目标中。</p><p>但是，如图2（a）所示，直接在潜在空间中应用循环变换会遇到一个新问题，我们将其称为<strong>目标混淆问题</strong>。 当建立从多个不完整形状（例如A1，A2和A3）到一个完整形状（例如A）的形状对应关系时，会出现此问题。 这是因为一个循环需要网络根据完整的输入来预测不完整的形状，并且相应的转换网络FY无法仅通过深层神经网络将一个完整的输入完全映射到多个不同的不完整的目标中。 为了解决这个问题，我们提出了可学习的缺失区域编码（MRC），将不完整的形状转换为完整的形状，如图2（b）所示。</p><p><img src="assets/1616750680725.png" alt="1616750680725"></p><p><strong>图2.b</strong> 缺失区域编码的解决方案。 我们建议使用可学习的代码Z（在上图中表示为Z1，Z2，Z3）来编码缺失区域</p><p>不完整形状的表示可以分解为两部分：一个是其相应完整形状的表示A，另一个是用于编码其缺失区域的代码 Z。 从不完整的形状预测完整形状时，仅考虑表示A，而从完整的形状预测不完整形状时，则考虑表示 A 和编码 Z。 因此，转换网络 FY 将通过学习将一个完整的输入投影到几个不完整的目标来减轻混乱。 取而代之的是，可学习的缺失区域代码Z可以帮助网络澄清哪个不完整形状是当前的转换目标，并缓解目标混乱的问题。 我们的主要贡献概述如下。</p><ul><li>We propose a novel unpaired point cloud completion network, named Cycle4Completion. Compared with previous unpaired completion methods which only consider the single-side correspondence from incomplete shapes to complete ones, Cycle4Completion can enhance the completion performance by establishing the geometric correspondence between complete shapes and incomplete shapes from both directions.我们提出了一种新颖的不成对的点云完成网络，称为Cycle4Completion。与以前的不成对完成方法仅考虑从不完整形状到完整形状的单边对应关系相比，Cycle4Completion可以通过在两个方向上在完整形状和不完整形状之间建立几何对应关系来提高完成性能。</li><li>We propose the partial matching loss and cycle matching loss, and combine them with the cycle transformations to establish the bidirectional geometric correspondence between the complete and incomplete shapes, and maintain the shape consistency throughout the whole transformation process.我们提出了局部匹配损失和循环匹配损失，并将它们与循环变换相结合，以建立完整和不完整形状之间的双向几何对应关系，并在整个变换过程中保持形状一致性。</li><li>We propose the missing region coding to decompose the incomplete shape representation into a representation of its corresponding complete shape, and a missing region code to encode the missing regions of the incomplete shapes, respectively. This solves the target confusion when the network tries to predict multiple incomplete shapes based on a single complete shape. 我们建议使用缺失区域编码将不完整的形状表示分解为对应的完整形状的表示，并提出缺失区域代码分别对不完整形状的缺失区域进行编码。 当网络尝试基于单个完整形状预测多个不完整形状时，这解决了目标混乱。</li></ul><h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h2><p>近年来，3D形状补全已引起越来越多的关注。 先前的补全方法可以大致分为两类，即传统方法和基于深度学习的方法，我们将在下面详细介绍。</p><p><strong>Traditional approaches for 3D shape completion.</strong> </p><p>基于传统几何/统计的方法[30、1、34、27、24、28]利用部分输入上的曲面的几何特征来生成3D形状的缺失区域[30、1、32、34]或利用 大型形状数据库以搜索相似的形状/补丁来填充3D形状的缺失区域[27、20、24、28]。 例如，Hu等人[34] 提出通过定义点云的平滑和去噪特性并在相似区域中全局搜索缺失区域，来利用点云的局部平滑度和非局部自相似性。 另一方面，数据驱动的形状完成方法，如Shen等[28]。 将3D形状的完成过程作为自下而上的零件组装过程进行描述，其中以3D形状存储库为参考来恢复各种高级完整结构。 总之，这些传统的形状完成方法主要基于手工规则来描述缺失区域的特征以及缺失区域与完整形状之间的相似性。 因此，这种方法的泛化能力通常受到限制。 例如，Sung等人[30]提出的方法。 预定义3D形状的语义部分的几类，并使用几何特征（例如部分位置，比例和方向）从形状数据库中查找缺失区域的相似部分。 这种方法通常在形状更复杂的情况下失败，这超出了预定义的语义部分类别或几何特征的描述。相反，基于深度学习的完成方法可以学习更灵活的功能，以根据不完整的输入预测完整的形状。这种方法将在下面的小节中详细介绍。</p><p><strong>Deep learning approaches for 3D shape completion.</strong> </p><p>第二类包括基于神经网络的方法，该方法利用深度学习从输入形状[15、10、9、11、22]中学习表示形式，并使用编码器-解码器框架根据表示来预测完整形状 。 该类别可以根据不同的输入形状形式进一步分类，包括：体积形状完成度[4、6、29] 和点云完成度[40、31、26、18、33]。 我们的 Cycle4Completion 也属于这一类，它完成了由点云表示的 3D 形状。 最近的著名研究，例如 MAPVAE [16]，TopNet [31]和SA-Net [36]在监督点云完成任务上取得了令人印象深刻的结果。</p><p>此外，RL-GAN-Net [26]在对抗训练中引入了强化学习，以进一步改善生成的完整点云的真实性和一致性。 但是，尽管在有监督的点云完成任务上已取得了很大的进步，但此任务在很大程度上取决于配对的训练数据，但是很少有用于不完整的真实世界扫描的配对G.T.。 另一方面，关于未配对点云完成任务的研究很少。 作为一项开创性的工作，AML [29]直接测量了不完整和完整形状的潜在表示之间的最大可能性。 遵循类似的做法，Pcl2Pcl [3]引入了GAN框架来弥合不完整和完整形状之间的语义鸿沟。</p><p>与上述未配对方法相比，我们的Cycle4Completion还通过在潜在空间中从两个方向进行循环变换来建立自监督，这可以为学习不完整形状和完整形状之间的双向几何对应关系提供更好的指导。</p><p><strong>Relationships with GANs.</strong> </p><p>二维域中不成对的样式传输网络CycleGAN，其简单的 cycle-consistency 循环一致性损失通常无法指导生成器推断缺失的形状，因为为不完整的输入设想一致的缺失形状会更加复杂 而不是转移样式。</p><p>因此，我们建议在<strong>潜在空间中</strong>执行循环变换，其中提出了部分和循环匹配损失以保持传递的形状一致性。 考虑到 3D 补全本质上是从 3D 形状到 3D 形状的重建过程，因此从 2D 图像[12、7、13]重建 3D 形状也是一个值得注意的研究方向，与3D补全密切相关。 两项任务之间的区别在于，从 2D 图像进行 3D 重建不需要输入3D信息，而基于 3D 形状的完成任务则需要 3D 形状信息作为输入。</p><hr><h2 id="3-The-Architecture-of-Cycle4Completion"><a href="#3-The-Architecture-of-Cycle4Completion" class="headerlink" title="3. The Architecture of Cycle4Completion"></a>3. The Architecture of Cycle4Completion</h2><h3 id="3-1-Formulation"><a href="#3-1-Formulation" class="headerlink" title="3.1. Formulation"></a>3.1. Formulation</h3><p>如图3（a）所示，令 $\mathcal{P}_{X}=\left\{\mathbf{p}_{i}^{x}\right\} $ 表示不完整形状的点云，而 $\mathcal{P}_{Y}=\left\{\mathbf{p}_{i}^{y}\right\} $ 表示完整的点云。 我们的目标是学习不完整形状的潜在表示 $ {x} $ 与完整形状的潜在表示 ${y}$ 之间的两个映射 $ F_{X} $ 和 $ F_{Y} $。 这些表示分别由点云编码器 $ E_{X}: \mathcal{P}_{X} \rightarrow \mathbf{x} $ 和 $ E_{Y}: \mathcal{P}_{Y} \rightarrow \mathbf{y} $ 生成，它们分别在自动编码器框架下与点云生成器 $G_{X}$ 和 $G_Y$ 一起训练。 另外，引入了两个对抗鉴别器 $D_X$ 和 $D_Y$ 。 $D_X$ 旨在区分 ${\mathbf{x}}$ 和 ${\mathbf{y}_{x}}$，其中 $\mathbf{y}_{x}=F_{Y}(\mathbf{y}) $。  $D_Y$ 旨在区分 ${\mathbf{y}}$ 和 ${\mathbf{x}_{y}}$，其中 $\mathbf{x}_{y}=F_{X}(\mathbf{x}) $。我们将两个函数 $F_X$ 和 $F_Y$ 的复合运算表示为 $F_X F_Y$。</p><p><img src="assets/1617284106275.png" alt="1617284106275"></p><p><strong>Fig. 3(a)</strong> （a）中的整体结构包括（b）中的不完整周期变换以及（c）中的完整周期变换。 两个循环都使用自我重建来学习形状一致性</p><h3 id="3-2-用于学习潜在空间的编码器-解码器"><a href="#3-2-用于学习潜在空间的编码器-解码器" class="headerlink" title="3.2. 用于学习潜在空间的编码器-解码器"></a>3.2. 用于学习潜在空间的编码器-解码器</h3><p>两个自动编码器分别学习不完整和完整形状的潜在表示空间。我们将两个点云 $\mathcal{P}_{1} $ 和 $\mathcal{P}_{2} $ 之间的完整倒角距离（CD）定义为</p><script type="math/tex; mode=display">\begin{equation} \mathcal{L}_{\mathrm{CD}}\left(\mathcal{P}_{1} \leftrightharpoons \mathcal{P}_{2}\right)=\sum_{\mathbf{p}_{i}^{1} \in \mathcal{P}_{1}} \min _{\mathbf{p}_{i}^{2} \in \mathcal{P}_{2}}\left\|\mathbf{p}_{i}^{1}-\mathbf{p}_{i}^{2}\right\|+\sum_{\mathbf{p}_{i}^{2} \in \mathcal{P}_{2}} \min _{\mathbf{D}_{i}^{1} \in \mathcal{P}_{1}}\left\|\mathbf{p}_{i}^{2}-\mathbf{p}_{i}^{1}\right\| . \end{equation} \tag{1}</script><p>用于训练自动编码器框架的重建损耗 $\mathcal{L}_{A E} $ 公式为：</p><script type="math/tex; mode=display">\begin{equation} \mathcal{L}_{A E}=\mathcal{L}_{C D}\left(\mathcal{P}_{X} \leftrightharpoons G_{X}(\mathbf{x})\right)+\mathcal{L}_{C D}\left(\mathcal{P}_{Y} \leftrightharpoons G_{Y}(\mathbf{y})\right) \end{equation}\tag{2}</script><hr><h3 id="3-3-Cycle-Transformation"><a href="#3-3-Cycle-Transformation" class="headerlink" title="3.3. Cycle Transformation"></a>3.3. Cycle Transformation</h3><h4 id="Transformation-with-missing-region-coding"><a href="#Transformation-with-missing-region-coding" class="headerlink" title="Transformation with missing region coding."></a>Transformation with missing region coding.</h4><p><img src="assets/1617286254236.png" alt="1617286254236"></p><p><strong>Fig. 3(b)</strong> 不完整周期变换，该变换从不完整的输入（红色）产生完整的预测（绿色）</p><p>对于图3（b）中的不完整循环变换，当 $\mathbb{x}$ 从不完整域转换为完整域 $\mathbf{x}_{y} $ 时，$F_X$ 会生成缺失区域代码 $\mathbf{x}_{y}^{z} $ 和完整形状表示 $\mathbf{x}_{y}^{r} $。 因此，$\mathbf{x}_{y} $ 可以进一步表示为 $\mathbf{x}_{y}=\left[\mathbf{x}_{y}^{r}: \mathbf{x}_{y}^{z}\right] $ 。 备注“：”表示两个特征向量的串联。 然后，基于 $ G_{Y} $ 的 $\mathbf{x}_{y}^{r} $ 预测完整形状为 $ G_{Y}\left(\mathbf{x}_{y}^{r}\right) $。 判别器 $D_Y$ 仅在  $\mathbf{x}_{y}^{r} $  和 $y$ 之间进行判别。 为了在变换过程中建立形状一致性，$\mathbf{x}_{y} $ 再次由 $ F_{Y} $ 投射回不完全域，表示为 $\hat{\mathbf{x}} $。 循环重建的形状由 $ G_{X} $ 预测，表示为 $ G_{X}(\hat{\mathbf{x}}) $。</p><p><img src="assets/1617286270674.png" alt="1617286270674"></p><p><img src="assets/1617286213830.png" alt="1617286213830"></p><p>对于图3（c）中的完整循环变换，编码器 $ E_{Y} $ 直接预测完整的形状表示 $\mathbf{y}^{r} $。 为了预测不完整的形状，我们从 $[0,1]$ 之间的均匀分布（表示为 $\mathbf{y}^{z} $）和与$\mathbf{y}^{r} $（表示 $\mathbf{y}=\left[\mathbf{y}^{r}: \mathbf{y}^{z}\right] $ ）之间的均匀分布中随机采样缺失的区域代码。 然后，变换网络 $ F_{Y} $ 将 $\mathbf{y} $ 变换为不完整域，记为 $\mathbf{y}_{x} $。 与不完全循环变换类似，基于  $\mathbf{y}_{x} $ 由 $ G_{X} $ 预测不完全形状，记为 $ G_{X}\left(\mathbf{y}_{x}\right) $ 。 判别器 $ D_{X} $ 在 $\mathbf{y}_{x} $ 和 $\mathbf{x} $ 之间进行判别。 遵循不完全循环变换的反方向，通过预测重构形状 $ G_{Y}(\hat{\mathbf{y}}) $ 来建立完整周期变换期间的形状一致性，其中 $\hat{\mathbf{y}}=F_{X}\left(\mathbf{y}_{x}\right) $。 请注意，与 $\mathbf{y} $ 相同，$\hat{\mathbf{y}} $ 还包含完整的表示 $\hat{\mathbf{y}}^{r} $ 和缺失的区域代码 $\hat{\mathbf{y}}^{z} $</p><hr><h4 id="Code-matching-Loss"><a href="#Code-matching-Loss" class="headerlink" title="Code matching Loss."></a>Code matching Loss.</h4><p>在图3（c）的完整循环变换中，从均匀分布中采样缺失区域代码y z，以便从当前完整输入P Y创建缺失区域。 在形状P Y通过F Y和F X循环之后，变换网络F Y F X预测出新的缺失区域代码y y z。 因为y z和ˆ y z都对应于相同的不完整形状，所以两个代码应相等。 因此，我们建议使用y z和ˆ y z之间的欧几里得距离作为代码匹配损耗，可以表示为：</p><script type="math/tex; mode=display">\begin{equation} \mathcal{L}_{\text {code }}=\left\|\mathbf{y}^{z}-\hat{\mathbf{y}}_{z}\right\|^{2} $\end{equation}\tag{3}</script><h4 id="Cycle-matching-loss"><a href="#Cycle-matching-loss" class="headerlink" title="Cycle matching loss."></a><strong>Cycle matching loss.</strong></h4><p>循环匹配损耗的目的是使循环重建G Y（/ y）/ G X（ˆ x）的形状与它们相应的输入P Y / P X匹配，这应在整个转换过程中保持形状一致性。 具体而言，我们将循环匹配损耗定义为输入P Y / P X与重构点云G Y（ˆ y）/ G X（ˆ x）之间的完整倒角距离，即L CD（P X？<br>   G X（ˆ x））和L CD（P Y？G Y（ˆ y））。 然后我们将转移网络F X和F Y的全周期匹配损失表示为：</p><script type="math/tex; mode=display">\begin{equation} \mathcal{L}_{\text {cycle }}=\mathcal{L}_{\mathrm{CD}}\left(\mathcal{P}_{X} \leftrightharpoons G_{X}(\hat{\mathbf{x}})\right)+\mathcal{L}_{\mathrm{CD}}\left(\mathcal{P}_{Y} \leftrightharpoons G_{Y}(\hat{\mathbf{y}})\right) \end{equation}\tag{4}</script><h4 id="Partial-matching-loss"><a href="#Partial-matching-loss" class="headerlink" title="Partial matching loss."></a><strong>Partial matching loss.</strong></h4><p>部分匹配损耗是方向性约束，旨在将一种形状匹配到另一种形状，而无需在反方向上进行匹配。 在以前的工作[3]中可以找到类似的做法，该工作采用定向Hausdoff距离将完全预测与不完全输入部分匹配。 但是，单方向的局部匹配不能为推断缺失区域提供进一步的指导，因此我们将局部匹配集成到循环变换中以在两个方向上建立更全面的几何对应关系。 我们将两个点云P 1和P 2之间的部分倒角距离定义为：</p><script type="math/tex; mode=display">\begin{equation} \mathcal{L}_{\mathrm{CD}^{\prime}}\left(\mathcal{P}_{1} \rightarrow \mathcal{P}_{2}\right)=\sum_{\mathbf{p}_{i}^{1} \in \mathcal{P}_{1}} \min _{\mathbf{p}_{i}^{2} \in \mathcal{P}_{2}}\left\|\mathbf{p}_{i}^{1}-\mathbf{p}_{i}^{2}\right\| \end{equation}\tag{5}</script><p>这是仅要求P 2的形状与P 1的形状部分匹配的约束。 对于图3（b）中的不完整周期，部分匹配损耗表示为L CD 0（PX→GY（xry）），对于图3（c）中的完整周期，部分匹配损耗表示为L CD 0  （GX（yx）→PY）。 注意，以上两个部分倒角距离的方向总是从不完整的形状指向完整的形状，这保证了不完整的形状部分地匹配完整的形状，无论是预测的还是真实的。 全部的部分匹配损耗定义为：L部分= L CD 0（P X→G Y（x r y））+ L CD 0（G X（y x）→P Y）。<br>   （6）</p><h4 id="Adversarial-loss"><a href="#Adversarial-loss" class="headerlink" title="Adversarial loss"></a>Adversarial loss</h4><p>To further bridge the geometric gap between the latent representations of complete and incomplete shapes, the adversarial learning framework is adopted as an unpaired constraint. Specifically, two discriminators D X and D Y are used to distinguish the real and fake representations in the incomplete and complete domains, respectively. The D X in incomplete domain discriminates between the real latent representations {x} and the fake latent represen-<br>tations {y x }; in the same way, the D Y in complete domain discriminates between {y} and {x y }. In order to stabilize the training, we formulate the objective loss for discriminator under the WGAN-GP [5] framework. For simplicity, we formulate the loss for D X as:</p><script type="math/tex; mode=display">\begin{equation} \mathcal{L}_{D_{X}}=\mathbb{E}_{\mathbf{x}} D_{X}(\mathbf{x})-\mathbb{E}_{\mathbf{y}_{x}} D_{X}\left(\mathbf{y}_{x}\right)+\lambda_{g p} \mathcal{T}_{D_{X}} \end{equation}\tag{7}</script><p>where λ gp is a pre-defined weight factor and T D X is gradient penalty term, denoted as:</p><script type="math/tex; mode=display">\begin{equation} \mathcal{T}_{D_{X}}=\mathbb{E}_{\mathbf{x}}\left[\left(\left\|\nabla_{\mathbf{x}} D_{X}(\mathbf{x})\right\|_{2}-1\right)^{2}\right] \end{equation}\tag{8}</script><p>The discriminator loss L D Y for D Y can be formulated in the same way. The final adversarial losses for generator {F X ,F Y } and discriminator {D X ,D Y } are given as</p><script type="math/tex; mode=display">\begin{equation} \mathcal{L}_{D}=\mathcal{L}_{D_{X}}+\mathcal{L}_{D_{Y}} \tag{9}\\ \end{equation}</script><script type="math/tex; mode=display">\mathcal{L}_{G}=\mathbb{E}_{\mathbf{y}_{x}}  D_{X}\left(\mathbf{y}_{x}\right)+\mathbb{E}_{\mathbf{x}_{y}}  D_{Y}\left(\mathbf{x}_{y}^{r}\right) \tag{10}</script><h2 id="5-Conclusions"><a href="#5-Conclusions" class="headerlink" title="5. Conclusions"></a>5. Conclusions</h2><p>我们提出了不成对点的 Cycle4Completion 来处理点云补全任务。我们的模型成功捕捉到收入和收入之间的双向几何对应完整的形状，使学习没有成对完整形状的点云完成。 我们的模型有效地学习生成假的不完整 引导完成网络的形状。拟议的Cy- cle4Completion在广泛使用的ShapeNet上进行评估 数据集，实验结果表明 与其他不成对的组件相比 完全方法。</p>]]></content>
      
      
      
        <tags>
            
            <tag> PointCloud </tag>
            
            <tag> Completion </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/03/03/hello-world/"/>
      <url>/2022/03/03/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> SLAM </tag>
            
            <tag> CUDA </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
